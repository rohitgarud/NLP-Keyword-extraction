{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yet Another Keyword Extractor (YAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import yake\n",
    "from fuzzywuzzy import process\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>abstract</th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble Statistical and Heuristic Models for ...</td>\n",
       "      <td>statistical word alignment, ensemble learning,...</td>\n",
       "      <td>Statistical word alignment models need large a...</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Improving Spectral Learning by Using Multiple ...</td>\n",
       "      <td>representation, spectral learning, discrete fo...</td>\n",
       "      <td>Spectral learning algorithms learn an unknown ...</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applying Swarm Ensemble Clustering Technique f...</td>\n",
       "      <td>software defect prediction, particle swarm opt...</td>\n",
       "      <td>Number of defects remaining in a system provid...</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reducing the Effects of Detrimental Instances</td>\n",
       "      <td>filtering, label noise, instance weighting</td>\n",
       "      <td>Not all instances in a data set are equally be...</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Concept Drift Awareness in Twitter Streams</td>\n",
       "      <td>twitter, adaptation models, time-frequency ana...</td>\n",
       "      <td>Learning in non-stationary environments is not...</td>\n",
       "      <td>Ensemble Methods</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "paper_id                                                      \n",
       "1         Ensemble Statistical and Heuristic Models for ...   \n",
       "2         Improving Spectral Learning by Using Multiple ...   \n",
       "3         Applying Swarm Ensemble Clustering Technique f...   \n",
       "4             Reducing the Effects of Detrimental Instances   \n",
       "5                Concept Drift Awareness in Twitter Streams   \n",
       "\n",
       "                                                   keywords  \\\n",
       "paper_id                                                      \n",
       "1         statistical word alignment, ensemble learning,...   \n",
       "2         representation, spectral learning, discrete fo...   \n",
       "3         software defect prediction, particle swarm opt...   \n",
       "4                filtering, label noise, instance weighting   \n",
       "5         twitter, adaptation models, time-frequency ana...   \n",
       "\n",
       "                                                   abstract           session  \\\n",
       "paper_id                                                                        \n",
       "1         Statistical word alignment models need large a...  Ensemble Methods   \n",
       "2         Spectral learning algorithms learn an unknown ...  Ensemble Methods   \n",
       "3         Number of defects remaining in a system provid...  Ensemble Methods   \n",
       "4         Not all instances in a data set are equally be...  Ensemble Methods   \n",
       "5         Learning in non-stationary environments is not...  Ensemble Methods   \n",
       "\n",
       "          year  \n",
       "paper_id        \n",
       "1         2014  \n",
       "2         2014  \n",
       "3         2014  \n",
       "4         2014  \n",
       "5         2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data \n",
    "dataset_csv = \"ICMLA_2014_2015_2016_2017.csv\"\n",
    "encoding = \"ISO-8859-1\"\n",
    "data_df = pd.read_csv(dataset_csv, encoding=encoding).set_index(\"paper_id\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAKE Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"text\"] = data_df[\"title\"] + \" \" + data_df[\"abstract\"]\n",
    "corpus = data_df[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = data_df[\"title\"].iloc[0]\n",
    "abstract = data_df[\"abstract\"].iloc[0]\n",
    "text = f\"{title} {abstract}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_yake(text):\n",
    "    deduplication_threshold = 0.7\n",
    "    deduplication_algo = 'seqm'\n",
    "    numOfKeywords = 20\n",
    "    y = yake.KeywordExtractor( \n",
    "        n=3, # maximum ngram size\n",
    "        dedupLim=0.7, # deduplication threshold\n",
    "        dedupFunc='seqm', # deduplication algorithm\n",
    "        top=numOfKeywords, \n",
    "        features=None)\n",
    "    doc_keywords = [keyword[0] for keyword in y.extract_keywords(text)]#[::-1]\n",
    "    deduplicated_doc_keywords = list(process.dedupe(doc_keywords, threshold=70))\n",
    "    final_keywords = \", \".join(deduplicated_doc_keywords[:5])\n",
    "    return final_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Statistical and Heuristic Models for Unsupervised Word Alignment Statistical word alignment models need large amount of training data while they are weak in small-size corpora. This paper proposes a new approach of unsupervised hybrid word alignment technique using ensemble learning method. This algorithm uses three base alignment models in several rounds to generate alignments. The ensemble algorithm uses a weighed scheme for resampling training data and a voting score to consider aggregated alignments. The underlying alignment algorithms used in this study include IBM Model 1, 2 and a heuristic method based on Dice measurement. Our experimental results show that by this approach, the alignment error rate could be improved by at least %15 for the base alignment models.\n",
      "================================================================\n",
      "Alignment Statistical word, Unsupervised Word Alignment, small-size corpora, large amount, Statistical and Heuristic\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(\"================================================================\")\n",
    "print(extract_keywords_yake(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.4 s ± 9.04 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Applying YAKE to whole dataset\n",
    "data_df[\"extracted_keywords\"] = data_df[\"text\"].apply(extract_keywords_yake)\n",
    "data_df[\"extracted_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Exception: 'numpy.ndarray' object has no attribute 'replace' generated by the following text: '['Ensemble Statistical and Heuristic Models for Unsupervised Word Alignment Statistical word alignment models need large amount of training data while they are weak in small-size corpora. This paper proposes a new approach of unsupervised hybrid word alignment technique using ensemble learning method. This algorithm uses three base alignment models in several rounds to generate alignments. The ensemble algorithm uses a weighed scheme for resampling training data and a voting score to consider aggregated alignments. The underlying alignment algorithms used in this study include IBM Model 1, 2 and a heuristic method based on Dice measurement. Our experimental results show that by this approach, the alignment error rate could be improved by at least %15 for the base alignment models.'\n",
      " 'Improving Spectral Learning by Using Multiple Representations Spectral learning algorithms learn an unknown function by learning a spectral (e.g., Fourier) representation of the function. However, there are many possible spectral representations, none of which will be best in all situations. Consequently, it seems natural to consider how a spectral learner could make use of multiple representations when learning. This paper proposes and compares three approaches to learning from multiple spectral representations. Empirical results suggest that an ensemble approach to multi-spectrum learning, in which spectral models are learned independently in each of a set of candidate representations and then combined in a majority-vote ensemble, works best in practice.'\n",
      " 'Applying Swarm Ensemble Clustering Technique for Fault Prediction Using Software Metrics Number of defects remaining in a system provides an insight into the quality of the system. Defect detection systems predict defects by using software metrics and data mining techniques. Clustering analysis is adopted to build the software defect prediction models. Cluster ensembles have emerged as a prominent method for improving robustness, stability and accuracy of clustering solutions. The clustering ensembles combine multiple partitions generated by different clustering algorithms into a single clustering solution. In this paper, the clustering ensemble using Particle Swarm Optimization algorithm (PSO) solution is proposed to improve the predict quality. An empirical study shows that the PSO can be a good choice to build defect prediction software  models.'\n",
      " 'Reducing the Effects of Detrimental Instances Not all instances in a data set are equally beneficial for inducing a model of the data. Some instances (such as outliers or noise) can be detrimental. However, at least initially, the instances in a data set are generally considered equally in machine learning algorithms. Many current approaches for handling noisy and detrimental instances make a binary decision about whether an instance is detrimental or not. In this paper, we 1) extend this paradigm by weighting the instances on a continuous scale and 2) present a methodology for measuring how detrimental an instance may be for inducing a model of the data. We call our method of identifying and weighting detrimental instances reduced detrimental instance learning (RDIL). We examine RIDL on a set of 54 data sets and 5 learning algorithms and compare RIDL with other weighting and filtering approaches. RDIL is especially useful for learning algorithms where every instance can affect the classification boundary and the training instances are considered individually, such as multilayer perceptrons trained with backpropagation (MLPs). Our results also suggest that a more accurate estimate of which instances are detrimental can have a significant positive impact for handling them.'\n",
      " 'Concept Drift Awareness in Twitter Streams Learning in non-stationary environments is not an easy task and requires a distinctive approach. The learning model must not only have the ability to continuously learn, but also the ability to change already acquired concepts. Additionally, given the significant importance that social networks gained as information networks, there is an ever-growing interest in the extraction of complex information used for trend detection, promoting services or market sensing. This dynamic nature tends to limit the performance of traditional static learning models and dynamic learning strategies must be put forward. In this paper we present a learning strategy to learn in the presence of concept drift in Twitter. We propose three different models: a time-window model, an ensemble-based model and an incremental model. Since little is known about the types of drift that can occur in Twitter, we simulate different types of drift by artificially timestamping real Twitter messages in order to evaluate and validate our strategy. Results are so far encouraging regarding learning in the presence of drift, along with classifying messages in Twitter streams.'\n",
      " \"High Precision Screening for Android Malware with Dimensionality Reduction This work presents a new method of classifying previously unseen Android applications as malware or benign. The algorithm starts with a large set of features: the frequencies of all possible n-byte sequences in the application's byte code. Principal components analysis is applied to that frequency matrix in order to reduce it to a low-dimensional representation, which is then fed into any of several classification algorithms. We utilize the implicitly restarted Lanczos bidiagonalization algorithm and exploit the sparsity of the n-gram frequency matrix in order to efficiently compute the low-dimensional representation. When trained upon that low-dimensional representation, several classification algorithms achieve higher accuracy than previous work.\"\n",
      " 'Reducing the Cost of Breaking Audio CAPTCHAs by Active and Semi-Supervised Learning CAPTCHAs are challenge-response tests that are widely used in the Internet to distinguish human users from machines. In addition to the well-known visual CAPTCHAs, most Internet services also provide an audio-based scheme, e.g., to enable access for visually impaired users. Recent research has shown that most CAPTCHAs are vulnerable as they can be broken by machine learning techniques. However, such automated attacks come at a relatively high cost as they require human experts to create labels for the unlabeled CAPTCHA samples collected from a website in order to train an attacking system.In this work we utilize active and semi-supervised learning methods for breaking audio CAPTCHAs. We show that these methods can reduce the labeling costs considerably, resulting in an increased vulnerability of audio CAPTCHAs as automated attacks are rendered even more worthwhile.In addition, our findings give insight into improvements to the design of CAPTCHAs, helping to harden prospective audio CAPTCHA schemes against active learning attacks in the future.\"\"\"'\n",
      " 'Q-Learning: From Computer Network Security To Software Security Reinforcement learning techniques become more popular in computer network security. The same reinforcement learning techniques developed for network security can be applied to software security as well. This research summarizes a work in progress attempt to incorporate Q-learning algorithm in software security. The Q-learning method is embedded as part of the software itself to provide a security mechanism that has ability to learn by itself to develop a temporary repair mechanism. The results of the experiment express that given the right parameters and the right setting the Q-learning approach rapidly learns to block all alicious actions. Data analysis on the Q-values produced by the software can provide security diagnostic as well. A larger scale experiment is expected to be seen in the future work.'\n",
      " 'On-line Signature Verification using Symbolic Aggregate Approximation (SAX) and Sequential Minimal Optimization (SMO) Signatures are the single most widely used method of identifying an individual but they carry with them an alarmingly significant amount of vulnerabilities implying a need for an effective and robust method of precisely identifying an individuals signature. The signature of an individual is visually acquired by using pen based tracking system (1), (2). This paper considers the possibility of discretizing visually acquired signatures to represent them as an unordered collection of words and then use Sequential Mining Optimization (SMO) for training Support Vector Machines (SVM) to classify the signature as either legitimate or forged. The discretizing of the signature is done by using Symbolic Aggregate Approximation (SAX) (4). SAX reduces the dimensions of the signature and produces a list of SAX words which are then represented as a bag-of-patterns model for classification purposes (5). The data set consisted of more than 3960 signatures of 106 subjects distributed across two sets. The results obtained provided good classification accuracy and additionally provided an insight into the unique pattern of each subjects signature.'\n",
      " 'Detection of abnormal human behavior using a matrix approximation-based approach Automatic detection of abnormal events is one of central tasks in video surveillance. In this paper we present a matrix approximation-based method to detect abnormal human behavior. In our model, a behavior pattern is represented by a motion matrix obtained through object tracking. We model typical motions associated with normal behaviors with a set of motion subspaces, computed through low-rank matrix approximation. Then, abnormal human behaviors are identified by the motion deviations from the representative subspaces. Our method does not require a complicated classification procedure, and can fast detect abnormal events in complex scenes. In addition, through the adaptive learning module, our model is built on the observed data, and can be expanded by incorporating new behavior patterns during the detection process. The results on simulated surveillance videos show the effectiveness of our method.'\n",
      " 'Activity Recognition Using Graphical Features Activity Recognition is important in order to facilitate elderly residents and their caregivers needs. This problem has been widely investigated using different methods including probabilistic and Markovian approaches. The focus of this paper is to perform activity recognition more accuractely than existing approaches. We represent motion sensors of smart environments in a graph and residents movements as edges in the graph.Then graph-based features are extracted and used as input for a Support Vector Machine. These features have been combined with motion-sensor based features. This method has been compared with three other widely used approaches, Naive Bayes, Hidden Markov Model (HMM) and Conditional Random Fields (CRF) on three different datasets from three smart aparments. In all cases, the method based on graphical features outpeformed existing approaches.'\n",
      " 'An Accurate, Fast Embedded Feature Selection for SVMs Feature selection is still a vital area for research in the machine learning field. After the emergence of big data, the need for mining large data sizes has increased to provide faster and more accurate predictions. Feature selection is concerned with selecting the most important features from a set of input features since some datasets may contain irrelevant and/or redundant features. In this paper, a new feature selection method of type embedded is presented and discussed with some preliminary results using existing benchmark datasets. The new method is called Recursive Feature Addition which works in a forward fashion and is based on Support Vector Machines. The new method has been applied to five different benchmark datasets and for which it has shown superior performance in terms of accuracy and time as compared to Filter, Wrapper and other Embedded methods.'\n",
      " 'Learning Good Features To Track Object tracking is an important task within the field of computer vision. Tracking accuracy depends mainly on finding good discriminative features to estimate the target location. In this paper, we introduce online feature learning in tracking and propose to learn good features to track generic objects using online convolutional neural networks (OCNN). OCNN has two feature mapping layers that are trained offline based on unlabeled data. In tracking, it is also augmented with a classifier to provide a decision. In order to learn discriminative and stable features for tracking, we propose a novel object function to train OCNN by penalizing the feature variations in consecutive frames. We build a tracking system by combining OCNN and a color-based multi-appearance model. Our experimental results on publicly available video datasets show that the tracking system has superior performance when compared with several state-of-the-art trackers.'\n",
      " 'Feature Selections for Effectively Localizing Faulty Events in GUI Applications Due to the complex causality of failure and the special characteristics of test cases, the faults in GUI (Graphic User Interface) applications are difficult to localize. This paper adapts feature selection algorithms to localize GUI-related faults in a given program. Features are defined as the subsequences of events executed. By employing statistical feature ranking techniques, the events can be ranked by the suspiciousness of events being responsible to exhibit faulty behavior. The features defined in a given source code implementing (event handle) the underlying event are then ranked in suspiciousness order. The evaluation of the proposed technique based on some open source Java projects verified the effectiveness of this feature selection based fault localization technique for GUI applications.'\n",
      " 'Dimensionality Reduction in Statistical Learning Many Statistical Learning tasks deal with data which are presented in high dimensional spaces, and the curse of dimensionality phenomena is often an obstacle to the use of many methods for solving these tasks. To avoid these phenomena, various Dimensionality Reduction algorithms are used as a first key step in solutions of these tasks. The algorithms transform the original high-dimensional data into their lower dimensional representations in such a way that the initial task may be reduced to the corresponding task for the constructed lower-dimensional representation of the original dataset. The Dimensionality Reduction problems have different formulations depending on initial Statistical Learning tasks. A new geometrically motivated algorithm that solves various Dimensionality Reduction problems is presented.'\n",
      " 'Bayesian Nonparametric Inverse Reinforcement Learning for Switched Markov Decision Processes In this paper we develop a Bayesian nonparametric Inverse Reinforcement Learning technique for switched Markov Decision Processes (MDP). Similar to switched linear dynamical systems, switched MDP (sMDP)can be used to represent complex behaviors composed of temporal transitions between simpler behaviors each represented by a standard MDP. We use sticky Hierarchical Dirichlet Process as a nonparametric prior on the sMDP model space, and describe a Markov Chain Monte Carlo method to efficiently learn the posterior on the sMDP models given the behavior data. We demonstrate the effectiveness of sMDP models for learning, prediction and  classification of complex agent behaviors in a simulated surveillance scenario.'\n",
      " 'State Abstraction in Reinforcement Learning by Eliminating Useless Dimensions Q-learning and other linear dynamic learning algorithms are subject to Bellmans curse of dimensionality for any realistic learning problem. This paper introduces a framework for satisficing state abstraction one that reduces state dimensionality, improving convergence and reducing computational and memory resources by eliminating useless state dimensions. Statistical parameters that are dependent on the state and Q-values identify the relevance of a given state space to a task space and allow state elements that contribute least to task learning to be discarded. Empirical results of applying state abstraction to a canonical single-agent path planning task and to a more difficult multi-agent foraging problem demonstrate utility of the proposed methods in improving learning convergence and performance in resource-constrained learning problems.'\n",
      " 'A knowledge growth and consolidation framework for lifelong machine learning systems A more effective vision of machine learning systems entails tools that are able to improve task after task and to reuse the patterns and knowledge that are acquired previously for future tasks. This incremental, long-life view of machine learning goes beyond most of state-of-the-art machine learning techniques that learn throw-away models. In this paper we present a long-life knowledge acquisition, evaluation and consolidation framework that is designed to work with any rule-based machine learning or inductive inference engine and integrate it into a long-life learner. In order to do that we work over the graph of working memory rules and introduce several topological metrics over it from which we derive an oblivion criterion to drop useless rules from working memory and a consolidation process to promote the rules to the knowledge base. We evaluate the framework on a series of tasks in a chess rule learning domain.'\n",
      " 'LaCova: A Tree-Based Multi-Label Classifier using Label Covariance as Splitting Criterion Dealing with multiple labels is a supervised learning problem of increasing importance. Multi-label classifiers face the challenge of exploiting correlations between labels. While in existing work these correlations are often modelled globally, in this paper we use the divide-and-conquer approach of decision trees which enables taking local decisions about how best to model label dependency. The resulting algorithm establishes a tree-based multi-label classifier called LaCova which dynamically interpolates between two well-known baseline methods: Binary Relevance, which assumes all labels independent, and Label Powerset, which learns the joint label distribution. The key idea is a splitting criterion based on the label covariance matrix at that node, which allows us to choose between a horizontal split (branching on a feature) and a vertical split (separating the labels). Empirical results on 12 data sets show strong performance of the proposed method, particularly on data sets with hundreds of labels.'\n",
      " 'Combining Exact And Metaheuristic Techniques For Learning Extended Finite-State Machines From Test Scenarios and Temporal Properties This paper addresses the problem of learning extended finite-state machine (EFSM) from user-specified behavior examples (test scenarios) and temporal properties. We show how to combine exact EFSM inference algorithms~(that always find a solution if it exists) and metaheuristics to derive an efficient combined EFSM learning algorithm. We also present a new exact EFSM inference algorithm based on Constraint Satisfaction Problem (CSP) solvers. Experimental results are reported showing that the new combined algorithm significantly outperforms a previously used metaheuristic.'\n",
      " 'Human action recognition based on recognition of linear patterns in action bank features using convolutional neural networks In this paper, we proposed a deep convolutional network architecture for recognizing human actions in videos using action bank features. Action bank features computed against of a predefined set of videos known as an action bank, contain linear patterns representing the similarity of the video against the action bank videos. Due to the independence of the patterns across action bank features, a convolutional neural network with linear masks is considered to capture the local patterns associated with each action. The knowledge gained through training is used to assign an action label to videos during testing. Experiments conducted on UCF50 dataset demonstrates the effectiveness of the proposed approach in capturing and recognizing these linear local patterns.'\n",
      " 'A Cyclic Contrastive Divergence Learning Algorithm for High-order RBMs The Restricted Boltzmann Machine (RBM), a special case of general Boltzmann Machines and a typical Probabilistic Graphical Models, has attracted much attention in recent years due to its powerful ability in extracting features and representing the distribution underlying the training data. A most commonly used algorithm in learning RBMs is called Contrastive Divergence (CD) proposed by Hinton, which starts a Markov chain at a data point and runs the chain for only a few iterations to get a low variance estimator. However, when referring to a high-order RBM, since there are interactions among its visible layers, the gradient approximation via CD learning usually becomes far from the log-likelihood gradient and even may cause CD learning to fall into the infinite loop with high reconstruction error. In this paper, a new algorithm named Cyclic Contrastive Divergence (CCD) is introduced for learning high-order RBMs. Unlike the standard CD algorithm, CCD updates the parameters according to each visible layer in turn, by borrowing the idea of Cyclic Block Coordinate Descent method. To evaluate the performance of the proposed CCD algorithm, regarding to high-order RBMs learning, both algorithms CCD and standard CD are theoretically analyzed, including convergence, estimate upper bound and both biases comparison, from which the superiority of CCD learning is revealed. Experiments of handwritten digit classification task on MNIST dataset are performed. The experimental results show that CCD is more applicable and consistently outperforms the standard CD in both convergent speed and performance.'\n",
      " 'Facial expression recognition using kinect depth sensor and convolutional neural networks Facial expression recognition is an active area of research with applications in the design of Human Computer Interaction (HCI) systems. In this paper, we propose an approach for facial expression recognition using deep convolutional neural networks (CNN) based on features generated from depth information only. The Gradient direction information of depth data is used to represent facial information, due its invariance to distance from the sensor. The ability of a convolutional neural networks (CNN) to learn local discriminative patterns from data is used to recognize facial expressions from the representation of unregistered facial images. Experiments conducted on EURECOM kinect face dataset demonstrate the effectiveness of the proposed approach.'\n",
      " 'Improving Performance on Problems with Few Labelled Data by Reusing Stacked Auto-Encoders Deep architectures have been used in transfer learning applications, with the aim of improving the performance of networks designed for a given problem by reusing knowledge from another problem. In this work we addressed the transfer of knowledge between deep networks used as classifiers of digit and shape images, considering cases where only the set of class labels, or only the data distribution, changed from source to target problem. Our main goal was to study how the performance of knowledge transfer between such problems would be affected by varying the number of layers being retrained and the amount of data used in that retraining. Generally, reusing networks trained for a different label set led to better results than reusing networks trained for a different data distribution. In particular, reusing for less classes a network trained for more classes was beneficial for virtually any amount of training data. In all cases, retraining only one layer to save time consistently led to poorer performance. The results obtained when retraining for upright digits a network trained for rotated digits raise the hypothesis that transfer learning could be used to better deal with image classification problems in which only a small amount of labelled data is available for training.'\n",
      " 'An Analysis of Instance Selection for Neural Networks to Improve Training Speed Training Artificial Neural Networks (ANN) is relatively slow compared to many other machine learning algorithms.  In this study, we focus on instance selection to improve training speed.  We first evaluate the effectiveness of instance selection algorithms for k-nearest neighbor algorithms with ANN.  We then analyze factors in accuracy distance from decision boundary, dense regions, and class distributions, and propose new instance selection algorithms.  We discuss the tradeoff between accuracy and training speed, and introduce a measure for the tradeoff.  Our empirical results on real data sets indicate that our proposed RDI is more effective with ANN.'\n",
      " 'Human action recognition based on MOCAP information using convolution neural networks Human action recognition is an important component in semantic analysis of human behavior. In this paper, we propose an approach for human action recognition based on motion capture (MOCAP) information using convolutional neural networks (CNN). Distance based metrics computed from MOCAP information of only three human joints are used in the computation of features. The range and temporal variation of these distance metrics are considered in the design of features which are discriminative for action recognition. A convolutional neural network capable of recognizing local patterns is used to identify human actions from the temporal variation of these features, which are distorted due to the inconsistency in the execution of actions across observations and subjects. Experiments conducted on Berkeley MHAD dataset demonstrate the effectiveness of the proposed approach.'\n",
      " 'Improving Named Entity Recognition for Morphologically Rich Languages using Word Embeddings In this paper, we addressed the Named Entity Recognition (NER) problem for morphologically rich languages by employing a semi-supervised learning approach based on neural networks. We adopted a fast unsupervised method for learning continuous vector representations of words, and used these representations along with language independent features to develop a NER system. We evaluated our system for the highly inflectional Turkish and Czech languages and obtained better F-score performances than the previously published results for these languages. We improved the state-of-the-art F-score by 2.26% for Turkish and 1.53% for Czech. Unlike the previous state-of-the-art systems developed for these languages, our system does not make use of any language dependent features. Therefore, we believe it can easily be applied to other morphologically rich languages.'\n",
      " 'Multi-Variable Neural Network Forecasting Using Two Stage Feature Selection This paper proposes a novel neural network based forecaster that predicts more than one variable at a time. A two stage neural network training algorithm is used that employs Newtons algorithm to estimate a vector of hidden unit optimal learning factors in each iteration. In order to reduce the size of the neural network and train it more effectively, the forecaster uses both subsetting and transformation types of feature selection, reducing the number of neural net inputs by 70 %.'\n",
      " 'Adaptive restructuring of radial basis functions using integrate-and-fire neurons This paper proposes a neurobiology-based extension of integrate-and-fire models of Radial Basis Function Neural Networks (RBFNN) that adapts to novel stimuli by means of dynamic restructuring of the networks structural parameters. The new architecture automatically balances synapses modulation, re-centers hidden Radial Basis Functions (RBFs), and stochastically shifts parameter-space decision planes to maintain homeostasis. Example results are provided throughout the paper to illustrate the effects of changes to the RBFNN model.'\n",
      " 'One-shot periodic activity recognition using Convolutional Neural Networks Activities capture vital facts for the semantic analysis of human behavior. In this paper, we propose a method for recognizing human activities based on periodic actions from a single instance using convolutional neural networks (CNN). The height of the foot above the ground is considered as features to discriminate human locomotion activities. The periodic nature of actions in these activities is exploited to generate the training cases from a single instance using a sliding window. Also, the capability of a convolutional neural network to learn local visual patterns is exploited for human activity recognition. Experiments on Carnegie Mellon University (CMU) Mocap dataset demonstrate the effectiveness of the proposed approach.'\n",
      " 'Semi-Supervised Kernel-Based Temporal Clustering In this paper, we adapt two existing methods to perform semi-supervised temporal clustering: Aligned Cluster Analysis (ACA), a temporal clustering algorithm, and Constrained Spectral Clustering, a semi-supervised clustering algorithm. In the first method, we add side information in the form of pairwise constraints to its objective function, and in the second, we add a temporal search to its framework. We also extend both methods by propagating the constraints throughout the whole similarity matrix. In order to validate the advantage of the proposed semi-supervised methods to temporal clustering, we evaluate them in comparison to their original versions as well as another semi-supervised temporal cluster on three temporal datasets. The results show that the proposed methods are competitive and provide good improvement over the unsupervised approaches.'\n",
      " 'Learning to Rank with Only Positive Examples A key to successfully retrieve relevant documents lies in how users express their information needs using keywords as queries.  However, for many users, it is difficult for them to use keywords to express their information needs. Search-By-Multiple-Examples (SBME), a promising method for overcoming this problem, allows users to specify their information needs as a set of relevant documents rather than as a set of keywords. In this study, we propose a Transductive Positive Unlabeled learning (TPU learning) based framework for document ranking The framework consists of two steps: 1) identifying potential relevant documents to reduce the searching space from the entire data collection to a smaller dataset, and 2) adopting TPU learning methods to re-rank the searching space by treating the relevant documents from a user as positive examples P and the documents in the searching space as unlabeled data U. Using MAP and p@k, we evaluate two state-of-the-art PU learning algorithms and the Rocchio classifier (Rc) for document ranking in the proposed framework with different sizes of P to simulate users online search behaviors. We then adopt the idea of ensemble learning to combine Rc with the two state-of-the-art PU learning algorithms respectively. Experiments conducted on two real datasets show that the ensemble learning based methods lead to significant improvement in performance.'\n",
      " 'Geometric PDEs on weighted graphs for semi-supervised classification In this paper, we consider the adaptation of two Partial Differential Equations (PDEs) on weighted graphs, p-Laplacian and eikonal equation, for semi-supervised classification tasks. These equations are a discrete analogue of well known geometric PDEs, which are widely used in image processing. While the p-Laplacian on graphs was intensively used in data classification, few works relate to the eikonal equation for data classification. The methods are illustrated through semi-supervised classification tasks on databases, where we compare the two algorithms. The results show that these methods perform well regarding the state-of-the-art and are applicable to the task of semi-supervised classification.'\n",
      " \"Post-Processing Association Rules using Networks and Transductive Learning Association is widely used to find relations among items in a given database. However, finding the interesting patterns is a challenging task due to the large number of rules that are generated. Traditionally, this task is done by post-processing approaches that explore and direct the user to the interesting rules of the domain. Some of these approaches use the user's knowledge to guide the exploration according to what is defined (thought) as interesting by the user. However, this definition is done before the process starts. Therefore, the user must know what may be and what may not be interesting to him/her. This work proposes a general association rule post-processing approach that extracts the user's knowledge during the post-processing phase. That way, the user does not need to have a prior knowledge in the database. For that, the proposed approach models the association rules in a network, uses its measures to suggest rules to be classified by the user and, then, propagates these classifications to the entire network using transductive learning algorithms. Therefore, this approach treats the post-processing problem as a classification task. Experiments were carried out to demonstrate that the proposed approach reduces the number of rules to be explored by the user and directs him/her to the potentially interesting rules of the domain.\"\n",
      " 'Variational Inference on Infinite Mixtures of Inverse Gaussian, Multinomial Probit and Exponential Regression We introduce a new class of methods and inference techniques for infinite mixtures of Inverse Gaussian, Multinomial Probit and Exponential Regression, models that belong to the widely applicable framework of Generalized Linear Model (GLM). We characterize the joint distribution of the response and covariates via a Stick-Breaking Prior. This leads to, in the various cases, nonparametric models for an infinite mixture of Inverse Gaussian, Multinomial Probit and Exponential Regression. Estimates of the localized mean function which maps the covariates to the response are presented. We prove the weak consistency for the posterior distribution of the Exponential model (SB-EX) and then propose mean field variational inference algorithms for the Inverse Gaussian, Multinomial Probit and Exponential Regression. Finally, we demonstrate their superior accuracy in comparison to several other regression models such as, Gaussian Process Regression, Dirichlet Process Regression, etc.'\n",
      " \"Varying Coefficient Models for Analyzing the Effects of Risk Factors on Pregnant Women's Blood Pressure In the study of gestational hypertension, most of studies focused on whether a risk factor is associated with gestational hypertension. However, according to the clinical experience, it is important to know the effects of risk factors on women's blood pressure during pregnancy. Thus, we examined the effects of known risk factors (age, hematocrit, etc.) over gestational age. We also examined whether the effects of known risk factors are different between gestational hypertension group and preeclampsia group. These were studied in 412 pregnant women including 1874 clinical follow-up records. On the longitudinal clinical data of pregnant women, varying coefficient models were applied to study the effects of known risk factors over gestational age. The results showed that the effects of known risk factors varied with gestational age, and the changing processes of known risk factors over gestational age were different between gestational hypertension group and preeclampsia group. In final, we used the relative error as the criterion to assess the accuracy of the estimated varying coefficient model. The relative errors for total clinical data, gestational hypertension group and preeclampsia group were 13.3%, 8.1% and 14.3%, respectively.\"\n",
      " 'Learning Score Systems for Patient Mortality Prediction in Intensive Care Units via Orthogonal Matching Pursuit The problem of predicting outcome of patients in intensive care units (ICUs) is of great importance in critical care medicine, and has wide implications for quality control in ICUs. A dominant approach to this problem has been to use an ICU score system such as the Acute Physiology and Chronic Health Evaluation (APACHE) system and the Simplified Acute Physiology Score (SAPS) system, to compute a certain severity score for a patient from a set of clinical observations, and apply a logistic regression model on this score to obtain an estimate of the probability of mortality for the patient, owing to their simplicity, these methods are widely used by clinicians. However, existing ICU score systems, which are built from a fixed set of patient data, often perform poorly when applied to a patient population with different characteristics, also, with changes in patient characteristics, a score system built from a given patient data set becomes suboptimal over time. Moreover, most of these score systems are built using semi-automated procedures, making it difficult to adapt them to a new patient population. Thus there is a huge need for adaptive methods that can automatically learn predictive models from a given set of patient data. Indeed, there has been much work in recent years on applying various machine learning methods to this problem, however these methods learn different representations from the score systems preferred by clinicians. In this work, we develop a machine learning method based on orthogonal matching pursuit that automatically learns a score system type model, which enjoys the benefits of both worlds: like other machine learning methods, it is adaptive, like standard score systems, it uses a representation that is easy for clinicians to understand. Experiments on real-world patient data sets show that our method outperforms standard ICU score systems, and performs at least as well as other machine learning methods for this problem.'\n",
      " 'Implementation of machine learning for classifying hemiplegic gait disparity through use of a force plate The synergy of gait analysis tools with machine learning enables the capacity to classify disparity existing in hemiplegic gait. Hemiplegic gait is characterized by an affected and unaffected leg, which can be quantified by the measurement of a force plate. The characteristic features of the force plate recording for gait consist of a two local maxima that represent the braking and push off phase of stance and their associated parameters. The quantified features of a hemiplegic pair of affected and unaffected force plate recordings are intuitively disparate. Logistic regression achieves 100% classification between an affected and unaffected hemiplegic leg pair based on the feature set of the force plate data.'\n",
      " 'Expert Bayes: Automatically refining manually built Bayesian networks Bayesian network structures are usually built using only the data and starting from an empty network or from a naive Bayes structure. Very often, in some domains, like medicine, a prior structure is already known based on expert knowledge. This structure can be automatically or manually refined in search for better performance models. In this work, we take Bayesian networks built by specialists and show that minor perturbations to this original network can yield better classifiers with a very small computational cost, while maintaining most of the interpretability of the original network.'\n",
      " 'Time Warping Symbolic Aggregation Approximation with Bag-of-Patterns Representation for Time Series Classification Standard Symbolic Aggregation approXimation (SAX) is at the core of many effective time series data mining algorithms. Its combination with Bag-of-Patterns has become the standard approach with bleeding-edge performance on standard datasets. However, standard SAX with BoP representation might neglect the internal temporal correlation embedded in the data. In this paper, we proposed time warping SAX, which extends the standard SAX methods with time delay embedding vector approaches by considering the temporal correlations. We test time warping SAX with BoP representation on 12 benchmark dataset from UCR Time Series Classification/Clustering Page and on 9 of them time warping SAX overtakes the state-of-th-eart performance of standard SAX. To validate our methods in real world applications, a new dataset of vital signs collected from the patients who may require blood transfusion (pRBC) in the next 6 hours are tested. All the results demonstrate that by considering the temporal internal correlation, our time warping SAX with BoP representations could significantly enhance the representation power.'\n",
      " 'A Hybrid Genetic-Programming Swarm-Optimisation Approach for Examining the Nature and Stability of High Frequency Trading Strategies Advances in high frequency trading in financial markets have exceeded the ability of regulators to monitor market stability, creating the need for tools that go beyond market microstructure theory and examine markets in real time, driven by algorithms, as employed in practice. This paper investigates the design, performance and stability of high frequency trading rules using a hybrid evolutionary algorithm based on genetic programming, with a particle swarm optimisation layered on top to improve the genetic operators performance. Our algorithm learns the relevant trading signal information using Foreign Exchange market data. We significantly reduce its execution time by implementing computationally intensive tasks using the Field Programmable Gate Array technology. This approach is shown to provide a reliable platform for examining the stability and nature of optimal trading strategies under different market conditions. We generate robust and significant statistical results on the optimal rules performance and their economic value.'\n",
      " 'Sequential Logistic Principal Component Analysis (SLPCA): Dimensional Reduction in Streaming Multivariate Binary-State System Sequential or online dimensional reduction is of interests due to the explosion of streaming data based applications and the requirement of adaptive statistical modeling, in many emerging fields, such as the modeling of energy end-use profile. Principal Component Analysis (PCA), is the classical way of dimensional reduction. However, traditional Singular Value Decomposition (SVD) based PCA fails to model data which largely deviates from Gaussian distribution. The Bregman Divergence was recently introduced to achieve a generalized PCA framework. If the random variables under dimensional reduction follow Bernoulli distribution, which occurs in many emerging fields, the generalized PCA is called Logistic PCA (LPCA). In this paper, we extend the batch LPCA to a sequential version (i.e. SLPCA), based on the sequential convex optimization theory. The convergence property of this algorithm is discussed compared to the batch version of LPCA (i.e. BLPCA), as well as its performance in reducing the dimension for multivariate binary-state systems. Its application in building energy end-use profile modeling is also investigated.'\n",
      " 'Using k-Nearest Neighbor and Speaker Ranking for Phoneme Prediction Speech recognition systems are either based on parametric approach or non-parametric approach. Parametric based system such as HMMs have been the dominant technology for speech recognition in the past decade. Despite a lot of advancements and enhancements in the design of these systems:  key problems such as long term temporal dependence, etc. has not yet been solved. Recently due to availability of large amount of data and inexpensive computing resources (processing power and memory) parametric based approach to solve speech recognition and classification task is becoming popular and feasible. The key advantage of parametric based approach is that all the information from the training data is retained as we dont approximate our data with specific statistical models resulting in more speaker specific information. In this paper we propose a kNN phoneme prediction scheme using speaker ranking vector. Speaker ranking vector is generated by finding the similarity of the given TEST speaker with the training data using kNN. The results were compared with nearest neighbor and kNN majority voting approach. Our proposed scheme gives a better prediction accuracy as compare with nearest neighbor and kNN majority voting scheme. This approach can help speech recognizer to customize on the fly for a given talker and customize training data on the basis of similarity measure.'\n",
      " 'A Machine Learning Approach to Combining Individual Strength and Team Features for Team Recommendation In IT strategic outsourcing businesses, it is critical to have competent deal teams design competitive service solutions and swiftly respond to clients request for proposals. In this paper we present a general team recommendation framework for finding best deal teams to pursue such engagement opportunities. Little previous work on team recommendation considers both individual and team-level features at the same time.  Our proposed framework can take into account diverse individual and team features, and accommodate various cost or feature functions. We introduce a team quality metric based on a weighted linear combination of these features, the weights of which are learned using a machine learning approach by leveraging historical project outcomes. A combinatorial optimization algorithm is finally applied to search the possible solution space for the approximate best team. We report a preliminary evaluation of our framework by applying it to a real-world data from strategic outsourcing businesses at a large IT service company. We also compare our approach with other existing work by using the public DBLP dataset for recommending teams in academic paper authoring.'\n",
      " 'Genetically Supervised Self-Organizing Map for the Classification of Glass Samples The self-organizing map (SOM) is a useful tool for creating abstractions of high-dimensional distributions of inputs. It computes the ideal mapping of the domain of observations, using either discrete or continuous distributions of values (1). The SOM benefits from the coupling with a genetic algorithm (GA). GAs are optimization algorithms that allow the user to evolve a solution from a distribution of potential solutions (2). The fittest candidates survive and participate in the production of future generations of new solutions. The fusion of these two techniques results in a dynamic algorithm that maps a diverse input plane in an optimizing fashion, striving towards perfection while learning from mistakes. We will detail the general principles involved and demonstrate the performance of this algorithm in the classification of glass samples.'\n",
      " 'Modelling Mutual Information Between Voiceprint and Optimal Number of Mel-frequency Cepstral Coefficients in Voice Discrimination In this paper, we study the relationship between the voiceprint and the optimal number of Mel-frequency Cepstral Coefficients (MFCCs) which yields the highest classification accuracy of the voice discrimination. The voiceprint is modelled as sub-MFCCs matrix with the first d number of MFCCs. We model the relationship through information theory and formulate it as the mutual information maximization problem subject to the probabilities constraint. The solution of this optimization problem provides the optimal number of MFCCs, which yields the highest classification accuracy of the voice discrimination, together with a confidence level. This study is dictated by the need to understand the use of MFCCs, which have proliferated since its invention to discriminate voice. We evaluate our model by comparing the leave-one-out cross validation (LOOCV) results of usual multi-class classifier, the Supervised Learning Gaussian Mixture Model (SLGMM), with a set of spoken words and solo acapella singings. The experimental results show that our model is a more comprehensive feature selection criteria for the MFCCs than the de-facto technique, LOOCV.'\n",
      " 'LSH vs Randomized Partition Trees: Which One to Use for Nearest Neighbor Search? Recently, randomized partition trees have been theoretically shown (cite{dasgupta13}) to be very effective in performing high dimensional nearest neighbor search. In this paper, we introduce a variant of randomized partition trees  for high dimensional nearest neighbor search problem and provide theoretical justification for its choice. Experiments on various real-life datasets show that this new variant performs better than the variant introduced in cite{dasgupta13}  and also than the locality sensitive hashing (LSH) method for nearest neighbor search. In addition, we show an interesting connection between various  notions of difficulty in nearest neighbor search problem, that have recently been introduced, namely, potential function (cite{dasgupta13}) and relative contrast (cite{he12}).'\n",
      " 'Topic Detection in Instant Messages In the past few years, instant messaging (IM) has been widely used in daily communication. However, due to the dispersion of topics and meaningless chatting, online IM groups are filled with useless messages. In order to help IM users capture what the IM group is talking about without spending a long time in reading all the messages, topic discovery in instant messages becomes a significant but challenging research task. In this paper, we propose a new method for topic detection in instant messages, which is applicable for the case where 1) useless terms keep emerging, 2) the instant messages are very short, and 3) multiple languages are used. The basic step is to treat each message in an online group discussion as a data item in message stream, and then apply PLSA to the collected instant messages. One strategy is designed to segment multilingual message without utilizing machine translation and remove the useless words that keep emerging. Extensive experiments have been conducted on the real-world QQ group data to confirm the effectiveness of the proposed method.'\n",
      " 'Automated scoring of the Level of Integrative Complexity from Text using Machine Learning Conceptual/Integrative complexity is a construct developed in political psychology and clinical psychology to measure an individuals ability to consider different perspectives on a particular issue and reach a justifiable conclusion after consideration of said perspectives. Integrative complexity (IC) is usually determined from text through manual scoring, which is time-consuming, laborious and expensive. Consequently, there is a demand for automating the scoring, which could significantly reduce the time, expense and cognitive resources spent in the process. Any algorithm that could achieve the above with a reasonable accuracy could assist in the development of intervention systems for reducing the potential for aggression, systems for recruitment processes and even training personnel for improving group disparity in the corporate world. In this study we used machine learning to predict IC levels from text. We achieved over 78% accuracy in a three way classification.'\n",
      " 'Extraction of Unexpected Rules from Twitter Hashtags and its Application to Sport Events Online news is now widely embraced because of its affordability, rich contents and fast broadcast of diverse real life events and occurrences. Twitter has become a dependable microblogging tool for real time information dissemination and newsworthy events broadcast. Its users sometimes break news on the network faster than traditional newsagents due to their presence at on-going real life events at all times. Different topic detection methods are currently used to match Twitter posts to real life news of mainstream media. In this paper, we analyse events highlights in the English FA Cup final 2012 played between Chelsea FC and Liverpool FC using our novel methodology named TRCM. Our system was able to detect all goals scored in the game, 1 of the 3 bookings and 3 of the four substitutions. Our system also detected other events like free kicks, goal saves and misses  as well as ball clearances and off-side positions that occurred during the match duration. We used the BBC Live Text Commentary as our ground truth to validate our method. The result of the experiment shows that our method performed well as a Topic Detection and Tracking approach.'\n",
      " 'Using Spectral Features to Improve Sentiment Analysis A common approach to sentiment classification is to identify a set of sentiment-carrying words and then to use machine learning to build a classifier that can classify sentiment based on the presence/absence of those words. In this paper, we propose a Fourier-based extension of this approach. Specifically, we introduce a spectral learning algorithm  that implicitly identifies sentiment-carrying words and higher-order functions of those words as it learns to assign real-valued sentiment scores to documents. The spectral learner extends the word presence model by applying Boolean logic operators (AND, OR, and XOR) to the word presence features to identify useful higher-order features. These spectral features can be used in other learning algorithms, and we show how the performance of other learning algorithms can be improved by these features. Finally, we consider the problem of determining which of a pair of reviews expresses more positive overall sentiment, and we show that the spectral learner can identify very small distinctions in sentiment with better-than-random accuracy, while larger distinctions can be correctly identified with high accuracy.'\n",
      " 'Recommendation Systems for Markets with Two Sided Preferences In recent times we have witnessed the emergence of large online markets with two-sided preferences that are responsible for businesses worth billions of dollars. Recommendation systems are critical components of such markets. It is to be noted that the matching in such a market depends on the preferences of both sides, consequently, the construction of a recommendation system for such a market calls for consideration of preferences of both sides. The online dating market, and the online freelancer market are examples of markets with two-sided preferences. Past studies on building recommendation systems for such markets, however, lacks a systematic approach. We observe that constructing recommendation systems for markets with two-sided preferences can be posed as an Area Under the receiver operator Curve(AUC) optimization problem. Generalized linear regression models are popular methods of constructing ranking or recommendation systems in such markets on account of their ability to be learned easily from big data, and their computational simplicity on engineering platforms. We conjecture that it is more likely for matching in such markets to be a complex combination of preferences of both sides. To account for this, we introduce a novel two-level model for optimizing the AUC of matching in such markets. For both synthetic and real data we show that the two-level model algorithm has a better AUC performance than the direct application of a generalized linear model such as $L_{1}$ logistic regression or an ensemble method such as random forest algorithm. We provide a theoretical justification of AUC optimality of two-level model and pose a theoretical problem for a more general result. To the best of our knowledge, this is the first systematic study of recommendation systems using AUC optimization in markets with two-sided preferences.'\n",
      " 'Improving Robustness of Gaussian Process-based Inferential Control System using Kernel Principle Component Analysis The plausibility and robustness of an inferential control system entirely depend on the prediction accuracy of the estimator used as the feedback element. This paper is based on a previously proposed Gaussian process inferential controller that employs Gaussian process soft sensor as an estimator. The paper enhances the robustness and the reliability of the control system, particularly, during sensor input failures. The contribution of the paper is i) alleviating the affect of the failure on the prediction accuracy of feedback element (soft sensor) and thus improving the robustness of the overall control system. ii) Hybridising Kernel Principal Component Analysis with Gaussian process Inferential Control System to achieve this robustness during all process operating conditions. The paper empirically shows the effectiveness and the plausibility of the processed hybrid system on a simulated chemical reactor process.'\n",
      " 'Arctic Sea Ice Extent Forecasting Using Support Vector Regression The summer minimum Arctic sea ice extent has long been used as a measure of climate change, with record lows being reported in recent years. Understanding the dynamics of Arctic sea ice extent is of utmost importance in understanding the timescales associated with this change. Complex global climate models are typically employed to gain insights about the future of Arctic sea ice, however, these models are typically very computationally expensive to solve and the results are often controversial. Here, we use historical data from remote sensing satellites along with machine learning algorithms in the forecasting of Arctic sea ice extent. Support Vector Regression is employed in the learning of a dynamic model to represent this system. Validation results demonstrate the ability of the method to successfully forecast both the seasonal and long-term trends in Arctic sea ice coverage.'\n",
      " \"WiFi Localization For Mobile Robots based on Random Forests and GPLVM The proliferation of WiFi networks has attracted many research communities to employ WiFi signals in estimating the location of mobile devices in indoor environments.In this paper, we propose a localization framework that is capable of determining the location of mobile robots in indoor limited areas. The proposed framework exploits the Random Forests algorithm in both classification and regression techniques, which are used to build cooperated supervised localization models. The localization models are trained offline based on training data that contains  measurements of WiFi signal strengths and the location of these measurements. We also proposed an extension to our framework using the Gaussian Process Latent Variable Model (GPLVM), which gives our framework the ability to build subjective localization models which don't require any prior knowledge about ground truth of the localization place. Our experimental evaluation of the proposed framework using KheperaIII mobile robot in one testbed show that it gives high accuracy, where the calculated mean localization error is 36 cm.\"\n",
      " 'Example-Dependent Cost-Sensitive Logistic Regression for Credit Scoring Several real-world classification problems are example-dependent cost-sensitive in nature, where the costs due to misclassification vary between examples. Credit scoring is a typical example of cost-sensitive classification. However, it is usually treated using methods that do not take into account the real financial costs associated with the lending business. In this paper, we propose a new example-dependent cost matrix for credit scoring. Furthermore, we propose an algorithm that introduces the example-dependent costs into a logistic regression. Using two publicly available datasets, we compare our proposed method against state-of-the-art example-dependent cost-sensitive algorithms. The results highlight the importance of using real financial costs. Moreover, by using the proposed cost-sensitive logistic regression, significant improvements are made in the sense of higher savings.'\n",
      " 'A Switch-and-Restart Algorithm with Exponential Restart Strategy for Objective Selection and its Runtime Analysis There exist optimization problems with the target objective, which is to be optimized, and several extra objectives, which may or may not be helpful in the optimization process. This paper considers the case when it is possible to find an optimum of the target objective by optimizing either the target objective or a single extra objective. An algorithm is presented that uses a single instance of an underlying single-objective optimization algorithm to optimize different objectives at different iterations and restarts the optimization algorithm between optimizing different objectives. This algorithm has the expected running time of at most 4 K min_O T_O until an optimum of the target objective is found, where T_O is the expected running time of the underlying optimization algorithm to find an optimum of the target objective by optimizing the objective O. An impact of not using restarts between iterations is also discussed.'\n",
      " 'Adding Diversity to Rank Examples in Anytime Nearest Neighbor Classification Data streams are ubiquitous in virtually every application domain. However, a property that is common to various domains and is frequently disregarded is the very high fluctuating data rates, in which the events do not occur with a fixed frequency. The classical learning algorithms do not seem to be adequate in such a scenario. In contrast, anytime classification provides a very convenient approach for this situation. In summary, an anytime classifier can be interrupted at any time before its completion and still be able to provide an intermediate classification. The popular k-nearest neighbor classifier can be easily made anytime by introducing a ranking of the training examples. In this paper, we show how the current state-of-the-art k-NN anytime classifier can be made more accurate by introducing diversity in the training set ranking. Our results show that, with this simple modification, the performance of the anytime version of the k-NN algorithm is consistently improved for a large number of datasets.'\n",
      " 'Improved kNN Rule for Small Training Sets The traditional k-NN classification rule predicts a label based on the most common label of the k nearest neighbors (the plurality rule). It is known that the plurality rule is optimal when the number of examples tends to infinity. In this paper we show that the plurality rule is sub-optimal when the number of labels is large and the number of examples is small. We propose a simple k-NN rule that takes into account the labels of all of the neighbors, rather than just the most common label. We present a number of experiments on both synthetic datasets and real-world datasets, including MNIST and SVHN. We show that our new rule can achieve lower error rates compared to the majority rule in many cases.'\n",
      " 'Computation of a Rejection Threshold used for the Bayes Classifier In this paper an algorithm for the efficient computation of a rejection threshold for Bayes classification is discussed. A theoretical and a practical evaluation of the performance regarding the accuracy of the numerical computation for uni- and multimodal high-dimensional probability distributions is given. Additionally some observations regarding the dimensionality and the number of samples are shared.'\n",
      " 'Protein Conformation Motion Modeling using sep-CMA-ES The problem of protein conformation motion modeling is an open problem in the structural computational biology. It is difficult to solve it using methods of molecular dynamics or quantum physics because these methods deal with time intervals of nanoseconds or microseconds, while conformation motions take time of millisecond order. In addition, these methods cannot take external forces into consideration. To cope with these problems, numerous approximated and coarse-grained methods are developed, which use ideas from geometry and motion planning.We present a new coarse-grained method of modeling the protein motion between two given conformations. The method is based on optimization of a cost function similar to the one in the Monge-Kantorovich mass transfer problem. The optimization is performed using sep-CMA-ES, which makes the running time of an iteration linear in the number of amino acids in a protein. The proposed method is compared with some of the existing methods on several molecules. It is shown that the results of the proposed method are more accurate than of the other methods.'\n",
      " 'Budgeted Learning for Developing Personalized Treatment There is increased interest in using patient-specific information to  personalize treatment. Personalized treatment decision rules can be learned using data from standard clinical trials, but such trials are very costly to run. This paper explores the use of budgeted learning techniques to design more efficient clinical trials, by effectively determining which type of patients to recruit, at each time, throughout the duration of the trial. We propose a Bayesian bandit model and discuss the computational challenges and issues pertaining to this approach. We compare our budgeted learning algorithm, which approximately minimizes the Bayes risk, using both simulated data and data modeled after a clinical trial for treating depressed individuals, with other plausible algorithms. We show that our budgeted learning algorithm demonstrated excellent performance across a wide variety of situations.'\n",
      " 'Visualising Singing Style Under Common Musical Events Using Pitch-Dynamics Trajectories and Modified TRACLUS Clustering In this paper, we present a novel method for visualising the singing style of vocalists. To illustrate our method, we take 26 audio recordings of a capella solo vocal music from two different professional singers and we visualise the performance style of each vocalist in a two dimensional space of pitch and dynamics. We use our own novel modification of a trajectory clustering algorithm called TRACLUS to generate four representative paths, called trajectories, in that two dimensional space.  Each trajectory represents the characteristic style of a vocalist during one of four common musical events: (1) Crescendo, (2) Diminuendo, (3) Ascending Pitches and (4) Descending Pitches. The unique shapes of these trajectories characterize the singing style of each vocalist with respect to each of these events. We present the details of our modified version of the TRACULUS algorithm and demonstrate graphically how the plots produced indicate distinct stylistic differences betweens singers. Potential applications for this method include: (a) automatic identification of singers and automatic classification of singing styles and (b) automatic retargeting of performance style to add human expression to computer generated vocal performances and allow singing synthesisers to imitate the styles of specific famous professional vocalists.'\n",
      " 'Supervised Music Chord Recognition Chord represents the back-bone of occidental music genre as it contains rich harmonic information which is useful for various music applications such as music genre classification or music retrieval. Hence, chord recognition or transcription is of importance for music representation. In this paper we focus on chord recognition and especially investigate different features representation used in such a system:  classical features as well as a new type of feature we propose are explored.  We evaluate their usefulness through a multi-class chord classification problem.'\n",
      " 'Uncertainty Quantified Matrix Completion using Bayesian Hierarchical Matrix Factorization Low-rank matrix completion methods have been successful in a variety of settings such as recommendation systems. However, most of the existing matrix completion methods only provide a point estimate of missing entries, and do not characterize uncertainties of the predictions. In this paper, we propose a Bayesian hierarchical probabilistic matrix factorization (BHPMF) model to 1) incorporate hierarchical side information, and 2) provide uncertainty quantified predictions. The former yields significant performance improvements in the problem of plant trait prediction, a key problem in ecology, by leveraging the taxonomic hierarchy in the plant kingdom. The latter is helpful in identifying predictions of low confidence which can in turn be used to guide field work for data collection efforts. A Gibbs sampler is designed for inference in the model. Further, we propose a multiple inheritance BHPMF (MI-BHPMF) which can work with a general directed acyclic graph (DAG) structured hierarchy, rather than a tree. We present comprehensive experimental results on the problem of plant trait prediction using the largest database of plant traits, where BHPMF shows strong empirical performance in uncertainty quantified trait prediction, outperforming the state-of-the-art based on point estimates. Further, we show that BHPMF is more accurate when it is confident, whereas the error is high when the uncertainty is high.'\n",
      " 'Using Balanced Random Forests on Load Spectrum Data for Classifying Component Failures of a HybridElectric Vehicle Fleet To be able to optimize the dimensioning of the power-train of a hybrid electric vehicle, engineers have to find relationships between stresses of the power-train and failures of its components. In this paper, we apply the machine learning technique random forest to a heterogeneous dataset consisting of so-called \"load spectrum\" data resulting from transforming stress-time functions to frequency distributions. In Fatigue Analysis this is the state-of-the-art data employed for calculating the fatigue life of components. We (i) study the usability of random forests modeled on this kind of data to distinguish between faulty and non-faulty vehicles, and (ii) address the problem of selecting a small number of relevant variables in order to further decrease the misclassification rate and, even more important from our engineering point of view, to identify failure related variables. As our data contains just very few samples of faulty compared to non-faulty vehicles, we furthermore present a framework for tuning the random forest to handle this class imbalance. We demonstrate experimentally for failures of the hybrid car battery that using random forests for variable selection and classification of load spectrum data achieves promising classification performance and enables engineers to identify possible relationships between loads and failures of hybrid components.'\n",
      " 'Multimodal Sparsity-Eager Support Vector Machines for Music Classification As the demand for multimedia grows, the development of information retrieval systems utilizing all available data modalities becomes of paramount importance. The provision of multiple modalities is motivated by usability, presence of noise in one modality and non-universality of a single modality. Radio stations and music TV channels hold archives of millions of music tapes and lyrics. Gigabytes of music files are also spread over the web along with the lyrics and metadata for each file. Searching and organizing large scale multimodal datasets is a challenging task. Supervised methods such as support vector machine (SVM) achieve state of the art performance for music classification on single modality, but suffer from over-fitting on training examples and limitations of single modality approaches. In this paper, we introduce a classifier fusion of multimodal audio and lyrics data to address these single modality classification limitations. We introduce the multimodal l1-SVM classifier, that utilizes sparse methods to deal with over-fitting for music classification. We compare the classification accuracy of the fusion classifier for a genre classification task in a large public dataset with single modality l1-SVM.'\n",
      " 'A Better Case Adaptation Method for Case-Based Effort Estimation Using Multi-Objective Optimization Case-Based Reasoning (CBR) is considered as one of the efficient methods in the area of software effort estimation because of its outstanding performance and capability of handling noisy datasets. This study examines the performance of multi-objective Particle Swarm Optimization algorithm to find the best configuration parameters for the adaptation process. Particularly, we propose a new adaptation method for which its parameters can be optimized by making trade off between multiple accuracy measures. The proposed adaptation is fully automated and able to dynamically adapt each case in the dataset individually. Based on empirical validation over 8 datasets, the performance figures have seen good improvements against conventional CBR and some adapted versions of CBR.'\n",
      " 'Employing Markov Networks on Curriculum Graphs to Predict Student Performance Colleges and universities are increasingly interested in tracking student progress as they monitor and work to improve their retention and graduation rates. Ideally, early indicators of student progress, or lack thereof, can be used to provide appropriate interventions that increase the likelihood of student success. In this paper we present a framework that uses data mining and machine learning techniques, and in particular, linear regression and a Markov network (MN), to predict the performance of students early in their academic careers. The results obtained show that the proposed framework can predict student progress, specifically student grade point average (GPA) within the intended major, with minimal error after observing a single semester of performance. Furthermore, as additional performance is observed, the predicted GPA in subsequent semesters becomes increasingly accurate, providing the ability to advise students regarding likely success outcomes early in their academic careers.'\n",
      " 'Leveraging Machine Learning Algorithms to Perform Online and Offline Highway Traffic Flow Prediction Advanced traffic management systems (ATMS) are heavily depending on traffic flow or equivalent travel time estimation. The main goal of this paper is to accomplish two different algorithms to perform offline and online traffic flow forecasting. A multi-layer perceptron (MLP), which is trained on yearly data, is utilized for mid-term offline predictions. Principal components analysis (PCA) is employed to speed up the training process. This model also serves as a baseline. The stochastic gradient descent deploys online forecasting. Both algorithms predict the flow of a location down a Trunk highway (the target point) using the history of flow of several locations ahead of the target point in Twin Cities Metro area in Minneapolis.'\n",
      " 'OUPS: A Combined Approach Using SMOTE and Propensity Score Matchingtching Building accurate classifiers is difficult when using data that is skewed or imbalanced which is typical of real world data sets. Two popular approaches that have been applied for improving classification accuracy and statistical comparisons of imbalanced data sets are: synthetic minority over-sampling technique (SMOTE) and propensity score matching (PSM). A novel sampling approach is introduced referred to as over-sampling using propensity scores (OUPS) that blends the two and is simple and easy to perform resulting in improvement in accuracy and sensitivity over both SMOTE and PSM. The performance of our proposed approach is assessed using a simulation experiment and several performance metrics are shown where this approach fares and falls in comparison to the others.'\n",
      " 'A Comparison of Supervised Machine Learning Techniques for Predicting Short-Term In-Hospital Length of Stay among Diabetic Patients Diabetes is a life-altering medical condition that affects millions of people and results in many hospitalizations per year. Consequently, predicting the length of stay of in-hospital diabetic patients has become increasingly important for staffing and resource planning. Although statistical methods have been used to predict length of stay in hospitalized patients, many powerful machine learning techniques have not yet been explored. In this paper, we compare and discuss the performance of various supervised machine learning algorithms (i.e., Multiple linear regression, support vector machines, multi-task learning, and random forests) for predicting long versus short-term length of stay of hospitalized diabetic patients.'\n",
      " 'Comparative Study of Different Classification Techniques: Heart Disease Use Case Common stream mining tasks include classification, clustering and frequent pattern mining among them, data stream classification has drawn particular attention due to its vast real-time application. Through these applications, the main goal is to efficiently build classification models from data streams for accurate prediction. The development of such model has shown the need for machine learning techniques to be applied to large scale data. A range of machine learning techniques exists and the selection of the accurate techniques is based on advantages and limits of each one and how these latter well addresses important research techniques. In this paper, we present the comparison of different classification techniques using WEKA in order to investigate the performance of a collection of classification algorithms. This comparison shows the support vector machine performance with higher accuracy and better results when classifying our dataset.'\n",
      " \"A Genetic Algorithm Approach to Partitioning Clustering : A case study on M.Sc. Applicants Acquiring a Master Degree is becoming a common practice to ensure successful life and good career path, especially in developing countries. Master Degree in Information Technology is one of the most popular programmes with prolific number of applications and students. This work has two main objectives. First is to discover the number of clusters of applicants and the characteristics of each cluster. Another is to develop a Genetic Algorithm based Partitioning Clustering Program. This is achieved by incorporating distance matrix and its application in Divisive Analysis and Gower's measure of similarity. The Genetic Algorithm based Partitioning Clustering program developed was proven superior to some common clustering techniques.\"\n",
      " 'American Sign Language Recognition Using Leap Motion Sensor In this paper, we present an American Sign Language recognition system using a compact and affordable 3D motion sensor. The palm-sized Leap Motion sensor provides a much more portable and economical solution than Cyblerglove or Microsoft kinect used in existing studies. We apply k-nearest neighbor and support vector machine to classify the 26 letters of the English alphabet in American Sign Language using the derived features from the sensory data. The experiment result shows that the highest average classification rate of 72.78% and 79.83% was achieved by k-nearest neighbor and support vector machine respectively. We also provide detailed discussions on the parameter setting in machine learning methods and accuracy of specific alphabet letters in this paper.'\n",
      " 'Learner Engagement Measurement and Classification in 1:1 Learning We explore the feasibility of measuring learner engagement and classifying the engagement level based on machine learning applied on data from 2D/3D camera sensors and eye trackers in a 1:1 learning setting. Our results are based on nine pilot sessions held in a local high school where we recorded features related to student engagement while consuming educational content. We label the collected data as Engaged or NotEngaged while observing videos of the students and their screens. Based on the collected data, perceptual user features (e.g., body posture, facial points, and gaze) are extracted. We use feature selection and classification methods to produce classifiers that can detect whether a student is engaged or not. Accuracies of up to 85-95% are achieved on the collected dataset. We believe our work pioneers in the successful classification of student engagement based on perceptual user features in a 1:1 authentic learning setting.'\n",
      " \"An Intelligent Tutoring System for Argument-Making in Higher Education: A Pilot Study This paper presents a pilot study on an intelligent tutoring system for domain-independent argument making. Students' responses to an open-ended question were collected as the instances for supervised text classification based on the grade given by the instructor using structured outcome of the learning observation taxonomy. The responses were processed using Cohmetrix as well as n-gram models to generate attributes for the classification task. The best result of 81.74% in classification correct rate was obtained when all grade classes were used.\"\n",
      " \"Automatically filtering irrelevant words for applications in language acquisition Building one's vocabulary in a language is an important component of language acquisition. Children learn their native language by being immersed in the language that is used in their environment. However, in second language acquisition, learners are often exposed to vocabulary that is selected by others specifically to aid language acquisition such as textbooks and word-lists. In this paper, we are presenting a machine learning based method for automatically selecting words that are relevant to the language acquisition task. The word relevancy is determined using data collected from 30 practicing English as a Second Language teachers for this purpose. We demonstrate the viability of this approach by using words from two major corpora, although in practice any corpora such as Google Books corpus can be utilized.\"\n",
      " 'A Clustering-based Grouping Model for Enhanceing Collaborative Learning Group work is widely used in tertiary institutions due to the considerable advantages of collaborative learning. Previous studies indicated that the group diversity had positive influence on the group work achievement. Therefore, how to achieve diversity within a group effectively and automatically is an interesting question. In this paper we propose a novel clustering-based grouping model. The proposed technique first employs balanced K-means algorithm to divide the students into several size-balanced clusters, such that the students within the same cluster are more similar (in some sense) to each other than to those in other clusters, then adopts one-sample-each-cluster strategy to construct the groups1. We evaluated the proposed technique based on two small-scale case studies. The result observed may indicate that the clustering-based grouping model is feasible and effective.'\n",
      " \"Improving an Early Warning System to Prediction of Student Examination Achievement In Turkey, there are many exams for transition to a higher education institution. These exams are all stages of life and have a great importance in the lives of students. As the severity rating of the exam, particularly students, parents and teachers are affected and exams create anxiety for students. Examination results are very important in shaping the lives of future students. Therefore, in this study is aimed to estimate the success of students, which is students' turning point in their lives, in the university entrance exam. The aim of this study, using data mining algorithms on the created student data warehouse, is to estimate the students' successes, who are taking the university entrance exam, by data mining. In this study, it has been improved a software considering Naive Bayes algorithms for student data warehouse. By that developed software by using C# languages, it is aimed to improve an early warning system that may estimate the states of the students' successes in university entrance exam for students and also for their families.\"\n",
      " \"Investigating Sentimental Relation between Social Media Presence and Academic Success of Turkish Universities In this study an approach that uses social networking data for developing sentiment analysis system is proposed. With the help of developed software, it is tried to find out whether there is any relation between universities' academic success and sentiment of the public about them in social media. After collecting enough text based data from Twitter, preprocessing of data is carried out and final data is trained by means of Nai¨ve Bayes Classifier. After testing process, experimental results have shown that developed sentiment analysis system can classify the tweets about top 10 universities according to URAP rankings in terms of their sentiment with the 72.33% success rate, and proposed methodology can be used by universities for understanding sentiment of the public about them in social media.\"\n",
      " 'Next Generation Application-Layer DDoS Defences: Applying the Concepts of Outlier Detection in DataStreams with Concept Drift The existing state-of-the art in the field of application-layer DDoS protection is generally designed, and thus effective, only for static Web-domains. To the best of our knowledge, this paper is the first one to study the problem of application-layer DDoS defense in Web-sites of dynamic content and/or organization and under non-trivial bot (i.e., Attack) behavior. The main contributions of the paper are threefold: 1) we provide a detailed taxonomy of the existing and next-generation application-layer HTTP-based DDoS attacks, 2) we discuss the relevance of a branch of data mining theory -- known as data streams with concept drift -- to the problem of application-layer DDoS defense in dynamic Web-domains, 3) we present the outline of our next-generation anti-DDoS system that is intended for dynamic Web-domains facing different sophisticated variants of application-layer DDoS attacks. The paper also includes some of our preliminary experimental results concerning the detection of malicious Web-users/sessions using the proposed system.'\n",
      " 'TSD: Detecting Sybil Accounts in Twitter Fake identities and user accounts (also called \"Sybils\") in online communities represent today a treasure for adversaries to spread fake product reviews, malware and spam on social networks, and Astroturf political campaigns. State-of-the-art in the defense mechanisms includes Automated Turing Tests (ATTs such as CAPTCHAs) and graph-based Sybil detectors. Sybil detectors in social networks leverage the assumption that Sybils will find it hard to befriend real users which leads to Sybils being connected to each other forming strongly connected sub graphs that can be detected using graph theory. However, the large majority of Sybils are in fact successful in integrating themselves into real user communities (such as the case in Twitter and Facebook). In this paper, we first study and compare the current detection mechanisms of Sybil accounts. We also explore various types of Twitter Sybil accounts detection features with the objective of building an effective and practical classifier. In order to build and evaluate our classifier, we collect and manually label a dataset of twitter accounts, including human users, bots, and hybrid (i.e., Tweets are posted by both human and bots). We believe this Twitter Sybils corpus will help researchers in conducting sound measurement studies. We also develop a browser plug-in (that we call Twitter Sybils Detector or TSD for short) that utilizes our classifier and warns the user about possible Sybil accounts before accessing them, upon clicking on a Twitter account.'\n",
      " 'An Intelligent Technique for Detecting Malicious Users on Mobile Stores In this study, malicious users who cause to resource exhausting are tried to detect in a telecommunication company network. Non-Legitimate users could cause lack of information availability and need countermeasures to prevent threat or limit permissions on the system. For this purpose, ANN based intelligent system is proposed and compared to SVM which is well known classification technique. According to results, proposed technique has achieved approximately 70% general success rate, 33% false positive rate and 27% false negative rate in controlled environment. Also ANN has high ability to work compare to SVM for our dataset. As a result proposed technique and developed application shows sufficient and acceptable defense mechanism in huge company networks. We discussed about this is initial study and ongoing research which is compared to the current literature. By the way, this study also shows that non security information such as users mobile experiences could be potential usage to prevent resource exhausting also known as DoS related attacks.'\n",
      " 'Age Estimation from Fingerprints: Examination of the Population in Turkey This paper focuses on a new approach to estimate ages from fingerprints. In the current study, a total number of 500 fingerprints from 10 fingers of 50 Turkish citizens were collected to estimate the ages of the participants from their fingerprints. Their full fingerprints were first taken and then the fingerprints were converted to binary images. Then, a matrix of 1×153600 was achieved from the binary images. Based on these distances, the fingerprint data were classified using KNN classification algorithm. An average success rate of 93.3% was obtained in males aged between 18-24 while 83.0% average success rate was obtained in females in the same age group. The initial results have shown that the proposed new method is very successful in estimating ages from fingerprints. It is expected that the proposed method will find more attentions especially for criminal cases.'\n",
      " 'Diagnosis using incomplete model in fuzzy discrete event system: Application to crisis management This paper presents a novel diagnosis approach for crisis management using fuzzy discrete event system (model). The method exploits the output events and membership value of each active state as input events of the diagnoser (diagnosis module). In our work the choice of fuzzy system representation is justified by the assumption that, during crisis management, the stress and/or impact emotion of the teams involved in crisis management must be taken into account and the evolution of the situation may not necessarily in one active state. The membership value generated by the model can be used for the possible control action during the crisis management.'\n",
      " 'Incremental SVD for Insight into Wind Generation In this paper, we formulate the problem of predicting wind generation as one of streaming data analysis. We want to understand if it is possible to use the weather data in a time window just before the current time to gain insight into how the wind generation might behave in a time interval just after the current time. Specifically, we use a singular value decomposition of the weather data, and how that the number of singular values and the largest singular value can be used to predict the magnitude of the change in the generation in the near future. The analysis uses an incremental algorithm based on a sliding window for reduced computational costs.'\n",
      " 'Transient Characteristics of DC-DC Converter with PID Parameters Selection and Neural Network Control This paper presents a neural network based PID parameter selection control to improve the transient response of dc-dc converters. In the conventional PID control, parameters of it such as proportional, integral, and differential coefficients are selected as fixed parameters to regulate both transient and steady-state characteristics simultaneously as much as possible. The parameter setting of PID control is not optimal for the improvement of transient-state characteristics since the setting needs to satisfy stable steady-state characteristics. Therefore, the parameter selection for different states is widely applicable from the point of view of the improvement of transient response. In this study, we present a novel parameter selection method for PID control based on the load change prediction of neural network to improve the transient response of dc-dc converter. In the presented method, suitable PID parameters are selected with neural network. This neural network is trained to predict the load change from the output voltage of dc-dc converter in advance. From the predicted result of neural network, PID parameters are changed to optimal ones after the load change occurs. Additionally, the reference modification with another neural network, which is trained to modify the reference value of PID control, is also adopted simultaneously to obtain more effective improvement of transient response. From evaluation results, we confirm that our presented method contributes to obtain an effective improvement of the transient response compared to the conventional PID control.'\n",
      " 'Intelligent Crude Oil Price Forecaster We propose two ensemble regression algorithms for forecasting the daily price of crude oil from features extracted from the U.S. Energy Administration and some international news agencies. An ensemble regression model consists of a group of homogeneous regressors with varying parameters, e.g. Linear regression models with different ridge regularization parameters. The first ensemble method called \"recent leader\" picks the individual regressor with least mean square error over recent data. The second model called \"exponentially weighted ensemble\" combines individual regressors in a linear fashion with weights of constituent models decaying exponentially with the mean square error over past predictions. These two methods were tested with linear regression, support vector regression, decision trees and Gaussian processes. Exponentially weighted ensemble with support vector regression had the best performance.'\n",
      " 'Improved Selection of Auxiliary Objectives Using Reinforcement Learning in Non-stationary Environment Efficiency of evolutionary algorithms can be increased by using auxiliary objectives. The method which is called EA+RL is considered. In this method a reinforcement learning (RL) algorithm is used to select objectives in evolutionary algorithms (EA) during optimization. In earlier studies, reinforcement learning algorithms for stationary environments were used in the EA+RL method. However, if behavior of auxiliary objectives change during the optimization process, it can be better to use reinforcement learning algorithms which are specially developed for non-stationary environments. In our previous work we proposed a new reinforcement learning algorithm to be used in the EA+RL method. In this work we propose an improved version of that algorithm. The new algorithm is applied to a non-stationary problem and compared with the methods which were used in other studies. It is shown that the proposed method achieves optimal value more often and obtains higher values of the target objective than the other algorithms'\n",
      " 'A New Algorithm for Adaptive Online Selection of Auxiliary Objectives Consider optimization problems, where a target objective should be optimized. Some auxiliary objectives can be used to obtain the optimum of the target objective in less number of objective evaluations. We call such auxiliary objective a supporting one. Usually there is no prior knowledge about properties of auxiliary objectives, some objectives can be obstructive as well. What is more, an auxiliary objective can be both supporting and obstructive at different stages of the target objective optimization. Thus, an adaptive online method of objective selection is needed. Earlier, we proposed a method for doing that, which is based on reinforcement learning. In this paper, a new algorithm for adaptive online selection of optimization objectives is proposed. The algorithm meets the interface of a reinforcement learning agent, so it can be fit into the previously proposed framework. The new algorithm is applied for solving some benchmark problems with single-objective evolutionary algorithms. Specifically, Leading Ones with OneMax auxiliary objective is considered, as well as the MH-IFF problem. Experimental results are presented. The proposed algorithm outperforms Q-learning and random objective selection on the considered problems.'\n",
      " 'Iterative Hard Thresholding for Keyword Extraction from Large Text Corpora To better understand and analyze text corpora, such as the news, it is often useful to extract keywords that are meaningfully associated with a given topic. A corpus of documents labeled by their topic can be used to approach this as a learning problem. We consider this problem through the lens of statistical text analysis, using bag-of-words frequencies as features for a sparse linear model. We demonstrate, through numerical experiments, that iterative hard thresholding (IHT) is a practical and effective algorithm for keyword-extraction from large text corpora. In fact, our implementation of IHT can quickly analyze more than 800,000 documents, returning keywords comparable to algorithms solving a Lasso problem-formulation, with significantly less computation time. Further, we generalize the analysis of the IHT algorithm to show that it is stable for rank deficient matrices, as those arising from our bag-of-words model often are.'\n",
      " 'A Novel Bayesian Network Based Scheme for Finding the Optimal Solution to Stochastic Online Equi-partitioning Problems A number of intriguing decision scenarios, such as order picking, revolve around partitioning a collection of objects so as to optimize some application specific objective function. In its general form, this problem is referred to as the Object Partitioning Problem (OOP), known to be NP-hard. We here consider a variant of OPP, namely the Stochastic Online Equi-Partitioning Problem (SO-EPP). In SO-EPP, objects arrive sequentially, in pairs. The relationship between the arriving object pairs is stochastic: They belong to the same partition with probability p. From a history of object arrivals, the goal is to predict which objects will appear together in future arrivals. As an additional complication, the partitions of related objects are required to be of equal cardinality. The decision maker, however, is not informed about the true relation between the objects, he is merely observing the stream of object pairs, and has to predict future behavior. Inferring the correct partitioning from historical behavior is thus a significant challenge, which becomes even more difficult when p is unknown. Previously, only heuristic sub-optimal solution strategies have been proposed for SO-EPP. In this paper, we propose the first it optimal solution strategy. In brief, the scheme that we propose, BN-EPP, is founded on a Bayesian Network representation of SO-EPP problems. Based on probabilistic reasoning we are not only able to infer the correct object partitioning with optimal accuracy. We are also able to simultaneously infer p, allowing us to accelerate learning as object pairs arrive. Being optimal, BN-EPP provides superior performance compared to existing state-of-the-art solution schemes. BN-EPP is also highly flexible, being capable of encoding object partitioning constraints. Finally, BN-EPP is parameter free - its performance does not rely on fine tuning any parameters. As a result of these advantages, BN-EPP opens up for significantly improved performance for OOP based applications.'\n",
      " 'Automatic Gender Classification System from Finger 2D: 4D Ratio and Comparison of Successes with Using Different Algorithm High rate of correctness of the information in determining the identity of corpses in mass deaths in such disasters as aircraft, high-speed train or sea accidents and fires, where people are damaged to an extent that they cannot be identified, and the method followed are main elements. In this study, a dataset was formed by taking the index finger, ring finger, height and ages of 67 Turkish men and 56 Turkish women. The dataset was used for identifying the sex of the person and thus, information that could reveal the identity of the information was obtained. LAD Tree algorithm, Naive Bayes algorithm, KNN algorithm and C4.5 algorithm were tried on the datasets. C4.5 algorithm had the highest rate of success in determining sex with a rate of 93%. Therefore, automatic sex classification was made using C4.5 algorithm. Studies revealed that 2D:4D ratio varies in different sexes and races. Moving from these studies, sex was determined from the ratio of index finger to ring finger. When compared with the existing studies in the literature on different races, it was proved that race also can be determined. It was found that left hand provided higher success in finger ratio use in identifying sex compared to the right hand.'\n",
      " 'Dynamic Inclusion of New Event Types in Visual Inspection using Evolving Classifiers In this paper, we are dealing with the automatic inclusion of new event types in visual inspection systems. Within the context of image classification for recognizing \"OK\" and \"not OK\" parts, a certain event can be directly associated with a class, as events are usually independent and disjoint from each other. In this sense, we are dealing with the problem of integrating a new class into the image classifier on-the-fly, once specified on-line by an operator. We are using evolving fuzzy classifiers (EFC), which are relying on fuzzy rule bases and are able to adapt their structure and update their parameters in incremental manner. The novel methodological aspects lie (1.) in appropriate structural changes in the EFC whenever a new class appears and (2.) in the estimation of the expected change in classifier accuracy on the older classes seen before, which is based on an analysis of the expected change in the classifier\\'s decision boundaries. The second point is an important aspect for operators, as they are already familiar to work with established classifiers that have some accuracy in classification. The new concepts will be evaluated on a real-world visual inspection scenario, where the main tasks is to classify event types which may occur on micro-fluidic chips and may lead to the deterioration of their quality.'\n",
      " 'Speeding Learning of Personalized Audio Equalization Audio equalizers (EQs) are perhaps the most commonly used tools used in audio production. The SocialEQ project is a web-based personalized audio equalization system that uses an alternative interface paradigm to the standard approach. Here, the user names a desired effect (e.g. Make the sound \"warm\") and teaches the tool (e.g. An equalizer) what settings make the sound embody the term. Social EQ typically requires 25 ratings to properly personalize the equalization settings. In this paper, we present three methods to improve the speed of generating personalized items (audio settings) so users can be provided personalized EQ curves after rating a much smaller number of examples. These methods can be adapted to any situation where collaborative filtering is desirable, the end products created for users are unique and comparable to each other, but prior users did not rate the same set of examples as the current user. Methods are tested on a data set of 1635 user sessions.'\n",
      " 'A Semi-supervised Clustering Approach for Semantic Slot Labelling Work on training semantic slot labellers for use in Natural Language Processing applications has typically either relied on large amounts of labelled input data, or has assumed entirely unlabelled inputs. The former technique tends to be costly to apply, while the latter is often not as accurate as its supervised counterpart. Here, we present a semi-supervised learning approach that automatically labels the semantic slots in a set of training data and aims to strike a balance between the dependence on labelled data and prediction accuracy. The essence of our algorithm is to cluster clauses based on a similarity function that combines lexical and semantic information. We present experiments that compare different similarity functions for both our semi-supervised setting and a fully unsupervised baseline. While semi-supervised learning expectedly outperforms unsupervised learning, our results show that this effect can be observed based on very few training data instances and that increasing the size of the training data does not lead to better performance, and that lexical and semantic information contribute differently in different domains so that clustering based on both types of information offers the best generalisation.'\n",
      " 'Multimodal Music and Lyrics Fusion Classifier for Artist Identification Humans interact with each other using different communication modalities including speech, gestures and written documents. In the absence of one modality or presence of a noisy modality, other modalities can benefit precision of systems. HCI systems can also benefit from these multimodal communication models for different machine learning tasks. The provision of multiple modalities is motivated by usability, presence of noise in one modality and non-universality of a single modality. Combining multimodal information introduces new challenges to machine learning such as designing fusion classifiers. In this paper we explore the multimodal fusion of audio and lyrics for music artist identification. We compare our results with a single modality artist classifier and introduce new directions for designing a fusion classifier.'\n",
      " \"Machine-Sourced Segmentations vs. Expert-Sourced Segmentations for the Classification of Lung Nodules with Outlier Removal Computer-aided diagnosis systems can provide additional opinions that serve as an aid to radiologists in the early detection of lung nodules. Previous CAD models have relied on radiologist-delineated contours to extract image features and classify lung nodules into semantic ratings. Manually creating these contours can be time-consuming and expensive. This paper proposes a different CAD system based on multiple machine-sourced segmentations that can provide semantic ratings at least as accurate as a panel of experts in order to aid in the diagnostic process. However, the mass production of machine-sourced segmentations may sometimes produce unwanted noise. Therefore, we propose to filter out the bad segmentations by applying an outlier detection algorithm that identifies segmentations that are far away from the majority of the segmentations. Our results are compared to a CAD system based on expert-sourced contours and a reference truth generated by radiologists' semantic ratings. Using the Lung Image Database Consortium dataset, we show that machine-sourced segmentations provide predictions at least as good as expert-sourced segmentations and how outlier removal affects mostly shape-dependent semantic ratings.\"\n",
      " 'Tool Machines with Brains - Touchless Wheel Alignment with Neural Networks This document describes a proof of concept for a new approach for next generation wheel alignment systems. We propose to measure the relevant angels with Kohonen self organizing networks from an image of a heavy precision camera, instead of a projecting system clamped on the wheel. This has the clear advantage, that we do not need to attach a specially designed clamp which holds on to a wheel with mirrors, scales or LEDs. That for the target system will shot a photo from each wheel from a well determined position and calculate the relevant angels from it with Kohonen self organizing neural networks. We compare the utility for several distance measures to retrieve the best association map which determines the necessary coordinates. The system is designed as a learning system that needs a certain amount of training. The training is designed, that it surely converges after a well determined number of runs. We further optimize the training using noisy data. The system is designed for car manufacturers, that need to measure many similar cars on a daily basis'\n",
      " 'Performance Comparison of Major Classical Face Recognition Techniques The goal of this paper is to present a critical comparison of existing classical techniques on recognition of human faces. This paper describes the four major classical face recognition techniques i.e., i) Principal Component Analysis (PCA), ii) Linear Discriminant Analysis (LDA), iii) Discrete Cosine Transform (DCT), and iv) Independent Component Analysis (ICA). Strong and weak features of these techniques are discussed. The paper then provides performance comparison and a generalized discussion of the training requirements for these face recognition techniques. Extensive experimental results with three publicly available databases (ORL, Yale, FERET databases) are provided. Performance comparison of recognizing face images taken under varying facial expressions, varying lighting condition and varying poses are discussed.'\n",
      " 'Assessment of Different Image Clutter Metrics Using Multivariate Analyses and Neurofuzzy System Image processing is the most frequently used technique in computer vision like target detection of monitored target images to recognize background clutter and observed target images. To evaluate the performance of various image processing algorithms, image clutter metrics are very important and useful factors for the better visual conception such as increasing the probability of detection, decreasing the false alarm rate, or a relatively shorter searching time. In this paper, different image clutter metrics such as probability of detection, false alarm rate, and search time, are assessed by the statistical analysis techniques and neurofuzzy systems through applying other statistical image clutter metrics in order to improve the machine visual conception with resolving the machine cognitive constraints for the computer vision.'\n",
      " 'Causal Discovery from Spatio-Temporal Data with Applications to Climate Science Causal discovery algorithms have been used to identify potential cause-effect relationships from observational data for decades. Recently more applications are emerging, for example in climate science, that extend over large spatial domains and require temporal models. This paper first reviews how the causal discovery problem can be set up for such spatiotemporal problems using constraint-based structure learning, then discusses pitfalls we encountered and some solutions we developed. In particular, we consider how to handle temporal and spatial boundaries (which often result in causal sufficiency violations) and discuss the effects of temporal resolution and grid irregularities on the resulting model.'\n",
      " \"Graphical Model Based Approach for Fault Diagnosis of Wind Turbines Wind turbine operation and maintenance costs depend on the reliability of its components. Thus, a critical task is to detect and isolate faults, as fast as possible, and restore optimal operating conditions in the shortest time. In this paper, a machine learning of graphical models approach is proposed for fault diagnosis of wind turbines, in particular pitch system. The role of the latter is to adjust the blade pitch angle by rotating it according to the current wind speed in order to optimize the wind turbine power production. This is achieved by a controller based on blade pitch angles measured by two redundant sensors in each blade. Without the sensor accuracy reading, the controller can be misled and fail to achieve the optimal control strategy according to the current operation conditions. In addition, pitch angle sensors complete failure can lead to dangerous actions of the controller, while fixed or drifted bias of sensor measurements may decrease the controller's efficiency. To better control and overcome these challenges, we propose a methodology that is based on Gaussian acyclic graphical models and the lasso estimate. The methodology has shown the ability to model, and diagnose faults that occur in the pitch system in wind turbines during its normal run and could lead to a fast recovery to the optimal operating conditions.\"\n",
      " 'A Directed Acyclic Graphical Approach and Ensemble Feature Selection for a Better Drug Development Strategy Using Partial Knowledge from KEGG Signalling Pathways In this paper we consider the application of machine learning of graphical models and feature selection for developing better drug-design strategies. The work discussed in this paper is based on utilizing partial prior knowledge available through KEGG signalling pathway database in tan dim with our recent developed ensemble feature selection methods for a better regularisation of the lasso estimate. This work adds an extra layer of previously unseen knowledge in KEGG signalling pathways that embodies infering the underlying connectivity between gene-families implicated in breast cancer in MAPK-signalling pathway in response to application of anti-cancer drugs \"neoadjuvant docetaxel\".'\n",
      " 'Feature Selection Using Gustafson-Kessel Fuzzy Algorithm in High Dimension Data Clustering The performance of objective function-based fuzzy clustering algorithms depends on the shape and the volume of clusters, the initialization of clustering algorithm, the distribution of the data objects, and the number of clusters in the data. Feature selection is also one of the most important issues in high dimension data clustering specifically in bioinformatics, data mining, signal processing etc., where the feature space dimension tends to be very large, making both clustering and classification tasks very difficult. It is evident that the feature subset needed to successfully perform a given clustering and recognition task depends on the discriminatory qualities of the chosen features. We propose a new hybrid approach addressing feature selection, based on informative weights, which takes into account the membership degrees of the features performed by Gustafson-Kessel fuzzy algorithm. The purpose is to efficiently achieve high degree of dimensionality reduction and enhance or maintain predictive accuracy with selected features. The candidate feature subsets are generated by using iterative feature elimination procedure which results in estimation of feature informative weights. We use both supervised and unsupervised methods in order to evaluate the clustering abilities of feature subsets.'\n",
      " 'Coordinate Descent Fuzzy Twin Support Vector Machine for Classification In this paper, we develop a novel coordinate descent fuzzy twin SVM (CDFTSVM) for classification. The proposed CDFTSVM not only inherits the advantages of twin SVM but also leads to a rapid and robust classification results. Specifically, our CDFTSVM has two distinguished advantages: (1) An effective fuzzy membership function is produced for removing the noise incurred by the contaminant inputs. (2) A coordinate descent strategy with shrinking by active set is used to deal with the computational complexity brought by the high dimensional input. In addition, a series of simulation experiments are conducted to verify the performance of the CDFTSVM, which further supports our previous claims.'\n",
      " 'Self-Configuring and Evolving Fuzzy Image Thresholding Every segmentation algorithm has parameters that need to be adjusted in order to achieve good results. Evolving fuzzy systems for adjustment of segmentation parameters have been proposed recently (Evolving fuzzy image segmentation -- EFIS [1]). However, similar to any other algorithm, EFIS too suffers from a few limitations when used in practice. As a major drawback, EFIS depends on detection of the object of interest for feature calculation, a task that is highly application-dependent. In this paper, a new version of EFIS is proposed to overcome these limitations. The new EFIS, called self-configuring EFIS (SC-EFIS), uses available training data to auto-configure the parameters that are fixed in EFIS. As well, the proposed SCEFIS relies on a feature selection process that does not require the detection of a region of interest (ROI).'\n",
      " 'Adaptive Fuzzy Prediction for Automotive Applications Usage Modern automobiles are increasingly complicated machines with an ever-increasing number of features. Understanding how these features work, when to use them, and in general how to make the best use of your vehicle is not a simple task. This research presents an evolving fuzzy system that personalizes the fuzzy membership functions based on individual driving habits. The system was successfully applied to estimate the likelihood of a driver using cruise control based on past usage preferences, current context, and recent driving history. Experimental results show that the proposed fuzzy system can learn the membership functions adaptively according to the driving behavior, and predicts the cruise control usage with high confidence.'\n",
      " 'Learning Multi-valued Biological Models with Delayed Influence from Time-Series Observations Delayed effects are important in modeling biological systems, and timed Boolean networks have been proposed for such a framework. Yet it is not an easy task to design such Boolean models with delays precisely. Recently, an attempt to learn timed Boolean networks has been made in Ribeiro et al 2015 in the framework of learning state transition rules from time-series data. However, this approach still has two limitations: (1) The maximum delay has to be given as input to the algorithm, (2) The possible value of each state is assumed to be Boolean, i.e., twovalued. In this paper, we extend the previous learning mechanism to overcome these limitations. We propose an algorithm to learn multi-valued biological models with delayed influence by automatically tuning the delay. The delay is determined so as to minimally explain the necessary influences. The merits of our approach is then verified on benchmarks coming from the DREAM4 challenge.'\n",
      " \"A Proposal of a Methodological Framework with Experimental Guidelines to Investigate Clustering Stability on Financial Time Series We present in this paper an empirical framework motivated by the practitioner point of view on stability. The goal is to both assess clustering validity and yield market insights by providing through the data perturbations we propose a multi-view of the assets' clustering behaviour. The perturbation framework is illustrated on an extensive credit default swap time series database available online at www.datagrapple.com.\"\n",
      " \"Evaluating Real-Time Anomaly Detection Algorithms \\x96 The Numenta Anomaly Benchmark Much of the world's data is streaming, time-series data, where anomalies give significant information in critical situations, examples abound in domains such as finance, IT, security, medical, and energy. Yet detecting anomalies in streaming data is a difficult task, requiring detectors to process data in real-time, not batches, and learn while simultaneously making predictions. There are no benchmarks to adequately test and score the efficacy of real-time anomaly detectors. Here we propose the Numenta Anomaly Benchmark (NAB), which attempts to provide a controlled and repeatable environment of open-source tools to test and measure anomaly detection algorithms on streaming data. The perfect detector would detect all anomalies as soon as possible, trigger no false alarms, work with real-world time-series data across a variety of domains, and automatically adapt to changing statistics. Rewarding these characteristics is formalized in NAB, using a scoring algorithm designed for streaming data. NAB evaluates detectors on a benchmark dataset with labeled, real-world time-series data. We present these components, and give results and analyses for several open source, commercially-used algorithms. The goal for NAB is to provide a standard, open source framework with which the research community can compare and evaluate different algorithms for detecting anomalies in streaming data.\"\n",
      " 'A Study of the Use of Complexity Measures in the Similarity Search Process Adopted by kNN Algorithm for Time Series Prediction In the last two decades, with the rise of the Data Mining process, there is an increasing interest in the adaptation of Machine Learning methods to support Time Series non-parametric modeling and prediction. The non-parametric temporal data modeling can be performed according to local and global approaches. The most of the local prediction data strategies are based on the k-Nearest Neighbor (kNN) learning method. In this paper we propose a modification of the kNN algorithm for Time Series prediction. Our proposal differs from the literature by incorporating three techniques for obtaining amplitude and offset invariance, complexity invariance, and treatment of trivial matches. We evaluate the proposed method with six complexity measures, in order to verify the impact of these measures in the projection of the future values. Besides, we face our method with two Machine Learning regression algorithms. The experimental comparisons were performed using 55 data sets, which are available at the ICMC-USP Time Series Prediction Repository. Our results indicate that the developed method is competitive and the use of a complexity-invariant distance measure generally improves the predictive performance.'\n",
      " 'The Influence of Sample Reconstruction on Stock Trend Prediction via NARX Neural Network In our study, through the established NARX neural network model, the sample data of stock AAPL in NASDAQ from 2006/01/01 to 2015/01/01 are utilized for training. The results show that under the same sampling frequency, with the increase of MA period, the trend of volatility becomes lower with obvious longer time delay, which will help to predict the trend of movement. In addition, through the use of reconstructed data containing the trend information as training sample, it has significantly reduced the prediction error, which is 16.29% lower than using daily training sample and 16.90% lower than using weekly training sample. The outputs directly reflect the probability of trend movement at every time point in stock price. It also improves the generalization ability of NARX model, so as to predict the stock trend change at a certain time. It has successfully estimated the possibility of buying and selling points, which provides the necessary theoretical basis on how to determine the stock trading points.'\n",
      " 'Statistical Fault Localization Based on Importance Sampling This paper presents a novel probabilistic approach for the fault localization challenge based on importance sampling. The iterative approach utilizes test results and execution profiles to estimate the likelihood of suspiciousness of program statements. Over a few iterations of probability updates and sampling, the procedure directs its attention towards those statements that are more likely to be faulty. The proposed approach is designed to be more sensitive to failing test cases in comparison to passing test cases. The effectiveness of the proposed stochastic approach is evaluated through two case studies and the results are compared against other popular fault localization methods.'\n",
      " \"Statistical Learning via Manifold Learning A new geometrically motivated method is proposed for solving the non-linear regression task consisting in constructing a predictive function which estimates an unknown smooth mapping f from q-dimensional inputs to m-dimensional outputs based on a given 'input-output' training pairs. The unknown mapping f determines q-dimensional Regression manifold M(f) consisting of all the (q+m)-dimensional 'input-output' vectors. The manifold is covered by a single chart, the training data set determines a manifold-valued sample from this manifold. Modern Manifold Learning technique is used for constructing the certain estimator M* of the Regression manifold from the sample which accurately approximates the Regression manifold. The proposed method called Manifold Learning Regression (MLR) finds the predictive function fMLR to ensure an equality M(fMLR) = M*. The MLR estimates also the m×q Jacobian matrix of the mapping f.\"\n",
      " 'Topic Novelty Detection Using Infinite Variational Inverted Dirichlet Mixture Models We propose model-based inference for topic novelty detection using a non-parametric Bayesian probability model. The probability model is a Dirichlet process mixture of inverted Dirichlet distributions which can be viewed as an infinite mixture model. The inference is based on variational Bayes deployed using approximate conjugate priors to the inverted Dirichlet. Detailed experimental study demonstrates the merits of our approach and shows that it gives good description of the data.'\n",
      " 'Evaluating the Uncertainty of a Bayesian Network Query Response by Using Joint Probability Distribution Bayesian network is a powerful tool to represent patterns inside past data. It can be used to predict future by calculating the posterior probability of future events. Machine learning techniques that can construct a Bayesian network from past data automatically are well developed in recent years. If we consider past data as a sampling set from an original probabilistic distribution, the \"learning\" process is actually trying to reproduce the original probabilistic distribution from the sampling set. Therefore, the finiteness of size of sampling set will bring uncertainties to the reproduced parameters of constructed Bayesian network. When the constructed Bayesian network is used to predict future, the uncertainties of reproduced parameters will be transferred to the uncertainty of query response. Here, the query response is the posterior probability that we are interested in. Evaluating the uncertainty of query response is critical to some strict industrial applications. Previous researches have proposed a method to evaluate the uncertainty. The consequence is shown as a variance of the query response. However, the conventional method need to work together with the bucket elimination, an exact inference method. Therefore, the conventional method can not deal with large Bayesian networks that used in real applications because of its calculation cost. We proposed a new approach to calculate the uncertainty of query responses by using joint probability distribution in this research. The proposed method can work with any inference method. Therefore, it can give an approximate evaluation even when the Bayesian network is large by using an approximate inference method. To investigate the accuracy of our proposed method, six well used public Bayesian networks are used as test cases. By comparing the approximate results with the exact results, an average error of -13.60% is got.'\n",
      " 'Nonparametric Bayesian Modeling for Automated Database Schema Matching The problem of merging databases arises in many government and commercial applications. Schema matching, a common first step, identifies equivalent fields between databases. We introduce a schema matching framework that builds nonparametric Bayesian models for each field and compares them by computing the probability that a single model could have generated both fields. Our experiments show that our method is more accurate and faster than the existing instance-based matching algorithms in part because of the use of nonparametric Bayesian models.'\n",
      " \"Performance Analysis of Majority Vote Combiner for Multiple Classifier Systems Combining rules in Multiple Classifier Systems (MCS) play a central role in shaping their performance (classification error probability). Many theoretical works are developed to predict the performance using different combining rules. Some of the developed works assumed that classifiers' outputs are independent, however in practice an ensemble of classifiers shows dependent behavior between each other. In this work, a theoretical model is derived for estimating the misclassification error probability of MCS based on majority vote combiner. In the derivation, we assumed that each classifier produces at its output an estimation of the posterior class probability that has a Gaussian distribution. In addition, we assumed that each classifier has two classes, and the outputs of classifiers are dependent and identically distributed. We validated our model using computer simulations. Results show that the ensemble performance is highly sensitive to class variance while exhibits a smoother behavior against class mean. Also, results show that as the correlation among classifiers' outputs increases, the probability of classification error degrades exponentially. The trend continues until the performance reaches the behavior of a single classifier regardless of the number of base classifiers used in the ensemble. The proposed model provides a better understanding of the behavior of majority vote combiner in MCS.\"\n",
      " 'The Effect of Dataset Size on Training Tweet Sentiment Classifiers Using automated methods of labeling tweet sentiment, large volumes of tweets can be labeled and used to train classifiers. Millions of tweets could be used to train a classifier, however, doing so is computationally expensive. Thus, it is valuable to establish how many tweets should be utilized to train a classifier, since using additional instances with no gain in performance is a waste of resources. In this study, we seek to find out how many tweets are needed before no significant improvements are observed for sentiment analysis when adding additional instances. We train and evaluate classifiers using C4.5 decision tree, Naïve Bayes, 5 Nearest Neighbor and Radial Basis Function Network, with seven datasets varying from 1000 to 243,000 instances. Models are trained using four runs of 5-fold cross validation. Additionally, we conduct statistical tests to verify our observations and examine the impact of limiting features using frequency. All learners were found to improve with dataset size, with Naïve Bayes being the best performing learner. We found that Naïve Bayes did not significantly benefit from using more than 81,000 instances. To the best of our knowledge, this is the first study to investigate how learners scale in respect to dataset size with results verified using statistical tests and multiple models trained for each learner and dataset size. Additionally, we investigated using feature frequency to greatly reduce data grid size with either a small increase or decrease in classifier performance depending on choice of learner.'\n",
      " 'Complex Decomposition of the Negative Distance Kernel A Support Vector Machine (SVM) has become a very popular machine learning method for text classification. One reason for this relates to the range of existing kernels which allow for classifying data that is not linearly separable. The linear, polynomial and RBF (Gaussian Radial Basis Function) kernel are commonly used and serve as a basis of comparison in our study. We show how to derive the primal form of the quadratic Power Kernel (PK) -- also called the Negative Euclidean Distance Kernel (NDK) -- by means of complex numbers. We exemplify the NDK in the framework of text categorization using the Dewey Document Classification (DDC) as the target scheme. Our evaluation shows that the power kernel produces F-scores that are comparable to the reference kernels, but is -- except for the linear kernel -- faster to compute. Finally, we show how to extend the NDK-approach by including the Mahalanobis distance.'\n",
      " 'A Family of Chisini Mean Based Jensen-Shannon Divergence Kernels Jensen-Shannon divergence is an effective method for measuring the distance between two probability distributions. When the difference between these two distributions is subtle, Jensen-Shannon divergence does not provide adequate separation to draw distinctions from subtly different distributions. We extend Jensen-Shannon divergence by reformulating it using alternate operators that provide different properties concerning robustness. Furthermore, we prove a number of important properties for this extension: the lower limits of its range, and its relationship to Shannon Entropy and Kullback-Leibler divergence. Finally, we propose a family of new kernels, based on Chisini mean Jensen-Shannon divergence, and demonstrate its utility in providing better SVM classification accuracy over RBF kernels for amino acid spectra. Because spectral methods capture phenomenon at subatomic levels, differences between complex compounds can often be subtle. While the impetus behind this work began with spectral data, the methods are generally applicable to domains where subtle differences are important.'\n",
      " 'Online One-Class SVMs with Active-Set Optimization for Data Streams A great advantage of support vector machines (SVMs) is its capability to learn decision borders, represented by a set of particular data points called margin support vectors. The real-time or nearly real-time online learning and detection from data streams poses stringent time and space constraints for the learner. We consider solving online one-class SVMs with an active-set method for quadratic programming (QP). At each iteration, the problem size is the size of the estimated support vectors so far. Active-set programming has the nice property that the solution of a previous problem can serve as a warm start of the next and computation time can thereby be greatly reduced. In general, finding a good warm-start point is difficult. We propose a method to find a good warm start by exploiting the structure of the SVM optimization problem.'\n",
      " 'Example-Specific Density Based Matching Kernels for Scene Classification Using Support Vector Machines In this paper, we propose the example-specific density based matching kernel (ESDMK) for classification of scene images represented as sets of local feature vectors. The proposed kernel is computed between the pair of examples, represented as sets of local feature vectors, by matching the estimates of example-specific densities computed at every local feature vector in those two examples. In this work, the number of local feature vectors of an example among the K nearest neighbors of a local feature vector is considered as an estimate of the example-specific density. The minimum of the two example-specific densities, one for each example, at a local feature vector is considered as the matching score. The ESDMK is then computed as the sum of the matching score computed at every local feature vector in a pair of examples. We also propose the spatial ESDMK (SESDMK) to include spatial information present in the scene images while matching the pair of scene images. Each of the scene images is divided spatially into a fixed number of regions. Then the SESDMK is computed as a combination of region specific ESDMKs that match the corresponding regions. We study the performance of the support vector machine (SVM) based classifiers using the proposed ESDMKs for scene classification and compare with that of the SVM-based classifiers using the state-of-the-art kernels for sets of local feature vectors.'\n",
      " 'Medical Image Classification via SVM Using LBP Features from Saliency-Based Folded Data Good results on image classification and retrieval using support vector machines (SVM) with local binary patterns (LBPs) as features have been extensively reported in the literature where an entire image is retrieved or classified. In contrast, in medical imaging, not all parts of the image may be equally significant or relevant to the image retrieval application at hand. For instance, in lung x-ray image, the lung region may contain a tumour, hence being highly significant whereas the surrounding area does not contain significant information from medical diagnosis perspective. In this paper, we propose to detect salient regions of images during training and fold the data to reduce the effect of irrelevant regions. As a result, smaller image areas will be used for LBP features calculation and consequently classification by SVM. We use IRMA 2009 dataset with 14,410 xray images to verify the performance of the proposed approach. The results demonstrate the benefits of saliency-based folding approach that delivers comparable classification accuracies with state-of-the-art but exhibits lower computational cost and storage requirements, factors highly important for big data analytics.'\n",
      " 'SMS Spam Filtering Through Optimum-Path Forest-Based Classifiers In the past years, SMS messages have shown to be a profitable revenue to the cell-phone industries, being one of the most used communication systems to date. However, this very same scenario has led spammers to concentrate their attentions into spreading spam messages through SMS, thus achieving some success due to the lack of proper tools to cope with this problem. In this paper, we introduced the Optimum-Path Forest classifier to the context of spam filtering in SMS messages, as well as we compared it against with some state-of-the-art supervised pattern recognition techniques. We have shown promising results with an user-friendly classifier, which requires minimum user interaction and less knowledge about the dataset.'\n",
      " 'TubeSpam: Comment Spam Filtering on YouTube The profitability promoted by Google in its brand new video distribution platform YouTube has attracted an increasing number of users. However, such success has also attracted malicious users, which aim to self-promote their videos or disseminate viruses and malwares. Since YouTube offers limited tools for comment moderation, the spam volume is shockingly increasing which lead owners of famous channels to disable the comments section in their videos. Automatic comment spam filtering on YouTube is a challenge even for established classification methods, since the messages are very short and often rife with slangs, symbols and abbreviations. In this work, we have evaluated several top-performance classification techniques for such purpose. The statistical analysis of results indicate that, with 99.9% of confidence level, decision trees, logistic regression, Bernoulli Naive Bayes, random forests, linear and Gaussian SVMs are statistically equivalent. Based on this, we have also offered the TubeSpam - an accurate online system to filter comments posted on YouTube.'\n",
      " \"Optimizing Attack Surface and Configuration Diversity Using Multi-objective Reinforcement Learning Minimizing the attack surface of a system and introducing diversity into a system are two effective ways to improve system security. However, determining how to include diversity in a system without increasing the attack surface more than necessary is a difficult problem, requiring knowledge about the system characteristics, operating environment, and available permutations that is generally not available prior to system deployment. We propose viewing a system's components, interfaces, and communication channels as a set of states and actions that can be analyzed using a sequential decision making process, and using a multi-objective reinforcement learning algorithm to learn a set of policies that minimize a system's attack surface and execute those policies to obtain configuration diversity while a system is operating. We describe a methodology for designing a system such that its components and behaviors can be translated into a multi-objective Markov Decision Process, demonstrate the use of multi-objective reinforcement learning to learn a set of optimal policies using three different multi-objective reinforcement learning algorithms in the context of an online file sharing application, and show that our multi-objective temporal difference afterstate algorithm outperforms the alternatives for the example problem.\"\n",
      " 'A Review of Machine Learning Solutions to Denial-of-Services Attacks in Wireless Sensor Networks Wireless sensor networks (WSNs) are used in various fields where remote data collection is necessary, such as environment and habitat monitoring, military applications, smart homes, traffic control, and health monitoring etc. Since WSNs play a crucial role in various domains and the sensors are constrained by resources, they are vulnerable to different types of attacks. One of the main attack types that threaten WSNs is Denial-of-Service (DoS) attacks. DoS attacks can be carried out at various layers of the network architecture. In this paper, we review the DoS attacks at each layer of TCP/IP protocol stack. Among them we focus on the network layer attacks because they are more diverse than other layer attacks. We review a number of studies proposing machine learning solutions pertaining to network layer DoS attacks in WSNs. We also provide some comparative conclusions to aid researchers studying in this field.'\n",
      " 'A Hybrid Method for Intrusion Detection Intrusion Detection Systems (IDSs) are used to detect malicious actions on information systems such as computing and networking systems. Abnormal behaviors or activities on the network systems could be detected by security systems. But, conventional security systems such as anti-virus and firewall cannot be successful in many malicious actions. To overcome this problem, better and more intelligent IDS solutions are required. In this study, a hybrid approach was proposed to use to detect network attacks. Genetic Algorithm (GA) and K-Nearest Neighbor (KNN) methods were combined to model and detect the attacks. KNN was employed to classify the attacks and GA was used to select k neighbors of an attack sample. This hybrid system was first applied in intrusion detection field. The system provides advantages such as, decreasing dependency of full training data set and providing plausible solution for intrusion detection. The results showed that the proposed system provides better results than single system.'\n",
      " 'Scalable Learning of Entity and Predicate Embeddings for Knowledge Graph Completion Knowledge Graphs (KGs) are a widely used formalism for representing knowledge in the Web of Data. We focus on the problem of link prediction, i.e. predicting missing links in large knowledge graphs, so to discover new facts about the world. Representation learning models that embed entities and relation types in continuous vector spaces recently were used to achieve new state-of-the-art link prediction results. A limiting factor in these models is that the process of learning the optimal embedding vectors can be really time-consuming, and might even require days of computations for large KGs. In this work, we propose a principled method for sensibly reducing the learning time, while converging to more accurate link prediction models. Furthermore, we employ the proposed method for training and evaluating a set of novel and scalable models. Our extensive evaluations show significant improvements over state-of-the-art link prediction methods on several datasets.'\n",
      " 'Measuring and Modelling Delays in Robot Manipulators for Temporally Precise Control Using Machine Learning Latencies and delays play an important role in temporally precise robot control. During dynamic tasks in particular, a robot has to account for inherent delays to reach manipulated objects in time. The different types of occurring delays are typically convoluted and thereby hard to measure and separate. In this paper, we present a data-driven methodology for separating and modelling inherent delays during robot control. We show how both actuation and response delays can be modelled using modern machine learning methods. The resulting models can be used to predict the delays as well as the uncertainty of the prediction. Experiments on two widely used robot platforms show significant actuation and response delays in standard control loops. Predictive models can, therefore, be used to reason about expected delays and improve temporal accuracy during control. The approach can easily be used on different robot platforms.'\n",
      " 'Metabolic Profiling of 1H NMR Spectra in Chronic Kidney Disease with Local Predictive Modeling Metabolic profiling, the study of changes in the concentration of the metabolites in the organism induced by biological differences within subpopulations, has to deal with a very large amount of complex data. It therefore requires the use of powerful data processing and machine learning methods. To overcome over-fitting, a common concern in metabolic profiling where the number of features is often much larger than the number of observations, many predictive analyses combined dimension reduction techniques with multivariate predictive linear modeling. Moreover, they built a global model that identifies biomarkers predictive of the output of interest giving their overall trend variations. However, this fails to capture local biological phenomena underlying subgroups of subjects. More recently, local exploration methods based on decision trees approaches have been applied in metabolomics but they only explore random parts of the feature space. In this study, we used a supervised rule-mining algorithm that locally and exhaustively explores the feature space to predict chronic kidney disease (CDK) stages based on proton Nuclear Magnetic Resonance (1H NMR) data. From the discriminant subregions obtained with this exploration, we extracted local features and learned a L2-regularized Logistic regression (L2LR) classifier. We compared the resulting local predictive model with a standard one, combining classical univariate supervised feature selection techniques with a L2LR, and a model mixing both global and local features. Results show that the local predictive model is more powerful in terms of predictive performance than the mixed and global models. Additionally, it gives key insights into biological variations specific to subgroups of subjects.'\n",
      " 'Predicting Churn of Expert Respondents in Social Networks Using Data Mining Techniques: A Case Study of Stack Overflow In Q&A social networks, the few respondents that answer most of the questions are an asset to that network. Being able to predict the churn of these expert respondents will enable the owners of such network put things in place in order to keep them. In this paper, we predicted the churn of expert respondents in Stack Overflow. We identified experts based on the InDegree of the respondents and the value of the incentives earned by these experts from the questions they have answered in the past. Using four data mining techniques: logistic regression, neural networks, support vector machines and random forests, we predicted user churn and evaluated our results with four evaluation metrics: percentage correctly classified, area under receiver operating characteristic curve, precision and recall. Of the four data mining algorithms, random forests performed best with PCC of 76%, ROC area of 0.82, precision of 0.76 and recall of 0.77.'\n",
      " 'Predictable Feature Analysis Every organism in an environment, whether biological, robotic or virtual, must be able to predict certain aspects of its environment in order to survive or perform whatever task is intended. It needs a model that is capable of estimating the consequences of possible actions, so that planning, control, and decision-making become feasible. For scientific purposes, such models are usually created in a problem specific manner using differential equations and other techniques from control-and system-theory. In contrast to that, we aim for an unsupervised approach that builds up the desired model in a self-organized fashion. Inspired by Slow Feature Analysis (SFA), our approach is to extract subsignals from the input, that behave as predictable as possible. These \"predictable features\" are highly relevant for modeling, because predictability is a desired property of the needed consequence-estimating model by definition. In our approach, we measure predictability with respect to a certain prediction model. We focus here on the solution of the arising optimization problem and present a tractable algorithm based on algebraic methods which we call Predictable Feature Analysis (PFA). We prove that the algorithm finds the globally optimal signal if this signal can be predicted with low error. To deal with cases where the optimal signal has a significant prediction error, we provide a robust, heuristically motivated variant of the algorithm and verify it empirically. Additionally, we give formal criteria a prediction model must meet to be suitable for measuring predictability in the PFA setting and also provide a suitable default model along with a formal proof that it meets these criteria.'\n",
      " 'Speaker Identification in Medical Simulation Data Using Fisher Vector Representation We present a robust speaker identification algorithm that uses effective features based on Fisher Vector (FV) representations. First, low-level spectral features are extracted from the training data. Next, we model the data (in the spectral feature space) by a mixture of Gaussian components. Then, we construct FV descriptors based on the deviation of the features from the Gaussian components. We analyze the FV feature representations on speech data with two common classifiers: K-nearest neighbor classifier (KNN) and support vector machines (SVM). The proposed approach is evaluated using audio data sets recorded to simulate medical crises. We show that the proposed FV feature representation approach achieves a significant improvement when compared to the state-of-art methods.'\n",
      " 'A Machine Learning Approach to False Alarm Detection for Critical Arrhythmia Alarms High false alarm rates in Intensive Care Unit (ICU) is a common problem that leads to alarm desensitization -- a phenomenon called alarm fatigue. Alarm fatigue can cause longer response time or missing of important alarms. In this work, we propose a methodology to identify false alarms generated by ICU bedside monitors. The novelty in our approach lies in the extraction of 216 relevant features to capture the characteristics of all alarms, from both arterial blood pressure (ABP) and electrocardiogram (ECG) signals. Our multivariate approach mitigates the imprecision caused by existing heartbeat/peak detection algorithms. Unlike existing methods on ICU false alarm detection, our approach does not require separate techniques for different types of alarms. The experimental results show that our approach can achieve high accuracy on false alarm detection, and can be generalized for different types of alarms.'\n",
      " 'Detecting Credit Card Fraud Using Periodic Features When constructing a credit card fraud detection model, it is very important to extract the right features from transactional data. This is usually done by aggregating the transactions in order to observe the spending behavioral patterns of the customers. In this paper we propose to create a new set of features based on analyzing the periodic behavior of the time of a transaction using the von Mises distribution. Using a real credit card fraud dataset provided by a large European card processing company, we compare state-of-the-art credit card fraud detection models, and evaluate how the different sets of features have an impact on the results. By including the proposed periodic features into the methods, the results show an average increase in savings of 13%. The aforementioned card processing company is currently incorporating the methodology proposed in this paper into their fraud detection system.'\n",
      " \"Classification of Evolving Data Streams with Infinitely Delayed Labels The majority of evolving data streams classification algorithms assume that the actual labels of the predicted examples are readily available without any time delay just after a prediction is made. However, given the high label costs, dependence of an expert, limitations in data transmission or even restrictions imposed by the problem's nature, there is a large number of real-world applications in which the availability of actual labels is infinitely delayed (never available). In these cases, it is necessary the use of algorithms that does not follow the traditional process of monitoring the error rate to detect changes in data distribution and uses the most recent labeled data to update the classification model. In this paper, we propose the method MClassification to classify evolving data streams with infinitely delayed labels. Our method is inspired on the use of Micro-Cluster representation from online clustering algorithms. Considering the presence of incremental drifts, our approach uses a distance-based strategy to maintain the Micro-Clusters' positions updated. An evaluation in several synthetic and real data shows that MClassification achieves competitive accuracy results to state-of-the-art methods and adequate computational cost. The main advantage of the proposed method is the absence of critical parameters that require user's prior knowledge, as occurs with rival methods.\"\n",
      " 'Sparse Temporal Difference Learning via Alternating Direction Method of Multipliers Recent work in off-line Reinforcement Learning has focused on efficient algorithms to incorporate feature selection, via l1-regularization, into the Bellman operator fixed-point estimators. These developments now mean that over-fitting can be avoided when the number of samples is small compared to the number of features. However, it remains unclear whether existing algorithms have the ability to offer good approximations for the task of policy evaluation and improvement. In this paper, we propose a new algorithm for approximating the fixed-point based on the Alternating Direction Method of Multipliers (ADMM). We demonstrate, with experimental results, that the proposed algorithm is more stable for policy iteration compared to prior work. Furthermore, we also derive a theoretical result that states the proposed algorithm obtains a solution which satisfies the optimality conditions for the fixed-point problem.'\n",
      " 'Transfer Learning of Air Combat Behavior Machine learning techniques can help to automatically generate behavior for computer generated forces inhabiting air combat training simulations. However, as the complexity of scenarios increases, so does the time to learn optimal behavior. Transfer learning has the potential to significantly shorten the learning time between domains that are sufficiently similar. In this paper, we transfer air combat agents with experience fighting in 2-versus-1 scenarios to various 2-versus-2 scenarios. The performance of the transferred agents is compared to that of agents that learn from scratch in the 2v2 scenarios. The experiments show that the experience gained in the 2v1 scenarios is very beneficial in the plain 2v2 scenarios, where further learning is minimal. In difficult 2v2 scenarios transfer also occurs, and further learning ensues. The results pave the way for fast generation of behavior rules for air combat agents for new, complex scenarios using existing behavior models.'\n",
      " \"Integrating Active Learning with Supervision for Crowdsourcing Generalization With various online crowdsourcing platforms, it is easy to collect multiple labels for the same examples from the crowd. Consensus integration algorithms can infer the estimated ground truths from the multiple label sets of these crowdsourcing datasets. However, it couldn't be avoided that these integrated (estimated) labels still contain noises. In order to further improve the performance of a model learned from data with these integrated labels, we propose an active learning framework to further improve the data quality, such that to improve the model quality, through acquiring limited true labels from experts (the oracle). We further investigate two active learning strategies in terms of two uncertainty measures (i.e., CLUE and MUE) within the active learning framework. From our experimental results on eight simulation crowdsourcing datasets and four real-world crowdsourcing datasets with three popular consensus integration algorithms, we draw several conclusions as follows. (i) Our active learning framework with the input from the oracle significantly improves the generalization ability of the model learned from crowdsourcing data. (ii) Our two active learning strategies outperform a random active learning strategy.\"\n",
      " 'Active Information Retrieval for Linking Twitter Posts with Political Debates Users of microblogging social networks produce millions of short messages every day. Retrieving relevant information to a particular event from this sheer volume of data is not a trivial task. In this paper, we present a framework for the retrieval of Twitter posts that are relevant to a set of political debates. Our main contribution is the proposal of a set of strategies for involving the user in the retrieval process, so that by presenting to her meaningful posts to be labeled, the method achieves a noticeably higher accuracy. The correct retrieval or labeling could be provided by an external information source such as a domain expert, or simulated with an oracle. A key aspect of active retrieval methods is to request the labels of the instances that help improve the retrieval accuracy the most, while keeping the number of labeling requests to a minimum. The proposed strategies for selecting labeling requests make use of the textual content of tweets and their structural information. The experimental results show the advantages of the proposed methods and the effectiveness of the selection strategies for involving the user in the retrieval process.'\n",
      " 'A Highly Distributable Computational Framework for Fast Cloud Data Retrieval Unlike the existing relational, hierarchical and object-oriented schemes, associative models can analyze data in similar ways to which our brain links information. Such interactions when implemented in voluminous data clouds can assist in searching for overarching relations in complex and highly distributed data sets with speed and accuracy. In this paper, a different perspective of data recognition will be considered. Rather than looking at conventional approaches, such as statistical computations and deterministic learning schemes, this paper will be focusing on distributed processing approach for scalable data recognition and processing through applying an access scheme that will enable fast data retrieval across multiple records and data segments associatively, utilizing a parallel approach. Doing so will yield a new form of databaselike functionality that can scale up or down over the available infrastructure without interruption or degradation, dynamically and automatically. In our proposed model, data records are treated as patterns. As a result, data storage and retrieval is performed using a distributed pattern recognition approach that is implemented through the integration of loosely-coupled computational networks, followed by a divide-and-distribute approach that facilitates distribution of these networks within the cloud dynamically.'\n",
      " 'Online Learning Algorithm for Collective LDA Collective Latent Dirichlet Allocation (C-LDA) is proposed as an extension of LDA to simultaneously model multiple corpora from different domains in order to overcome bias of individual corpus. However, with large volume of document collections from various sources, it becomes challenging to achieve fast convergence for C-LDA. The high time complexity of C-LDA limits its application to real-world tasks. Luckily, online learning has shown promise for speeding up the convergence of LDA. In this paper, we propose to explore online learning for collective LDA (OVCLDA). We first develop an efficient variational inference algorithm for collective LDA and then extend it to the online learning framework. We perform experiments with various real-world corpora. Experimental results have shown that OVCLDA can learn comparable topics with C-LDA and better than Online LDA, and achieves comparable computational efficiency with Online LDA and is much more efficient than C-LDA.'\n",
      " 'Automatic Topic Labeling Using Ontology-Based Topic Models Topic models, which frequently represent topics as multinomial distributions over words, have been extensively used for discovering latent topics in text corpora. Topic labeling, which aims to assign meaningful labels for discovered topics, has recently gained significant attention. In this paper, we argue that the quality of topic labeling can be improved by considering ontology concepts rather than words alone, in contrast to previous works in this area, which usually represent topics via groups of words selected from topics. We have created: (1) a topic model that integrates ontological concepts with topic models in a single framework, where each topic and each concept are represented as a multinomial distribution over concepts and over words, respectively, and (2) a topic labeling method based on the ontological meaning of the concepts included in the discovered topics. In selecting the best topic labels, we rely on the semantic relatedness of the concepts and their ontological classifications. The results of our experiments conducted on two different data sets show that introducing concepts as additional, richer features between topics and words and describing topics in terms of concepts offers an effective method for generating meaningful labels for the discovered topics.'\n",
      " 'Investigating Eating Behaviours Using Topic Models Chronic conditions, such as diabetes and obesity are related to quality of diet. However, current research findings are conflicting with regards to the impact of snacking on diet quality. One reason for this is the lack of a clear definition of a snack or a meal. This paper presents a novel approach to understanding how foods are grouped together in eating events using a machine learning algorithm, topic models. Approaches for applying topic models to a nutrition application are discussed. A topic model is implemented for the UK National Diet and Nutrition Survey Rolling Programme dataset. The results demonstrate that the topics found are representative of typical eating events in terms of food group content and associated time of day. There is a strong potential for topic models to reveal useful patterns in food diary data that have not previously been considered.'\n",
      " 'Fine-Grained Opinion Extraction with Markov Logic Networks Markov Logic Networks, a joint inference framework that combines logical and probabilistic representations, enable effective modeling of the dependencies that exist between different instances of a data sample. While its ability to capture relational dependencies makes it an ideal framework for predicting the structures inherent in many natural language processing (NLP) tasks, it is arguably underused in NLP, especially in comparison to other joint inference frameworks such as integer linear programming. In this paper, we present the first Markov logic model for the NLP task of fine-grained opinion extraction that exploits a factuality lexicon. When evaluated on a standard evaluation corpus, our approach surpasses a state-of-the-art approach in performance.'\n",
      " 'The Effect of Clustering on Data Privacy The data obtained by various organizations provide opportunities for generating solutions in the future. It is essential that, the accurate data must be sharable with research communities and scientists in order to improve quality of life. However, accurate records of personal data include sensitive information about individuals. Hence sharing these records without applying any anonymization criteria paves the way for disclosure of personal privacy. In an effort to protect personal privacy, Privacy-Preserving Data Mining (PPDM) and Privacy-Preserving Data Publishing (PPDP) approaches have been studied extensively. Numerous works have been dedicated to diversifying techniques for de-identification or anonymization of identifiable datasets, but there is an important trade-off between data loss and data privacy. While original data anonymized, it exposed to information loss. In order to minimize information loss, the anonymization algorithms discard keeping diversity. In this study, we proposed an approach that uses a clustering algorithm as a pre-process for privacy preserving methods to improve the diversity of anonymized data. In addition, the effect of clustering on anonymization was evaluated by using original and clustered form of a real world dataset. The results are evaluated with the aspect of usability in scientific works and it was observed that a clustering algorithm and an affective anonymization algorithm must be used in privacy preservation approaches in order to keep diversity of the original datasets.'\n",
      " \"Detection of SSH Brute Force Attacks Using Aggregated Netflow Data The SSH Brute force attack is one of the most prevalent attacks in computer networks. These attacks aim to gain ineligible access to users' accounts by trying plenty of different password combinations. The detection of this type of attack at the network level can overcome the scalability issue of host-based detection methods. In this paper, we provide a machine learning approach for the detection of SSH brute force attacks at the network level. Since extracting discriminative features for any machine learning task is a fundamental step, we explain the process of extracting discriminative features for the detection of brute force attacks. We incorporate domain knowledge about SSH brute force attacks as well as the analysis of a representative collection of the data to define the features. We collected real SSH traffic from a campus network. We also generated some failed login data that a legitimate user who has forgotten his/her password can produce as normal traffic that can be similar to the SSH brute force attack traffic. Our inspection on the collected brute force Netflow data and the manually produced SSH failed login data showed that the Netflow features are not discriminative enough to discern brute force traffic from the failed login traffic produced by a legitimate user. We introduced an aggregation of Netflows to extract the proper features for building machine learning models. Our results show that the models built upon these features provide excellent performances for the detection of brute force attacks.\"\n",
      " 'A Machine-Learning Based Approach for Measuring the Completeness of Online Privacy Policies Web site privacy policies are often long, difficult to understand, and contain incomplete information. Consequently, users tend not to read the privacy policies, thus putting their privacy at risk. This paper describes an automated approach for assisting users to evaluate online privacy policies based on completeness. The term completeness refers to the presence of 8 sections in an online privacy policy that have been recognized as helpful in establishing the transparency of a privacy policy. Given a new online privacy policy, the proposed system employs a machine-learning based approach to predict a completeness score for the privacy policy. This score can then be used by the user to assess the risk to their privacy.'\n",
      " 'Combating Comment Spam with Machine Learning Approaches The feature of posting comments enables websites visitors (e.g., Youtube and Amazon) to interact and contribute to the posted content by adding comments. The fact that such comments are becoming part of the website content so that many visitors read them and that such comments are usually unvetted make them attractive to spammers for the purposes of advertising, spreading malware, phishing attacks, or spreading political or religious views. Due to large volume of comment spam, using manual filtration and vetting is unpractical and hence automatic spam detection techniques play a de-facto role in fighting spam content. In this paper, we propose and develop a comment spam detection mechanism that can be deployed as a browser plugin for inspecting the Document Object Model (DOM) of the web page in question and remove comments with spam content. We examine most detection features in the literature along with proposing new features to build a comment spam classifier. In order to test the accuracy of our classifier, we manually label a new corpus of blogs comments. We encourage other researchers to build upon our work and we hope that our corpus will benefit the research community in this area.'\n",
      " 'Using Bipartite Anomaly Features for Cyber Security Applications In this paper we use anomaly scores derived from a technique for bipartite graphs as features for a supervised machine learning algorithm for two cyber security problems: classifying Short Message Service (SMS) text messages as either spam or non-spam and detecting malicious lateral movement within a network. While disparate problems, both spam and lateral movement detection can be viewed as bipartite graphs and we can compute bipartite anomaly scores for each situation. The bipartite anomaly scores by themselves are not very predictive, but used as auxiliary features can boost the receiver operating characteristic (ROC) curve of a supervised classifier. We examine the UCI SMS Spam Collection Data Set for the SPAM problem and use an authentication graph from Los Alamos National Laboratory. We create features by dimensionality reduction through principal component analysis (PCA) on the message-term or user-computer matrix, and then augment those features with anomaly scores. By using the anomaly scores we are able to improve the area under the curve (AUC) for the receiver operating characteristic (ROC) up to 27.5% for the spam data and 21.4% for the authentication data.'\n",
      " \"Effective User Authentications Using Keystroke Dynamics Based on Feature Selections Efficient keystroke authentication systems should have the ability to capture and build the user's pattern in minimal time. These systems also should be able to achieve quickest detection while maintaining good detection accuracy. However, maintaining high detection accuracy and minimal detection delay are conflicting requirements that need to be balanced. A possible approach to tackle this problem is reducing the number of features that need to be learned by a classifier and thereby decreasing the processing time. A wrapper based feature subset selection approach is presented in this paper with the objective of reducing the dimensionality of the user data through identifying a smaller subset of features that represent the most discriminating features in keystrokes dynamic. Several features selection techniques such as genetic and greedy algorithms, best first search Algorithms, and Particle Swarm Optimization (PSO) are used to search for the best subset features. These selection techniques are integrated (Wrapped) with different machine learning classifiers namely Support Vector Machine (SVM), Naive Bayesian (NB), and K Nearest Neighbors (KNN) for feature subset selection procedure that can automatically select the most appropriate and representative subset of features.\"\n",
      " 'Statistical Downscaling of Climate Change Scenarios of Rainfall and Temperature over Indira Sagar Canal Command Area in Madhya Pradesh, India General circulation models (GCMs) have been employed by climate agencies to predict future climate change. A challenging issue with GCM output for local relevance is their coarse spatial resolution of the projected variables. Statistical Downscaling Model (SDSM) identifies relationships between large-scale predictors (i.e., GCM-based) and local-scale predictands using multiple linear regression models. In this study (SDSM) was applied to downscale rainfall and temperature from GCMs. The data from single station located in the Indira Sagar canal command area at Madhya Pradesh, India were used as input of the SDSM. The study included calibration and validation with large-scale atmospheric variables encompassing the NCEP reanalysis data, the future estimation due to a climate scenario, which is HadCM3 A2. Results of the downscaling experiment demonstrate that during the calibration and validation stages, the SDSM model can be well acceptable regard its performance in the downscaling of daily rainfall and temperature. For a future period (2010-2099), the SDSM model estimated an increase in total average annual rainfall and annual average temperature for station. This indicates that the area of station considered will be wet and humid in the future. Also, the mean temperature is projected to rise to 1.5 C to 2.5 C for present study area. However, the model projections show a rise in mean daily precipitation with varying percentage in the months of July (0.59% to 2.09%) and August (0.79% to 1.19) under A2 of HadCM3 model for future periods.'\n",
      " 'Prediction of SPEI Using MLR and ANN: A Case Study for Wilsons Promontory Station in Victoria The prediction of drought is of major importance in climate-related studies, hydrologic engineering, wildlife or agricultural studies. This study explores the ability of two machine learning methods to predict 1, 3, 6 and 12 months standardized precipitation and evapotranspiration index (SPEI) for the Wilsons Promontory station in Eastern Australia. The two methods are multiple linear regression (MLR) and artificial neural networks (ANN). The data-driven models were based on combinations of the input variables: mean precipitations, mean, maximum and minimum temperatures and evapotranspiration, for data between 1915 and 2012. Two performance metrics were used to compare the performance of the optimum MLR and ANN models: the coefficient of determination (R2) and the root mean square error (RMSE). It was found that ANN provided greater accuracy than MLR in forecasting the 1, 3, 6 and 12 months SPEI.'\n",
      " 'Prediction of Sunspot Number Using Minimum Error Entropy Cost Based Kernel Adaptive Filters Several algorithms in adaptive filtering are based on the minimization of the mean squared error (MSE) cost function. However, MSE is just a second order statistics and hence does not capture the entire information about the probability distribution of the error in the system. An information theoretic alternative is using the minimum error entropy (MEE) cost function. Adaptive algorithms based on this criterion have been developed and shown to be superior as compared to MSE counterparts. In this work, kernel versions of some of these methods are designed and tested on predicting the annual sunspot number. The sunspot number is the number of visibly darker regions on the solar surface and has been shown to be instrumental in modeling space weather, state of the ionosphere, climatic anomalies and even global warming. A comparative performance study of the various linear and kernel algorithms, trained with both MEE and MSE criteria, in predicting such a chaotic non-linear time series is presented in this paper. Experimental results clearly show the advantage of the MEE based kernel design which is as per expectation given that it has the advantage of being non-linear along with being able to derive maximum information from the error distribution.'\n",
      " \"Secure Data Aggregation Model (SDAM) in Wireless Sensor Networks Nowadays, Wireless Sensor Networks (WSN's) are becoming more and more promising and applicable to a variety of fields: military, environmental, medical, wild life habitat, and transportation as well wearable devices, target-tracking. WSN are expected to be a main player in the Internet of Things technology. Power management is very important factor in considering WSN's and it has been demonstrated that communication cost is higher than the computational as nodes consume most of the energy in communication. Added to the fact that sensors could be closely deployed and report the same reading, the data aggregation concept was introduced to resolve those issues and for the sake of better performance at a reduced cost. Nonetheless, sensing devices are prone to failure due to several aspects such as node failure or low batteries as well as being compromised. In this paper, we are introducing a novel method Secure Data Aggregation Model (SDAM) aiming at assuring a secure aggregate communication at a low cost (in terms of resources). Our simulation results showed that implementing SDAM resulted into an increase in the energy efficiency as well as a considerable reduction in cross-layering overhead.\"\n",
      " 'A New Video Steganography Algorithm Based on the Multiple Object Tracking and Hamming Codes In the modern world, video steganography has become a popular option for secret data communication. The performance of any steganography algorithm is based on the embedding efficiency, embedding payload, and robustness against attackers. In this paper, we propose a new video steganography algorithm based on the multiple object tracking algorithm and Hamming codes. The proposed algorithm includes four different stages. First, the secret message is preprocessed, and Hamming codes (n, k) are applied in order to produce an encoded message. Second, a motion-based multiple object tracking algorithm is applied on cover videos in order to identify the regions of interest of the moving objects. Third, the process of embedding 3 and 6 bits of the encoded message into the 1 LSB and 2 LSBs of RGB pixel components is performed for all motion regions in the video using the foreground mask. Fourth, the process of extracting the secret message from the 1 LSB and 2 LSBs for each RGB component of all moving regions is accomplished. Experimental results of the proposed video steganography algorithm have demonstrated a high embedding efficiency and a high embedding payload.'\n",
      " 'A Novel Study for the Modeling of Monthly Evaporation Using K-Nearest Neighbor Algorithms for a Semi-Arid Continental Climate This study aims to reveal a reliable and efficient method for predicting the monthly evaporation. For this purpose, the accuracy of machine learning algorithms, MLA, that include k-nearest neighbor, k-NN, was used in modeling monthly evaporation. The tenfold cross-validation approach was employed to determine the performances of prediction methods for MLA. The results revealed that k-NN algorithms outperformed the other MLA (ANN and SVM), with the R value of 0.95, the RMSE value of 1.01 mm, MAE value of 0.78 mm, and RME value of 0.04 mm. It is concluded that the suggested k-NN model can be successfully employed for predicting monthly evaporation for a semi-arid continental climate.'\n",
      " 'Decaying Potential Fields Neural Network: An Approach for Parallelizing Topologically Indicative Mapping Exemplars Mapping methodologies aim to make sense or connections from hard data. The human mind is able to efficiently and quickly process images through the visual cortex, in part due to its parallel nature. A basic Kohonen self-organizing feature map (SOFM) is one example of a mapping methodology in the class of neural networks that does this very well. Optimally the result is a nicely mapped neural network representative of the data set, however SOFMs do not translate to a parallelized architecture very well. The problem stems from the neighborhoods that are established between the neurons, creating race conditions for updating winning neurons. We propose a fully parallelized mapping architecture based loosely on SOFM called decaying potential fields neural network (DPFNN). We show that DPFNN uses neurons that are computationally uncoupled but symbolically linked. Through analysis we show this allows for the neurons to reach convergence with having only a passive data dependency on each other, as opposed to a hazard generating direct dependency. We have created this network to closely reflect the efficiency and speed of a parallel approach, with results that rival or exceed those of similar topological networks such as SOFM.'\n",
      " 'A Bilevel Parameter Tuning Strategy of Partially Connected ANNs Partially connected ANN with Evolvable Topology (PANNET) is a non-fully connected recurrent neural network with proper number of context nodes. The structure of the network along with connection weights are determined through the evolutionary process of a customized genetic algorithm. In this paper, we develop an evolutionary bilevel optimization procedure for tuning the hyper-parameters of PANNET. In the upper level, an evolutionary algorithm optimizes the hyper-parameters, while the customized genetic algorithm is training the PANNET in the lower level optimization. Since executing the lower level optimization for each candidate hyper-parameters requires a high computational cost, fitness function approximation is performed using a regression model based on the Random Forest method. The proposed procedure provides more flexibility on choosing the hyper-parameters, and generate a smaller network with more accuracy in prediction.'\n",
      " 'Sequence Classification with Neural Conditional Random Fields The proliferation of sensor devices monitoring human activity generates voluminous amount of temporal sequences needing to be interpreted and categorized. Moreover, complex behavior detection requires the personalization of multi-sensor fusion algorithms. Conditional random fields (CRFs) are commonly used in structured prediction tasks such as part-of-speech tagging in natural language processing. Conditional probabilities guide the choice of each tag/label in the sequence conflating the structured prediction task with the sequence classification task where different models provide different categorization of the same sequence. The claim of this paper is that CRF models also provide discriminative models to distinguish between types of sequence regardless of the accuracy of the labels obtained if we calibrate the class membership estimate of the sequence. We introduce and compare different neural network based linear-chain CRFs and we present experiments on two complex sequence classification and structured prediction tasks to support this claim.'\n",
      " 'Classification of Occluded Objects Using Fast Recurrent Processing Recurrent neural networks are powerful tools for handling incomplete data problems in computer vision, thanks to their significant generative capabilities. However, the computational demand for these algorithms is too high to work in real time, without specialized hardware or software solutions. In this paper, we propose a framework for augmenting recurrent processing capabilities into a feedforward network without sacrificing much from computational efficiency. We assume a mixture model and generate samples of the last hidden layer according to the class decisions of the output layer, modify the hidden layer activity using the samples, and propagate to lower layers. For visual occlusion problem, the iterative procedure emulates feedforward-feedback loop, filling-in the missing hidden layer activity with meaningful representations. The proposed algorithm is tested on a widely used dataset and shown to achieve 2× improvement in classification accuracy for occluded objects. When compared to Restricted Boltzmann Machines, our algorithm shows superior performance for occluded object classification.'\n",
      " 'Using Machine Learning to Understand and Mitigate Model Form Uncertainty in Turbulence Models The question of how to accurately model turbulent flows is one of the most long-standing open problems in physics. Advances in high performance computing have enabled direct numerical simulations of increasingly complex flows. Nevertheless, for most flows of engineering relevance, the computational cost of these direct simulations is prohibitive, necessitating empirical model closures for the turbulent transport. These empirical models are prone to \"model form uncertainty\" when their underlying assumptions are violated. Understanding, quantifying, and mitigating this model form uncertainty has become a critical challenge in the turbulence modeling community. This paper will discuss strategies for using machine learning to understand the root causes of the model form error and to develop model corrections to mitigate this error. Rule extraction techniques are used to derive simple rules for when a critical model assumption is violated. The physical intuition gained from these simple rules is then used to construct a linear correction term for the turbulence model which shows improvement over naive linear fits.'\n",
      " 'A Finite Gamma Mixture Model-Based Discriminative Learning Frameworks It is well-known that classification tasks can be approached using either generative models or discriminative ones. While the goal of generative approaches is to learn class-conditional densities, the main goal of discriminative techniques is to learn decision boundaries directly without taking into account class-conditional densities. In classic supervised learning, we would usually represent a given object (an image, for instance) by a vector of D real-valued features and then select a given generative or discriminative approach to perform classification. In many applications, however, the object can be represented by a set (or) bag of vectors. Recent developments in machine learning, along with powerful computational tools, have enabled researchers to develop more sophisticated models to handle such applications using the so-called hybrid generative discriminative models. The main idea is based on exploiting the advantages of both families of models. Thus, the success of such an approach depends on the choice of an appropriate discriminative technique and a suitable generative one. The goal of this paper is to develop a hybrid generative discriminative framework based on support vector machine and Gamma mixture. In particular, we focus on the generation of kernels when examples (images, for instance) are structured data (i.e. described by sets of vectors) modeled by Gamma mixtures. Experimental results on real-world challenging applications, namely 3D shape class recognition, object categorization, and video event analysis, show the effectiveness of the proposed framework.'\n",
      " 'Multi-label Classification of Anemia Patients This work examines the application of machine learning to an important area of medicine which aims to diagnose paediatric patients with ?-thalassemia minor, iron deficiency anemia or the co-occurrence of these ailments. Iron deficiency anemia is a major cause of microcytic anemia and is considered an important task in global health. Whilst existing methods, based on linear equations, are proficient at distinguishing between the two classes of anemia, they fail to identify the co-occurrence of this issues. Machine learning algorithms, however, can induce non-linear decision boundaries that enable accurate classification within complex domains. Through a multi-label classification technique, known as problem transformations, we convert the learning task to one that is appropriate for machine learning and examine the effectiveness of machine learning algorithms on this domain. Our results show that machine learning classifiers produce good overall accuracy and are able to identify instances of the co-occurrence class unlike the existing methods.'\n",
      " 'Donor Selection for Hematopoietic Stem Cell Transplant Using Cost-Sensitive SVM Donor selection for Hematopoietic Stem Cell Transplant often requires physicians to manually select 3 to 5 donors from a list of 100s of genetically compatible donors as identified by HLA-based matching algorithms. The decision process is complicated by a lack of strict guidelines governing a \"secondary\" selection process, which is based upon non-HLA donor attributes. Our research is aimed at modeling this \"secondary\" decision process which can help physicians choose the right donors, based on donor attributes and historical choice behavior. Proposed black box models will help in improving selection consistency.'\n",
      " 'Towards Sleep Apnea Screening with an Under-the-Mattress IR-UWB Radar Using Machine Learning In this work, we apply machine learning to investigate the effectiveness of an Impulse Radio Ultra-Wide Band (IR-UWB) radar panel, in an under-the-mattress configuration, for detecting apnea events in subjects known to have obstructive sleep apnea (OSA). We consider a collection of features, some novel and some inspired by features that worked well for sleep apnea detection using other types of sensors (i.e., not IR-UWB). To extract the features, we collected a total of 25 hours of data from four subjects as they slept through the night. The data included digitized samples of the IR-UWB radar return signal and the scored polysomnograph (PSG), which is the gold standard and measures a large number of physiological parameters in a well-equipped sleep laboratory. Normal and apnea epochs were extracted from the IR-UWB data corresponding to normal and apnea epochs in the PSG data. Statistical features were derived from these extracted epochs and a Linear Discriminant classifier was trained. Using cross-validation, we found that the classifier had an accuracy of around 70% in detection of apnea and normal epochs. The novel aspect of this project involves processing and investigation of different methods for feature extraction on data obtained from real apnea subjects and suggests that the radar, when paired with other under-the-mattress sensors might provide an effective screening device in a convenient form factor.'\n",
      " \"iClass: Combining Multiple Multi-label Classification with Expert Knowledge Roper Center is one of the largest public opinion data archives in the world. It collects data sets of polled survey questions from numerous media outlets and organizations. The volume of data introduces search complexities over survey questions and poses challenges when analyzing search trends. Roper Center question-level retrieval applications used human metadata experts to assign topics to content. This has been insufficient to reach required levels of consistency and provides an inadequate base for creating an advanced search experience. The objective of this work is to combine the human expert teams' knowledge of the nature of the survey questions and the concepts and topics these questions express, with the ability of multi-label classifiers to learn this knowledge and apply it to an automated, fast and accurate classification mechanism. This approach cuts down the question analysis and tagging time significantly as well as provides enhanced consistency and scalability for topics' descriptions. At the same time, creating an ensemble of machine learning classifiers combined with expert knowledge is expected to enhance the search experience and provide much needed analytic capabilities to the survey questions databases. In our design, we use classification from several machine learning algorithms like SVM and Decision Trees, combined with expert knowledge in form of handcrafted rules, data analysis and result review. We consolidate the different techniques into a Multipath Classifier with a Confidence point system that decides upon the relevance of topics assigned to survey questions with nearly perfect accuracy.\"\n",
      " 'An Interval-Radial Algorithm for Hierarchical Clustering Analysis Hierarchical clustering analysis (HCA) produces a structure that is more informative than an unstructured set of clusters. However, the advantage comes at the cost of lower efficiency. In analyzing large dataset with HCA, it is important to improve its efficiency. Motivated by the fact that small quantitative differences may not necessarily reflect changes of qualitative property, we report an interval-radial algorithm for HCA. By grouping data points within a neighborhood, the interval-radial algorithm is O(N^2) for both agglomerative and divisive approaches under an easy to satisfy weak condition. The algorithm can adaptively adjust radius during its execution. Furthermore, the algorithm provides flexibility to users for them to select initial radius and step size such that to produce customized output automatically. We report the algorithm, its analysis, and results of computational experiments on several benchmark datasets. Examples and illustrative dendrograms are included.'\n",
      " 'Time Series Prediction Based on Robust Recurrent Kernel Online Learning We propose a robust recurrent kernel online learning (RRKOL) algorithm based on the celebrated real-time recurrent learning (RTRL) approach that exploits the kernel trick in a recurrent online training manner. The RRKOL algorithm automatically weights the regularized term in the recurrent loss function such that we not only minimize the estimation error but also improve the generalization performance via sparsification with simulation support.'\n",
      " 'Recognizing Human Activities from Raw Accelerometer Data Using Deep Neural Networks Activity recognition from wearable sensor data has been researched for many years. Previous works usually extracted features manually, which were hand-designed by the researchers, and then were fed into the classifiers as the inputs. Due to the blindness of manually extracted features, it was hard to choose suitable features for the specific classification task. Besides, this heuristic method for feature extraction could not generalize across different application domains, because different application domains needed to extract different features for classification. There was also work that used auto-encoders to learn features automatically and then fed the features into the K-nearest neighbor classifier. However, these features were learned in an unsupervised manner without using the information of the labels, thus might not be related to the specific classification task. In this paper, we recommend deep neural networks (DNNs) for activity recognition, which can automatically learn suitable features. DNNs overcome the blindness of hand-designed features and make use of the precious label information to improve activity recognition performance. We did experiments on three publicly available datasets for activity recognition and compared deep neural networks with traditional methods, including those that extracted features manually and auto-encoders followed by a K-nearest neighbor classifier. The results showed that deep neural networks could generalize across different application domains and got higher accuracy than traditional methods.'\n",
      " 'Zero Shot Deep Learning from Semantic Attributes We study the problem of classifying images when no training exemplars are available for some image classes, and therefore direct classification is not possible. We use instead semantic attributes: if attributes of yet unseen classes can be determined, then class labels may themselves be decided based on prior knowledge of class to attributes relationships. We present several methods for determining attributes, including (A) an approach based on attribute classifiers, and approaches using (B) MAP and (C) MMSE attribute estimators using image classifiers for known classes. Preliminary tests obtained using a dataset comprised of ImageNet images and Human218 attributes yield encouraging performance.'\n",
      " 'Speaker Adaptation Using Speaker Similarity Score on DNN Features This paper proposes a novel speaker adaptation algorithm for classifying speech based on deep neural networks (DNNs). The adaptation algorithm consists of two steps. In the first step a deep neural network is trained using raw Mel-frequency cepstral coefficient (MFCC) features to discover hidden structures in the data and employing the activations of the last hidden layers of the DNN as acoustic features. In the second step using nearest neighbor, an adaptation algorithm learns speaker similarity scores based on a small amount of adaptation data from each target speaker using the DNN-based acoustic features. Based on the speaker similarity score, classification is done using a k-nearest neighbor (k-NN) classifier. The novelty of this work is that instead of modifying and re-training the DNN for speaker adaptation, which comprises a large number of parameters and is computationally expensive, activations of the learned DNN are used to project features from MFCC to a sparse DNN space, then speaker adaptation is performed based on similarity (i.e. nearest neighbor) using k-NN algorithm. With only a small amount of adaptation data, it reduces the number of phoneme classification error in the TIMIT dataset by 23%. This work also analyzes impact of deep neural networks architecture on speaker adaptation performance.'\n",
      " 'Simplicity of Kmeans Versus Deepness of Deep Learning: A Case of Unsupervised Feature Learning with Limited Data We study a bio-detection application as a case study to demonstrate that Kmeans -- based unsupervised feature learning can be a simple yet effective alternative to deep learning techniques for small data sets with limited intra-as well as inter-class diversity. We investigate the effect on the classifier performance of data augmentation as well as feature extraction with multiple patch sizes and at different image scales. Our data set includes 1833 images from four different classes of bacteria, each bacterial culture captured at three different wavelengths and overall data collected during a three-day period. The limited number and diversity of images present, potential random effects across multiple days, and the multi-mode nature of class distributions pose a challenging setting for representation learning. Using images collected on the first day for training, on the second day for validation, and on the third day for testing Kmeans -- based representation learning achieves 97% classification accuracy on the test data. This compares very favorably to 56% accuracy achieved by deep learning and 74% accuracy achieved by handcrafted features. Our results suggest that data augmentation or dropping connections between units offers little help for deep-learning algorithms, whereas significant boost can be achieved by Kmeans -- based representation learning by augmenting data and by concatenating features obtained at multiple patch sizes or image scales.'\n",
      " 'Adaptive OpenMP Task Scheduling Using Runtime APIs and Machine Learning Task-based programming models adopt different scheduling strategies to exploit parallelism in irregular applications. These scheduling strategies differ in terms of exploiting data locality, maintaining load balance, and minimizing overhead. OpenMP tasks allow programmers to express unstructured parallelism at a high level of abstraction and make the runtime responsible about the burden of scheduling parallel execution. For irregular applications, the performance of task scheduling cannot often be predicted due to the nature of application, the used compiler, and the platform/architecture dependencies. In this work, we introduce an automatic, portable, and adaptive runtime feedback-driven framework (APARF) that combines standard low-level tasking runtime APIs, a developed profiling tool, and a hybrid machine learning model. We employ APARF to select the optimum task scheduling scheme of any given application using similarity analysis through the correlation between the captured runtime APIs with low profiling costs. Our hybrid model predicts the best scheduling strategy for a variety of unseen applications with an average accuracy of 93%, while maintaining a 100% training accuracy. An average performance enhancement of 25% was obtained compared with the default configuration, when APARF was applied on different unseen programs. APARF was examined against a real application (Molecular Dynamics), where we achieved up to 31% performance improvement. Compared to Intel, PGI and GNU compilers, our predicted scheme achieved better performance in most cases.'\n",
      " 'MLaaS: Machine Learning as a Service The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.'\n",
      " 'Detecting Erosion Events in Earth Dam and Levee Passive Seismic Data with Clustering Geophysical sensor technologies can be used to understand the structural integrity of Earth Dams and Levees (EDLs). We are part of an interdisciplinary team researching techniques for the advancement of EDL health monitoring and the automatic detection of internal erosion events. We present results from our performance study that uses signal processing, feature extraction, and unsupervised learning on passive seismic data from an experimental laboratory earth embankment. We used popular unsupervised clustering algorithms to gain insights to this real-world problem, and evaluated our results using internal and external validation techniques. In four of the clustering algorithms applied, results consistently show a clear separation of events from non-events. We provide proof of concept and an initial pattern recognition process that could be used as a tool for nonintrusive and long-term EDL monitoring.'\n",
      " 'A Power Variance Test for Nonstationarity in Complex-Valued Signals We propose a novel algorithm for testing the hypothesis of nonstationarity in complex-valued signals. The implementation uses both the bootstrap and the Fast Fourier Transform such that the algorithm can be efficiently implemented in O(NlogN) time, where N is the length of the observed signal. The test procedure examines the second-order structure and contrasts the observed power variance -- i.e. the variability of the instantaneous variance over time -- with the expected characteristics of stationary signals generated via the bootstrap method. Our algorithmic procedure is capable of learning different types of nonstationarity, such as jumps or strong sinusoidal components. We illustrate the utility of our test and algorithm through application to turbulent flow data from fluid dynamics.'\n",
      " 'BreakFast: Analyzing Celerity of News In the hypercompetitive news market, news outlets race to break news first. In order to provide better breaking news service and improve the reader experience, news agencies need to understand how to identify bottlenecks and streamline their reporting and delivery processes. With that in mind, we built a system, BreakFast, to measure and compare the speed of delivery of breaking news from various news sources to readers. One of the primary challenges of this comparison is how to identify which breaking news items are about the same emerging event but reported by different news agencies with different headlines and content. To tackle this problem, we extracted keywords automatically from the content, identified important topics, and then developed a classification model. The model identifies the same breaking stories from multiple news sources with an accuracy of approximately 90%. We also proposed new metrics to evaluate the speed of breaking news services and built real-time dashboards to monitor performance over time. We deployed BreakFast into the breaking news service at The Washington Post. This integrated system narrowed in on bottlenecks in its breaking news generation and delivery process, and improved its breaking news service in terms of time by more than 50%.'\n",
      " 'Adaptive Modular Approach for Online Fault Diagnosis of Discrete Event Systems In this paper, an adaptive modular approach is proposed to achieve the fault diagnosis of discrete event systems. The desired (normal) behavior is represented by a set of specifications while faults of each predefined fault type are considered to be the execution of specific fault behavior violating a specification. The inference of the fault type of each fault is achieved by a diagnosis module called diagnoser. This approach considers that only normal behavior is known in advance. Then, it adapts the diagnoser in order to integrate new specific fault behaviors into its inference engine. This adaptation allows increasing the diagnosis capacity, called diagnosability, over time.'\n",
      " 'Achievements Recommendation Framework Based on Scientific Collaboration Network With the rapid growth of the Internet, vast amounts of data available and in other digital repositories make it challenging for users to find the right sources of information. This study presents a hierarchical recommendation framework that enriches the domain ontologies and retrieves more relevant information resources. In this paper, we analyze the features of achievements information related to the scientific and technological domains, and then build an ontology that represents their latent collaborative relations and detect clusters from the collaboration network. We conduct a case study to collect a data set of research achievements in electric vehicle field and better clustering results are obtained. This work also lays out a novel insight into the exploitation of scientific collaboration network to better classify achievements information.'\n",
      " \"Diagnosis of Bearing Defects in Induction Motors by Fuzzy-Neighborhood Density-Based Clustering In this paper, a supervised fuzzy-neighborhood density-based clustering approach is proposed for the fault diagnosis of induction motors' bearings. The proposed approach makes use of the labeled data regarding the actual classes of faulty and fault-free cases, in order to train the fuzzy-neighborhood density-based clustering algorithm in a supervised manner, by resorting to an invasive weed optimization algorithm that aims to minimize an error-based objective function. The proposed classifier can properly classify multi-class data with complex and variously shaped decision boundaries among the different classes of faults and the fault-free state, and is robust against noise. This is due mainly to the fact that the classifier is constructed using the fuzzy-neighborhood density based clustering method, which is not sensitive to the geometrical shape of clusters in the feature space.\"\n",
      " 'Measuring Level-K Reasoning, Satisficing, and Human Error in Game-Play Data Inferences about structured patterns in human decision making have been drawn from medium-scale simulated competitions with human subjects. The concepts analyzed in these studies include level-k thinking, satisficing, and other human error tendencies. These concepts can be mapped via a natural depth of search metric into the domain of chess, where copious data is available from hundreds of thousands of games by players of a wide range of precisely known skill levels in real competitions. The games are analyzed by strong chess programs to produce authoritative utility values for move decision options by progressive deepening of search. Our experiments show a significant relationship between the formulations of level-k thinking and the skill level of players. Notably, the players are distinguished solely on moves where they erred -- according to the average depth level at which their errors are exposed by the authoritative analysis. Our results also indicate that the decisions are often independent of tail assumptions on higher-order beliefs. Further, we observe changes in this relationship in different contexts, such as minimal versus acute time pressure. We try to relate satisficing to insufficient level of reasoning and answer numerically the question, why do humans blunder?'\n",
      " \"Synthetic Oversampling for Advanced Radioactive Threat Detection Gamma-ray spectral classification requires the automatic identification of a large background class and a small minority class composed of instances that may pose a risk to humans and the environment. Accurate classification of such instances is required in a variety of domains, spanning event and port security to national monitoring for failures at industrial nuclear facilities. This work proposes a novel form of synthetic oversampling based on artificial neural network architecture and empirically demonstrates that it is superior to the state-of-the-art in synthetic oversampling on the target domain. In particular, we utilize gamma-ray spectral data collected for security purposes at the Vancouver 2010 winter Olympics and on a node of Health Canada's national monitoring networks.\"\n",
      " \"Intelligent Bus Stop Identification Using Smartphone Sensors Intelligent transportation systems can be built by developing models that learn from the collected transport data. Data collection and implementation of such systems is often costly, and few countries have support for such systems in their transportation budgets. In places where maintaining currency and accuracy of information is difficult, many problems arise. For instance, in Chennai, India, real time bus transit data is not maintained, there is no proper communication about the bus schedules, bus stops are not regularly updated and inconsistent information about bus stops is observed in the transport authority's website. We are interested in developing models for identifying bus stops from trajectories for situations where accurate and current information is not available and traffic conditions are challenging, such as Chennai, India. We develop a simple yet easily accessible Android mobile application (App) to collect GPS traces of bus routes. We use our App to collect GPS trajectory data from Baltimore, Maryland, a place where there are facilities to access up-to-date information about bus stops. We also collect GPS trajectories from Chennai, India. We then develop a model using machine learning techniques to identify bus stops from the collected trajectories. We experimentally evaluate our model by training it on the Baltimore dataset and testing it on the Chennai dataset, achieving testing accuracy between 85 -- 90%. This is comparable to the accuracy of 95% achieved by both training and testing on the Chennai dataset. This illustrates that our approach is effective in helping maintain an accurate and current transport information system for resource constraint environments.\"\n",
      " 'Rejection Factors of Pull Requests Filed by Core Team Developers in Software Projects with High Acceptance Rates When developers want to contribute to an opensource project, they fork the repository, make changes, and send a pull request to the core team to incorporate these changes back into the repository. However, some projects enforce this collaboration model even for changes made by core team developers. This potentially enhances the quality of the repository by adding an inspection step before accepting a contribution into the repository. In this context, though less frequently, the contributions may be rejected. The understanding of the factors that lead to the rejection of these internal contributions is crucial for the improvement of the ways core developers collaborate, having a direct impact on the team productivity. In this work we extract association rules from pull request data stored in software repositories in order to find factors that have influence over the decision of rejecting contributions made by core developers. In addition, we present a qualitative analysis of some cases, helping to understand the patterns that arose from the association rules. The results indicate that some key factors increase the changes of having internal contributions rejected: (i) the inexperience with pull requests, (ii) the complexity of contributions, as well as the locality of the artifacts that have been modified, and (iii) the contribution policy of the projects.'\n",
      " 'Learning Convex Piecewise Linear Machine for Data-Driven Optimal Control In a data-driven Optimal Control (OP) scheme, one or more involved components, such as objective function, system dynamics, or operation constraints, are described with statistical models and learned from data. In this work, we focus on the machine learning of operation constraints which is rarely addressed in previous research. Although a rich collection of supervised learning methods exist in literature, most of them are not suitable for modeling operation constraints, because their decision rules usually induce undesirable non-linear couplings in system variables. In order to surpass simple linear models while at the same time maintaining compatibility with downstream control applications, we propose to describe system operation requirement by convex piecewise linear machine (CPLM), which does not incur any difficulties in optimization and is directly pluggable. The generalization performance of the proposed classifier is analyzed through bounding its VC-dimension, and a large margin cost sensitive learning objective is formulated with Bayes consistent hinge loss. We solve the training problem by online stochastic gradient descent and propose a mixed integer based initialization method. A case study on Heating, Ventilation and Air Conditioning (HVAC) systems control with comfort requirement is conducted and the results show that CPLM is not only a promising candidate for cost sensitive learning in general, but also enables much better description and exploitation of the system operation region for optimal control purpose.'\n",
      " 'Augmenting Interactive Evolution with Multi-objective Optimization Deceptive fitness landscapes are a growing concern for the field of evolutionary computation. Recent work has demonstrated that incorporating human insights with short-term automated evolution has a synergistic effect that eases deception and accelerates the discovery of solutions. While human evaluators provide rich insight into a domain, they fatigue easily. Previous work reduced the number of human evaluations by evolving a diverse set of candidates via intermittent searches for novelty. While successful at evolving solutions for a deceptive maze domain, it lacked the ability to measure solution qualities that the human evaluator implicitly identified as important. The key insights of this paper are that multi-objective evolutionary algorithms (MOEAs) foster diversity and that the non-dominated set can serve as a surrogate for novelty while measuring user preferences data. This new approach, called Pareto Optimality-Assisted Interactive Evolutionary Computation (POA-IEC), leverages human intuitions by allowing users to identify candidates in the non-dominated set that they feel are promising. Interestingly, the experimental results demonstrate that POA-IEC finds solutions in significantly fewer evaluations than previous approaches, and that the non-dominated set contains significantly more novel behaviors than the dominated set. In this way, POA-IEC simultaneously leverages human insights while quantifying their preferences.'\n",
      " 'NewsCubeSum: A Personalized Multidimensional News Update Summarization System Popular online publishers produce huge amount of news articles every day, so it is important to summarize the most up-to-the-minute information to help users quickly know the progresses of their interested news events. In this paper, we develop NewsCubeSum, a novel personalized news summarization system utilizing OLAP and supervised sentence selection techniques to generate brief summaries delivering news updates in multiple dimensions (such as time, entity, and topic). An illustrative case study and experimental results on summarization performance comparisons are provided to show the effectiveness of NewsCubeSum.'\n",
      " 'Investigating New Bootstrapping Approaches of Bagging Classifiers to Account for Class Imbalance in Bioinformatics Datasets One major challenge posed by bioinformatics datasets is class imbalance which occurs when one class has many more instances than the other class(es). Its undesirable effect on the classification performance is compounded with the fact that, in general, the class with fewer instances is the class of interest. Bagging has been utilized by practitioners in the field to overcome the challenge of class imbalance and to improve the classification performance. Our motivation for this study is to investigate whether changes to the bootstrapping step of bagging classifiers can further improve their performance. Specifically, these modifications to the bootstrapping process take into account the membership of the classes. We performed an extensive empirical study utilizing four bootstrap approaches within bagging framework using three feature rankers along with four feature subset sizes and two base classifiers across 15 imbalanced bioinformatics datasets. Three of these bootstrap approaches were proposed and implemented by our research team for this study. Our results show that all new approaches improve performance over the classic bootstrap approach, with balanced bagging having the highest performance, however, observed increases in performance are not statistically significant. We recommend the balanced bootstrap approach because it shows the most improvement, in terms of frequency of having the highest performance, and it generates fully balanced bootstrap datasets that can account for the class imbalance problem. The uniqueness of this paper is proposing and implementing the three innovative bootstrapping approaches to examine the effects of these bootstrapping processes against the classic one on the performance of bagging classifiers in the domain of bioinformatics.'\n",
      " 'Request Type Prediction for Web Robot and Internet of Things Traffic The volume of Web robot traffic seen by Web servers and clouds continue to increase with the popularity of Internet of Things (IoT) devices. Such traffic exhibits decidedly different statistical and resource request patterns compared to humans. However, the optimizations ensuring high levels of Web systems and cloud performance requires traffic to exhibit the statistical and behavioral patterns of humans, not robots. This necessitates the design of novel Web system optimizations to handle Web robot traffic effectively. Caches are a basic component of high performing Web systems, but their effectiveness relies on accurate resource request prediction. In this paper, we explore a suite of classifiers for the resource request type prediction problem for robot traffic. Our analysis reveals: (i) a striking difference in the request patterns of robots across multiple servers from the same domain, and (ii) that Elman neural networks hold promise to predict request types despite these differences.'\n",
      " 'Interpretable Classifier for Identifying High-Value Child Support Cases This work brings interpretable and accurate data analytics to child support agencies with the goal of substantially increasing their effectiveness. In the realm of child support, a custodial parent may be entitled to periodic child support payments from the noncustodial parent. In order to analyze this process, we have gathered case data from several child support agencies. The objective of the work is to develop analytical models that characterize and predict high-value child support cases. High-value cases are those that result in successful payments and require far fewer resources for enforcement. We create interpretable and accurate scoring models to identify these cases so that the key attributes driving their prediction are easily understood by the caseworkers. This information may be integrated with case management systems to schedule and prioritize the caseload.'\n",
      " 'Learning Common Metrics for Homogenous Tasks in Traffic Flow Prediction Nearest neighbor based nonparametric regression is a classic data-driven method for traffic flow prediction in intelligent transportation systems (ITS). Performances of those models depend heavily on the similarity or distance metric used to search nearest neighborhood. Metric learning algorithms have been developed to learn the distance metrics from data in recent years. In real-world transportation application, multiple forecasting tasks are set since there are lots of road sections and detector points in the traffic network. Previous works tend to learn only one global metric to be used for all the tasks or learn multiple local metrics for each task which may lead to under-fitting or over-fitting problem. To balance these two kinds of methods and improve the generalization of learned metrics, we propose a common metric learning algorithm under the intuition that homogenous tasks tend to have similar local metrics. Then the learned common metrics are used in common metric KNN (CM-KNN) for traffic flow prediction. Experimental results show that our algorithm to learn common metrics are reasonable and CM-KNN method for traffic flow prediction outperforms other competing methods.'\n",
      " \"Car Following Markov Regime Classification and Calibration The car following behavior has recently gained much attention due to its wide variety of applications. This includes accident analysis, driver assessment, support systems, and road design. In this paper, we present a model that leverages Markov regime switching models to classify various car following regimes. The detected car following regimes are then mined to calibrate the parameters of drivers to be dependent on the driver's current driving regime. A two stage Markov regime switching model is utilized to detect different car following regimes. The first stage discriminates normal car following regimes from abnormal ones, while the second stage classifies normal car following regimes to their fine-grained regimes like braking, accelerating, standing, free-flowing, and normal following. A genetic algorithm is then employed to the observed driver data in each car following regime to optimize car following model parameter values of the driver in each regime. Experimental evaluation of the proposed model using a real dataset shows that it can detect up-normal (rare and short time) events. In addition, it can infer the switching process dynamics such as the expected duration, the probability of moving from one regime to another and the switching parameters of each regime. Finally, the model is able to accurately calibrate the parameters of drivers according to their driving regimes, so we can achieve a better understanding of drivers behavior and better simulation of driving situation.\"\n",
      " 'Gaussian Mixture Model Cluster Forest Random Forest (RF) classification algorithm is widely used in the area of information retrieval and became a basis for some extended branches of classification and/or regression algorithms. Cluster Forest (CF) represents a particular branch, and brings usually better results than individual clustering algorithms. This article describes a new ensemble clustering algorithm based on CF that internally uses a probabilistic model called Gaussian Mixture Model (GMM). Finally, Expectation-maximization algorithm is used for estimation of GMM parameters. The proposed ensemble clustering algorithm will be compared with several different approaches and tested on eight datasets.'\n",
      " 'Comparative Evaluation of Top-N Recommenders in e-Commerce: An Industrial Perspective We experiment on two real e-commerce datasets and survey more than 30 popular e-commerce platforms to reveal what methods work best for product recommendations in industrial settings. Despite recent academic advances in the field, we observe that simple methods such as best-seller lists dominate deployed recommendation engines in e-commerce. We find our empirical findings to be well-aligned with those of the survey, where in both cases simple personalized recommenders achieve higher ranking than more advanced techniques. We also compare the traditional random evaluation protocol to our proposed chronological sampling method, which can be used for determining the optimal time-span of the training history for optimizing the performance of algorithms. This performance is also affected by a proper hyperparameter tuning, for which we propose golden section search as a fast alternative to other optimization techniques.'\n",
      " \"A Code-Centric Cluster-Based Approach for Searching Online Support Forums for Programmers Online forums provide peer-to-peer technical support for many user populations, including programmers struggling to master a new language. Programmers can help one another by uploading code samples to such a forum. Unfortunately, finding relevant code samples can prove difficult using existing search engines for large, diverse forums. Therefore, we have prototyped a new kind of code search engine for online forums that draws upon unsupervised machine learning in two ways. First, it displays code samples in visual groupings based on the mutual similarity of code samples. Second, it uses the assignment of code samples to clusters to achieve a form of query expansion, thereby identifying additional search results as potentially useful. We evaluated the system by running it on the forum for the LabVIEW programming language. A textual analysis of posts showed that the unsupervised machine learning algorithm successfully tended to assign code samples to clusters based on topical similarity. An empirical user evaluation confirmed that the new search engine improved on the forum's existing search engine by providing results for more queries, by generating more results per query, and by providing more relevant search results.\"\n",
      " 'What to Learn Next: Recommending Commands in a Feature-Rich Environment Despite an abundance of commands to make tasks easier to perform, the users of feature-rich applications, such as development environments, use only a fraction of the commands available. Earlier work has shown that command recommendation -- in which, given the command usage history of a set of users, the objective is to predict a command that is likely useful for the user to learn -- can improve the usage of a range of commands available within such applications. In this paper, we present a new algorithm, CoDis, which is built upon three hypotheses. First, we hypothesize that in feature-rich applications there exists co-occurrence patterns between commands. Second, we hypothesize that users of feature-rich applications have prevalent discovery patterns. Finally, we hypothesize that users need different recommendations based on the time elapsed between their last activity and the time of recommendation. We show on data submitted by many users of an integrated development environment (Eclipse) that CoDis outperforms existing approaches: compared to ADAGRAD, the best performing baseline, it achieves an improvement of 10.22% in recall, for a top-N recommendation task (N = 20).'\n",
      " 'Multi-period Prediction of Solar Radiation Using ARMA and ARIMA Models Due to the variations in weather conditions, solar power integration to the electricity grid at a high penetration rate can cause a threat for the grid stability. Therefore, it is required to predict the solar radiation parameter in order to ensure the quality and the security of the grid. In this study, initially, a 1-h time series model belong to the solar radiation parameter is created for multi-period predictions. Afterwards, autoregressive moving average (ARMA) and autoregressive integrated moving average (ARIMA) models are compared in terms of the goodness-of-fit value produced by the log-likelihood function. As a result of determining the best statistical models in multi-period predictions, one-period, two-period and three-period ahead predictions are carried out for the solar radiation parameter in a comprehensive way. Many feasible comparisons have been made for the solar radiation prediction.'\n",
      " 'A Data-Driven Method to Detect the Abnormal Instances in an Electricity Market Participants in an electricity market expect to have a fair, transparent, and open competition. Market Surveillance Administrators (MSA) are responsible for monitoring the market outcomes to investigate if they are consistent with the fundamentals of the electricity markets. It can be an immensely time-consuming process with high amounts of computations in an electricity market with huge numbers of participants. Besides, a manual review of market operations may be biased by involving humans in the decision making process. If this anomaly detection procedure can be done automatically then it can be a great aid to the market surveillance process for having an unbiased and prompt tool to monitor the market. In this paper, an anomaly detection algorithm is proposed to identify the events of interest in an electricity market. This algorithm provides the MSA with a tool to detect the instances in the electricity market when electricity price behavior deviates from the normal expected regime. These anomalous hours can then be analyzed further in order to diagnose the reason.'\n",
      " 'Statistical Scenarios for Demand Forecast of a High Voltage Feeder: A Comparative Study The electricity demand forecasting has gained remarkable concern in energy market operation and planning with the emergence of deregulation in the power industry. Power system operators benefit from accurate demand forecasts by supporting investment decisions more objectively. As a crucial requirement, this paper focuses on hourly demand forecasts of a high voltage feeder. Moving average (MA), weighted moving average (WMA), autoregressive moving average (ARMA) and autoregressive integrated moving average (ARIMA) models have been used for creating statistical demand scenarios at 1-h, 2-h, 3-h and 4-h intervals. Many constructive comparisons have been conducted among MA, WMA, ARMA and ARIMA models comprehensively. Besides, the best statistical model employed in each hourly demand scenario provides the robust improvement percentage with respect to the persistence model.'\n",
      " 'Incremental Learning on Decorrelated Approximators In general, designing an incremental learning system for a particular task at least consists of choosing an appropriate approximation structure and learning algorithm. Common Linear In the Parameters (LIP) approximation structures are for example polynomials, radial basis functions or grid-based lookup tables. Typical learning algorithms accompanying them are for example Passive-Aggressive (PA) or Recursive Least Squares (RLS). Usually, these two choices are not independent as not every learning algorithm is able to handle any approximation structure well. Here we present a formalism that allows the designer to treat these two design aspects independently from each other. By decorrelating the basis functions of the approximator we form a new set of basis functions that can be handled by any learning algorithm. We develop design guidelines in order to make our approach an easy to use tool and to support the designer in making the learning progress reliable at design time. Further, we look at the properties of our approach as an extension to LIP approximators and investigate its implications for the behavior of the incremental learning system using artificial, benchmark and real world data sets for regression tasks.'\n",
      " \"A Demonstration of Stability-Plasticity Imbalance in Multi-agent, Decomposition-Based Learning Layered learning is a machine learning paradigm used in conjunction with direct-policy search reinforcement learning methods to find high performance agent behaviors for complex tasks. At its core, layered learning is a decomposition-based paradigm that shares many characteristics with robot shaping, transfer learning, hierarchical decomposition, and incremental learning. Previous studies have provided evidence that layered learning has the ability to outperform standard monolithic methods of learning in many cases. The dilemma of balancing stability and plasticity is a common problem in machine learning that causes learning agents to compromise between retaining learned information to perform a task with new incoming information. Although existing work implies that there is a stability-plasticity imbalance that greatly limits layered learning agents' ability to learn optimally, no work explicitly verifies the existence of the imbalance or its causes. This work investigates the stability-plasticity imbalance and demonstrates that indeed, layered learning heavily favors plasticity, which can cause learned subtask proficiency to be lost when new tasks are learned. We conclude by identifying potential causes of the imbalance in layered learning and provide high level advice about how to mitigate the imbalance's negative effects.\"\n",
      " 'Resampling-Based Variable Selection with Lasso for p >> n and Partially Linear Models The linear model of the regression function is a widely used and perhaps, in most cases, highly unrealistic simplifying assumption, when proposing consistent variable selection methods for large and highly-dimensional datasets. In this paper, we study what happens from theoretical point of view, when a variable selection method assumes a linear regression function and the underlying ground-truth model is composed of a linear and a non-linear term, that is at most partially linear. We demonstrate consistency of the Lasso method when the model is partially linear. However, we note that the algorithm tends to increase even more the number of selected false positives on partially linear models when given few training samples. That is usually because the values of small groups of samples happen to explain variation coming from the non-linear part of the response function and the noise, using a linear combination of wrong predictors. We demonstrate theoretically that false positives are likely to be selected by the Lasso method due to a small proportion of samples, which happen to explain some variation in the response variable. We show that this property implies that if we run the Lasso on several slightly smaller size data replications, sampled without replacement, and intersect the results, we are likely to reduce the number of false positives without losing already selected true positives. We propose a novel consistent variable selection algorithm based on this property and we show it can outperform other variable selection methods on synthetic datasets of linear and partially linear models and datasets from the UCI machine learning repository.'\n",
      " \"Source-Aware Partitioning for Robust Cross-Validation One of the most critical components of engineering a machine learning algorithm for a live application is robust performance assessment prior to its implementation. Cross-validation is used to forecast a specific algorithm's classification or prediction accuracy on new input data given a finite dataset for training and testing the algorithm. Two most well known cross-validation techniques, random subsampling (RSS) and K-fold, are used to generalize the assessment results of machine learning algorithms in a non-exhaustive random manner. In this work we first show that for an inertia based activity recognition problem where data is collected from different users of a wrist-worn wireless accelerometer, random partitioning of the data, regardless of cross-validation technique, results in statistically similar average accuracies for a standard feed-forward neural network classifier. We propose a novel source-aware partitioning technique where samples from specific users are completely left out of the training/validation sets in rotation. The average error for the proposed cross-validation method is significantly higher with lower standard variation, which is a major indicator of cross-validation robustness. Approximately 30% increase in average error rate implies that source-aware cross validation could be a better indication of live algorithm performance where test data statistics would be significantly different than training data due to source (or user)-sensitive nature of process data.\"\n",
      " 'Learning Complex Events from Sequences with Informed Gaps Complex event processing is key technology for current business in which sequences of events are controlled. However, defining complex events is not easy, and sequence learning algorithms can help. To that end, sequence learning methods should consider temporal relationship among events. In this paper, we tackle the problem of mining complex events using frequent sequence pattern mining with time gaps. A constraint model of the learning problem is proposed. Consistently, the learning problem is addressed using solvers off the shelf. The experiments are carried out in a bike hiring domain so as a CEP system can account how many users will reach a depot, independently of which was their origin. Results are analysed in terms of individual and multiple users, as well as regarding the scalability of the method.'\n",
      " 'An Edge-Less Approach to Horizon Line Detection Horizon line is a promising visual cue which can be exploited for robot localization or visual geo-localization. Prominent approaches to horizon line detection rely on edge detection as a pre-processing step which is inherently a non-stable approach due to parameter choices and underlying assumptions. We present a novel horizon line detection approach which uses machine learning and Dynamic Programming (DP) to extract the horizon line from a classification map instead of an edge map. The key idea is assigning a classification score to each pixel, which can be interpreted as the likelihood of the pixel belonging to the horizon line, and representing the classification map as a multi-stage graph. Using DP, the horizon line can be extracted by finding the path that maximizes the sum of classification scores. In contrast to edge maps which are typically binary (edge vs no-edge) and contain gaps, classification maps are continuous and contain no gaps, yielding significantly better solutions. Using classification maps instead of edge maps allows for removing certain assumptions such as the horizon is close to the top of the image or that the horizon forms a straight line. The purpose of these assumptions is to bias the DP solution but they fail to produce good results when they are not valid. We demonstrate our approach on three different data sets and provide comparisons with a traditional approach based on edge maps. Although our training set is comprised of a very small number of images from the same location, our results illustrate that our method generalizes well to images acquired under different conditions and geographical locations.'\n",
      " 'Efficient and Rotation Invariant Fingerprint Matching Algorithm Using Adjustment Factor This paper presents a new efficient and rotation invariant algorithm that makes use of local features forfingerprint matching. Minutiae points are first extracted from afingerprint image. Minutiae code mc, defined in this paper, is then generated for each extracted minutiae point. The proposed minutiae code is invariant to rotation of the fingerprint image. Adjustment factor (AF) is introduced to address the problem due to differences in a claimant fingerprint and a template fingerprint of the same person that may be present due to variations in inking or variations in pressure applied between a finger and the scanner. Adjustment factor is calculated from the minutiae code (mc) of the two fingerprints being matched. A two stage fingerprint matching process is proposed. During first stage only a few minutiae codes are checked to decide if the second stage of matching process is required. This makes the matching process faster. The proposed strategy is tested on a number of publicly available images (DB1 of FVC2004 database) and the results are promising.'\n",
      " 'Robust Vehicle Tracking Using Perceptual Hashing Algorithm Vehicle tracking, significant in the computer vision using machine learning method, allows the vehicle to comprehend its immediate environment and therefore, enhances the intelligence of the vehicles and the safety of vehicle occupants. We propose a novel tracking algorithm that can work robustly under challenging circumstances such as road scene where several kinds of appearance and motion changes of a tracking object occur. Our algorithm is based on the perceptual hashing algorithm (PHA) and the color, low-frequency and rotation information are considered. By means of PHA, our tracker generates a single identification at each frame. The sliding windows produce a series of candidates between consecutive frames so that the new position of tracking object can be updated by comparing the binary code of candidates and identification. In the experiment, the quantitative and qualitative results are expressed by center location error(CLE) and VOC overlap ratio(VOR). Compared to the advanced tracker at present, PHA tracker shows its robustness when confronting violent changes of noise, illumination, background clutter and part occlusion, which demonstrates its state-of-the-art performance in the field of dynamic vehicle tracking.'\n",
      " 'Acoustic Features for Recognizing Musical Artist Influence Musicologists have been interested in the topic of influence between composers for years and have developed methods and heuristics for recognizing influence in classical music. While these methods work well for music where the score is the primary source of information, this type of analysis is not well suited for modern popular music where the audio recording itself is arguably the primary representation. This paper presents two audio content-based systems for influence recognition: a system using a spectral representation (Constant-q transform) and support vector machines and another system that obtains features by using a deep belief network and then logistic regression for classification. The system using the spectral representation provides a baseline for future comparisons and evidence to support the idea that influence recognition can be performed using information extracted from the audio signal. The other system attempts to improve performance by using a deep belief network to learn features useful for influence recognition by mapping data extracted from the audio signal to labeled influence data. A dataset of about 77,000 30-second audio clips, consisting of retail previews of popular music tracks was gathered for this work. These songs were chosen from expertly-labeled influence relationship information gathered by the editors of the AllMusic guide.'\n",
      " 'Using Consumer Behavior Data to Reduce Energy Consumption in Smart Homes: Applying Machine Learning to Save Energy without Lowering Comfort of Inhabitants This paper discusses how usage patterns and preferences of inhabitants can be learned efficiently to allow smart homes to autonomously achieve energy savings. We propose a frequent sequential pattern mining algorithm suitable for real-life smart home event data. The performance of the proposed algorithm is compared to existing algorithms regarding completeness/correctness of the results, run times as well as memory consumption and elaborates on the shortcomings of the different solutions. We also propose a recommender system based on the developed algorithm. This recommender provides recommendations to the users to reduce their energy consumption. The recommender system was deployed to a set of test homes. The test participants rated the impact of the recommendations on their comfort. We used this feedback to adjust the system parameters and make it more accurate during a second test phase. The historical dataset provided by digitalSTROM contained 33 homes with 3521 devices and over 4 million events. The system produced 160 recommendations on the first phase and 120 on the second phase. The ratio of useful recommendations was close to 10%.'\n",
      " 'Frequent Set Mining for Streaming Mixed and Large Data Frequent set mining is a well researched problem due to its application in many areas of data mining such as clustering, classification and association rule mining. Most of the existing work focuses on categorical and batch data and do not scale well for large datasets. In this work, we focus on frequent set mining for mixed data. We introduce a discretization methodology to find meaningful bin boundaries when itemsets contain at least one continuous attribute, an update strategy to keep the frequent items relevant in the event of concept drift, and a parallel algorithm to find these frequent items. Our approach identifies local bins per itemset, as a global discretization may not identify the most meaningful bins. Since the relationships between attributes my change over time, the rules are updated using a weighted average method. Our algorithm fits well in the Hadoop framework, so it can be scaled up for large datasets.'\n",
      " 'Identifying Daily Electric Consumption Patterns from Smart Meter Data by Means of Clustering Algorithms This paper presents clustering approaches applied on daily energy consumption curves of a building. Our aim is to identify a reduced set of consumption patterns for a tertiary building during one year. These patterns depend on the temperature throughout the year as well as the type of the day (working day, work-free day and school holidays). Two clustering approaches are used independently, namely the functional K- means algorithm, that takes into account the functional aspect of data and the Expectation-Maximization algorithm based on Gaussian Mixture Model (EM-GMM). The clustering results of the two algorithms are analyzed and compared. This study represents the first step towards the development of prediction models for energy consumption.'\n",
      " 'Improved Wind Power Forecasting Using Combination Methods Integration of the wind power into the existing transmission grid is an important issue due to discontinuous and volatile behavior of wind. Moreover, the power plant owners need reliable information about day-ahead power production for market operations. Therefore, wind power forecasting approaches have been gaining importance in renewable energy research area. The Wind Power Monitoring and Forecast System for Turkey (RITM) currently monitors a growing number of wind power plants in Turkey, and uses wind power measurements in addition to different numerical weather predictions to generate short-term power forecasts. Forecasting models of RITM give considerably good results individually. However, forecast combination approaches are frequently used in order not to rely on a single forecast model, and also utilize forecast diversification. In this paper, an analysis of wind power domain and the current wind power forecasting methods of RITM are presented. Then, three main forecast combination approaches, namely Lp-norm based combination, FSS (Fuzzy Soft Sets) based combination and tree-based combination, are proposed to provide better forecasts. These combination methods have been verified on forecasts data of RITM in terms of normalized mean absolute error (NMAE) metric. The experimental results show that all of the applied combination methods give lower NMAE rates for most of the wind power plants compared to individual forecasts.'\n",
      " 'A Web-Based Auction Platform for Electricity Retail Markets A web-based combinatorial reverse auction platform for electricity retail markets is designed and implemented. At consumer side, the system provides cheaper electricity consumption by means of established competitive market environment. The competitive set up allows suppliers a continuous channel of bidding and chance to increase number of their customers. The winner determination problem of combinatorial auctions - known to be NP-Hard is solved by using available commercial off the shelf optimizer. Experimental results showed that the performance critical component of the platform (i.e. the optimizer) performs quite satisfactory in terms of solution time & memory loads. We observed that there is no correlation between different number of bidders, bids per bidder and solution time & memory load values.'\n",
      " \"Optimized Small-Scaled Hybrid Energy Management of a Smart House Based on Genetic Algorithm Renewable energy sources provide both electricity and heating for experimental smart house located at renewable energy test site at Nazarbayev University. Smart house's electric and heating subsystems are supplied by PV cells and solar thermal heater respectively. Partially the system consumes the electricity from utility grid. The dynamics of the system consists of electrical and thermal parts based on the state of charge of accumulator battery stack and temperatures of the heating system and smart house itself. The goal of designed control is to maintain the states of the system inside of required ranges and simultaneously to minimize the expenses for power consumption from utility grid. The task of minimization is solved using genetic algorithm. The simulation results are obtained in MATLAB and confirm the efficiency of designed control.\"\n",
      " 'Concept of 4th Dimension for Databases In these days, the data are being more and more important for not only social or commercial aspects but also military and security aspects. Therefore, storing the data accurately and accessing it exactly are quite important issues. Currently, most databases use 3 dimension (3D) data structure to store the physical parameters of real objects, which are width, length and depth/height. If the data have the four dimension for any object, it will definitely be more useful than 3D structure. In this paper, we investigated to how the time can be used as the 4th dimension for any object and the concepts of dynamic calculation of the time in order to store it in databases. Some type of objects have been selected as base shapes such as rectangular, cylinder, sphere, ellipse, pyramid and cone, for 4th dimension objects and a sample application is given in the study in order to explain how the time dimension can be used for databases.'\n",
      " \"Probabilistic Models for One-Day Ahead Solar Irradiance Forecasting in Renewable Energy Applications Solar irradiance forecasting is an important problem in renewable energy management where any dips in solar energy generation must be made up for by reserves in order to ensure an uninterrupted energy supply. In this paper, we study several data mining methods for short term solar irradiance forecasting at a given location. In particular, we apply linear regression, probabilistic models, and naive Bayes classifier to forecast solar irradiance one day ahead, i.e., we forecast what tomorrow's solar irradiance will be like at sundown today. We evaluate the forecasting performance of our adaptations of the three models using land-based weather data from several weather stations on the island of Oahu in Hawai'i.\"\n",
      " 'Artificial Neural Network Based Abdominal Organ Segmentations: A Review There are many neural network based abdominal organ segmentation approaches from medical images. Computed tomography images were mostly used in these approaches. Applied techniques are usually based on prior information regarding position, shape, and size of organs in these methods. In the literature, there are only a few neural network based techniques that were implemented to segment abdominal organs from magnetic resonance based images. In this paper, we present these methods and their results.'\n",
      " 'A Neural Network Based Kidney Segmentation from MR Images : Preliminary Results Automated and robust kidney segmentation from medical image sequences is a very difficult task particularly because of the gray level similarities of adjacent organs, partial volume effects and injection of contrast media. In addition to these difficulties, variations in kidney shapes, positions and gray levels make automated identification and segmentation of the kidney harder. Also, different image characteristics with different scanners much more increase the difficulty of the segmentation task. Therefore, in this paper, we present an automated kidney segmentation method by using a multi-layer perceptron based approach that adapts all parameters according to images to handle all these challenging problems. The efficiency in terms of the segmentation performance is achieved by using the information from the previously segmented kidney image. The proposed approach is also efficient in terms of required processing time since it does not include pre-processing and training stages, which are very time consuming. Moreover, the unsupervised segmentation approach eliminates the common problem of most neural network based approaches that is dependency of results to the chosen data in the training stage.'\n",
      " 'An EMD Based Method for Reduction of Ballistocardiogram Artifact from EEG Studies of Evoked Potentials Multi-modality data acquisition is a topic of research that gained interest in the recent years. It provides the opportunity to gather detailed information for analysis. Simultaneous electroencephalography (EEG) and functional magnetic resonance imaging is one good example of it. The information we get after fusing data from EEG and fMRI have both high temporal and spatial resolution. On the other side, this EEG recording suffers from some additional artifacts due to the fMRI environment, in particular, the Ballistocardiogram artifact. In this article, a new method of removing Ballistocardiogram Artifact from evoked potential studies is proposed. The method does not require any reference signal or prior information. The results presented are using the data of three subjects (volunteers). The results show that the proposed method can efficiently reduce Ballistocardiogram artifact and has performed better compared to the conventional methods.'\n",
      " 'Automated Detection of Adenoviral Conjunctivitis Disease from Facial Images Using Machine Learning Nowadays scientists are focusing on diagnosing certain eye diseases using image processing. Among these diseases, Adenoviral conjunctivitis is a key eye infection to be observed and diagnosed. In this paper, digital image processing (DIP) is applied for an automated, fast and cost-effective diagnosis of conjunctivitis by physicians. In our study, we measure the vascularization and intensity of redness in pink eyes after segmenting the region of infection in corneal images to diagnose the conjunctivitis. Corneal images captured using our simple setup and processed through the proposed DIP approach successfully detects eye infections and isolates potentially contagious patients correctly 93% of the time. We were able to achieve this rate by isolating the sclera region using the automated GrabCut method that identifies the seed region from the image itself. Such adaptive isolation of region of interest overcomes challenges presented by the lightning and resolution. During this study, we evaluated the performance of known DIP methods and incorporated them in eye disease diagnosis.'\n",
      " 'A Neural Network Based Handover Management Strategy for Heterogeneous Networks One of the key challenges for improvement of quality of services (QoS) in Heterogeneous wireless networks is the design of Vertical Handover (VHO) Management strategy. VHO is required to guide the decision for a mobile terminal (MT) to handoff between different types of networks. This is an essential task to cope with various multimedia services QoS settings. In this paper, we present a machine learning scheme based on Neural Network for calls vertical handover in heterogeneous networks. The Neural Network Based Handover Management Scheme (NNBHMS) of this paper aims toward achieving seamless connectivity and Always Best Connected (ABC) call status for group mobility over a set of heterogeneous networks. The proposed scheme evaluates and creates relationships between different decision criteria related to heterogeneous networks conditions, terminal capabilities, application requirements, and user preferences. Afterward, the estimates of each attribute are forwarded to neural network to select the optimal access network. The proposed scheme is applied for vertical handover Management in heterogeneous networks offering both real time services (voice over IP services), and data Services (packet data traffic). Through the implementation of neural networks based machine learning approach, the proposed research scheme allows solving the complexity of the handover decision process resulting from the multitude dimensions of the decision criteria and the dynamicity of many of its components. The performance results evaluated through simulation show that the use of the a neural network based machine learning scheme to carry out the Handover process can enhance the QoS perceived by both types of voice and data service while fulfilling to great extent the user preference.'\n",
      " 'Resource Allocation Predictive Modeling to Optimize Virtual World Simulator Performance Virtual world simulation for military training is an emerging domain. As such, detailed analysis is required to optimize the performance the simulators. Unfortunately, due to a lack of extensive virtual world performance analysis, simulator administrators often make arbitrary resource allocations to support their environments and training scenarios. In this paper, we provide a lightweight predictive model that will be used in an automated, dynamic resource allocation system in the popular three-dimensional open-sourced virtual world simulator OpenSimulator. Prior to this investigation, only OpenSimulator developers and users with extensive experience with the platform could manually load balance the server resources based on anticipated usage. Now, with the proposed system and its predictive model, the simulator advances towards having an automated mechanism to determine the minimal critical resources that are required to support a target number of concurrent users in the virtual world.'\n",
      " 'Summary Sentence Classification Using Stylometry Summary sentence classification is an important step to generate document surrogates known as summary extracts. The quality of an extract depends much on the correctness of this step. We aim to classify potential summary sentences using a statistical learning method that models sentences according to a linguistic technique which examines writing styles, known as Stylometry. The sentences in documents are represented using a novel set of stylometric attributes. For learning, an innovative two-stage classification is set up that comprises two learners in subsequent steps: k-Nearest Neighbour and Naive Bayes. We train and test the learners with the newswire documents collected from two benchmark datasets, viz., the CAST and the DUC2002 datasets. Extensive experimentation strongly suggests that our method has outstanding performance for the single document summarization task. However, its performance is mixed for classifying summary sentences from multiple documents. Finally, comparisons show that our method performs significantly better than most of the popular extractive summarization methods.'\n",
      " 'Superposed Naive Bayes for Accurate and Interpretable Prediction Background: Data mining and machine learning techniques have been widely applied in software engineering research. However, past research has mainly focused on only prediction accuracy. Aim: The interpretability of prediction results should be accorded greater emphasis in software engineering research. A prediction model that has high accuracy and explanatory power is required. Method: We propose a new algorithm of naïve Bayes ensemble, called superposed naïve Bayes (SNB), which firstly builds an ensemble model with high prediction accuracy and then transforms it into an interpretable naïve Bayes model. Results: We conducted an experiment with the NASA MDP datasets, in which the performance and interpretability of the proposed method were compared with those of other classification techniques. The results of the experiment indicate that the proposed method can produce balanced outputs that satisfy both performance and interpretability criteria. Conclusion: We confirmed the effectiveness of the proposed method in an experiment using software defect data. The model can be extensively applied to other application areas, where both performance and interpretability are required.'\n",
      " 'Event Prioritization and Correlation Based on Pattern Mining Techniques With the growing deployment of host and network intrusion detection systems in increasingly large and complex communication networks, managing low-level events from these systems becomes critically important. A network has multiple tasks, which consist of multiple network services aiding the execution of a task. An emerging track of security research has focused on event prioritization and correlation to rank the criticality of events and reduce the number of low-level events. To prioritize and correlate events, the ongoing tasks in an enterprise network are identified, as the goal of network operators is to protect ongoing tasks when a security breach occurs. The prioritization of an event depends on the criticality of an ongoing task that is potentially threatened by the event. Additionally, in order to support network operators, we correlate all events that target the same task. A particular task may depend on multiple network services and involve multiple network devices. So, if one network service becomes unavailable, other network services will be affected over time since they Unfortunately, dependency details are often not documented and are difficult to discover by relying on human expert knowledge. In order to solve this problem, a network dependency analysis based on network traffic is conducted. We rely on pattern mining techniques to discover tasks in a monitored enterprise network. A formal description of the identified tasks is provided and events are prioritized and correlated based on this model. The pattern mining based network dependency analysis algorithm is evaluated based on a real-world network and three networks that where created with a network simulator.'\n",
      " 'Modeling and Simulation of Community Mobility Model for Next Generation Wireless Networks Using Coloured Petri Nets In order to obtain comprehensive research analysis of mobility management schemes and routing protocols for Wireless Communication, it is prerequisite that the mobility model on which the simulation is based, shows a realistic mobility pattern. A key problem with much of the literature on random models is that they produce unrealistic node movement trajectory and have limitations viz., border effect, un-sociological behavior and memory less mobility phenomenon. This paper presents a novel community mobility model, which provide a foundation for generating realistic mobility traces and mimics real-world scenarios. The analytical results validate its performance, extensive simulation experiments are conducted through steady state space analysis.'\n",
      " 'Prediction of Continuous Phenotypes in Mouse, Fly, and Rice Genome Wide Association Studies with Support Vector Regression SNPs and Ridge Regression Classifier The ranking of SNPs and prediction of phenotypes in continuous genome wide association studies is a subject of increasing interest with applications in personalized medicine and animal and plant breeding. The ranking of SNPs in case control (discrete label) genome wide association studies has been examined in several previous studies with machine learning techniques but this is poorly explored for studies with quantitative labels. Here we study ranking of SNPs in mouse, fly, and rice continuous genome wide association studies given by the popular univariate Pearson correlation coefficient and the multivariate support vector regression and ridge regression. We perform cross-validation with the support vector regression and ridge regression models on top ranked SNPs and compute correlation coefficients between true and predicted phenotypes. Our results show that ridge regression prediction with top ranked support vector regression SNPs gives the highest accuracy. On all datasets we achieve accuracies comparable to previously published values but with fewer SNPs. Our work shows we can learn parsimonious SNP models for predicting continuous labels in genome wide studies.'\n",
      " 'Random Forest with Random Projection to Impute Missing Gene Expression Data Measurement error or lack of proper experimental setup often results in invalid or missing data in gene expression studies. Small sample size and cost of re-running the experiment presents a need for an efficient missing data imputation technique. In this paper, we propose a method based on Random forest using Random projection as a data pre-processing filter. Initial results using varying missing data proportions on variety of real datasets show that the imputation process based on Random forest performs equally well or better than K-Nearest Neighbor & Support Vector Regression based methods. Using Random projection we show that dimensionality of a dataset can be reduced by 50 percent without affecting the imputation process.'\n",
      " 'Mining over a Reliable Evidential Database: Application on Amphiphilic Chemical Database In recent years, the mining of frequent itemsets from uncertain databases has attracted much attention. Several researches have been conducted using different uncertain frameworks as probabilities, fuzzy sets and, most recently, evidence theory. There is very little study paid to mining pertinent knowledge from data where reliability is questionable. In this paper, we study and extend the evidential database framework in accounting data reliability. We propose new measures of support and confidence under uncertainty that consider the reliability and extend the state-of-the-art works. The proposed framework is thoroughly experimented on a real case problem for developing classification model from a chemical database.'\n",
      " 'Class Decomposition Using K-Means and Hierarchical Clustering This paper presents a clustering-based class decomposition approach to improve the performance of classifiers. Class decomposition works by dividing each class into clusters, and by relabeling instances contained by each cluster with a new class. Several case studies used class decomposition combined with linear classifiers. While there is an essential improvement in classification accuracy because of class decomposition, the most effective clustering algorithm is not obvious. The aim of this work is to investigate the effect of two clustering algorithms, K-means and hierarchical, on class decomposition. In this work, we study class decomposition when combined with the Naive Bayes classifier using four real-world datasets. Experimental results show an improvement in classification accuracy for most of the datasets when class decomposition using both K-means and hierarchical clustering is performed. The results also show that class decomposition is not suitable for all datasets.'\n",
      " 'An Application of Classification and Class Decomposition to Use Case Point Estimation Method Use Case Points (UCP) estimation method describes the process of computing the software project size and productivity from use case diagram elements. These metrics are then used to predict the project effort at early stage of software development. The main challenges with previous models are that they were constructed based on a very limited number of observations, and using limited productivity ratios. This paper presents a new approach to predict productivity from UCP environmental factors by applying classification with decomposition technique. A class decomposition provides a number of advantages to supervised learning algorithms through segmenting classes into more homogenous classes, and therefore, increase their diversity. The proposed model is constructed and validated over two datasets that have relatively sufficient number of observations. The accuracy results are promising and have potential to increase accuracy of early effort estimation.'\n",
      " 'Improved Time Series Classification with Representation Diversity and SVM Time series classification is an important task in data mining that has been traditionally addressed with the use of similarity-based classifiers. The 1-NN DTW is typically considered the most accurate model for temporal data. Nevertheless, some authors have recently proposed ingenious alternatives to the 1-NN DTW by using diversity of time series representation or by using DTW for feature extraction. In this paper, we explore diversity of time series representations and distance functions to obtain distance features, which in turn are used to train an SVM model. We argue that the scientific community has largely neglected a vast body of unconventional distance functions, and we present empirical evidence that distance features are better than the 1-NN DTW with respect to classification accuracy.'\n",
      " 'Iterative Grammar-Based Framework for Discovering Variable-Length Time Series Motifs In recent years, finding repetitive similar patterns in time series has become a popular problem. These patterns are called time series motifs. Recent studies show that using grammar compression algorithms to find repeating patterns from the symbolized time series holds promise in discovering approximate motifs with variable length. However, grammar compression algorithms are traditionally designed for string compression. Therefore, existing work on grammar induction has not fully utilized much available information that can be used to enhance the performance of the algorithms. In this work, an iterative framework based on grammar induction is proposed. In each iteration, a revision operator called Noise Reduction Operator is applied to revise the symbolized time series string based on the rules returned from a base grammar induction algorithm. In our experiments, we show that the proposed work can find motifs of the same quality, with much faster running time compared to the state-of-the-art variable-length exact motif discovery algorithm in real world time series data.'\n",
      " \"Filer Response Time Prediction Using Adaptively-Learned Forecasting Models Based on Counter Time Series Data Ability to predict the future performance of a storage system is critical for its efficient management. A modern storage system is a very complex combination of hardware and software elements and inferring its state from those of its individual components is practically impossible. Moreover, the state of the system undergoes continuous changes due to diverse and evolving workloads, frequent configuration changes and natural degradation in components. This paper presents an approach to predict the future response time of a storage system by applying a combination of machine learning techniques on the data of its internal parameters. To the best of our knowledge, this is the first attempt to quantify the response time of a storage system directly from the time-series of its internal parameters. We present a systematic experimental setup for collecting the system data and for measuring its response time while loading the system with different standard workloads. Another novel contribution of the paper is a combination of time-series forecasting model followed by a regression model to predict the response time repeatedly in real-time. The said model is shown to be able to repeatedly predict fairly accurate 15-minutes-ahead response time values using the system data of the past 20-minutes' window. It is shown that the validation calculations typically complete within ~30 seconds on an average using a computer of moderate configurations making the presented model applicable for practically reasonable prediction horizons. The design of the model is such that it can be adaptively tuned online at regular intervals as more system data is observed.\"\n",
      " 'Dynamic Factor Mixture of Experts for Functional Time Series Modeling A new approach is introduced in this paper for dynamic modeling and dimensionality reduction from time series of curves. For this purpose, a dynamic mixture of experts model whose regression coefficients evolve from curve to curve according to a Gaussian random walk over low dimensional factors, is proposed. The resulting model is neither else than a particular state-space model involving discrete and continuous latent variables, whose parameters are learned across a sequence of curves through a dedicated variational Expectation-Maximization algorithm. The experimental study conducted on simulated sequences of curves has shown the strong potential of the proposed approach.'\n",
      " \"Inferring Hearing Loss from Learned Speech Kernels Does a hearing-impaired individual's speech reflect his hearing loss, and if it does, can the nature of hearing loss be inferred from his speech? To investigate these questions, at least four hours of speech data were recorded from each of 37 adult individuals, both male and female, belonging to four classes: 7 normal, and 30 severely-to-profoundly hearing impaired with high, medium or low speech intelligibility. Acoustic kernels were learned for each individual by capturing the distribution of his speech data points represented as 20 ms duration windows. These kernels were evaluated using a set of neurophysiological metrics, namely, distribution of characteristic frequencies, equal loudness contour, bandwidth and Q10 value of tuning curve. Our experimental results reveal that a hearing-impaired individual's speech does reflect his hearing loss provided his loss of hearing has considerably affected the intelligibility of his speech. For such individuals, the lack of tuning in any frequency range can be inferred from his learned speech kernels.\"\n",
      " 'Automatic Optimization of Localized Kernel Density Estimation for Hotspot Policing Kernel density estimation is a popular method for identifying crime hotspots for the purpose of data-driven policing. However, computing a kernel density estimate is computationally intensive for large crime datasets, and the quality of the resulting estimate depends heavily on parameters that are difficult to set manually. Inspired by methods from image processing, we propose a novel way for performing hotspot analysis using localized kernel density estimation optimized with an evolutionary algorithm. The proposed method uses local learning to address three challenges associated with traditional kernel density estimation: computational complexity, bandwidth selection, and kernel function selection. We evaluate our localized kernel model on 17 crime types from Chicago, Illinois, USA. Preliminary results indicate significant improvement in prediction performance over the traditional approach. We also examine the effect of data sparseness on the performance of both models.'\n",
      " 'Robust Kernel Embedding of Conditional and Posterior Distributions with Applications This paper proposes a novel non-parametric method to robustly embed conditional and posterior distributions to reproducing Kernel Hilbert space (RKHS). Robust embedding is obtained by the eigenvalue decomposition in the RKHS. By retaining only the leading eigenvectors, the noise in data is methodically disregarded. The non-parametric conditional and posterior distribution embedding obtained by our method can be applied to a wide range of Bayesian inference problems. In this paper, we apply it to heterogeneous face recognition and zero-shot object recognition problems. Experimental validation shows that our method produces better results than the comparative algorithms.'\n",
      " 'Conformalized Kernel Ridge Regression General predictive models do not provide a measure of confidence in predictions without Bayesian assumptions. A way to circumvent potential restrictions is to use conformal methods for constructing non-parametric confidence regions, that offer guarantees regarding validity. In this paper we provide a detailed description of a computationally efficient conformal procedure for Kernel Ridge Regression (KRR), and conduct a comparative numerical study to see how well conformal regions perform against the Bayesian confidence sets. The results suggest that conformalized KRR can yield predictive confidence regions with specified coverage rate, which is essential in constructing anomaly detection systems based on predictive models.'\n",
      " \"Automated Optimal Architecture of Deep Convolutional Neural Networks for Image Recognition Recent advancements in deep Convolutional Neural Networks (CNNs) have led to impressive progress in computer vision, especially in image classification. CNNs involve numerous hyperparameters that identify the network's structure such as depth of the network, kernel size, number of feature maps, stride, pooling size and pooling regions etc. These hyperparameters have a significant impact on the classification accuracy of a CNN. Selecting proper CNN architecture is different from one dataset to another. An empirical approach is often used in determining the near optimal value of these hyperparameters. Some recent works have tried optimization techniques for hyperparameter selection as well. In this paper, we develop a framework for hyperparameter optimization that is based on a new objective function that combines the information from the visualization of learned feature maps via deconvolutional networks, and the accuracy of the trained CNN model. Nelder-Mead Algorithm (NMA) is used in guiding the CNN architecture towards near optimal hyperparameters. Our proposed approach is evaluated on CIFAR-10 and Caltech-101 benchmarks. The experimental results indicate that the final architecture of a CNN obtained by our objective function outperforms other approaches in terms of accuracy. It is shown that our optimization framework contributes to increase in the depth of network, shrinks the size of stride and pooling sizes to obtain the best CNN architecture.\"\n",
      " 'Infrared Colorization Using Deep Convolutional Neural Networks This paper proposes a method for transferring the RGB color spectrum to near-infrared (NIR) images using deep multi-scale convolutional neural networks. A direct and integrated transfer between NIR and RGB pixels is trained. The trained model does not require any user guidance or a reference image database in the recall phase to produce images with a natural appearance. To preserve the rich details of the NIR image, its high frequency features are transferred to the estimated RGB image. The presented approach is trained and evaluated on a real-world dataset containing a large amount of road scene images in summer. The dataset was captured by a multi-CCD NIR/RGB camera, which ensures a perfect pixel to pixel registration.'\n",
      " 'Assessing Threat of Adversarial Examples on Deep Neural Networks Deep neural networks are facing a potential security threat from adversarial examples, inputs that look normal but cause an incorrect classification by the deep neural network. For example, the proposed threat could result in hand-written digits on a scanned check being incorrectly classified but looking normal when humans see them. This research assesses the extent to which adversarial examples pose a security threat, when one considers the normal image acquisition process. This process is mimicked by simulating the transformations that normally occur in of acquiring the image in a real world application, such as using a scanner to acquire digits for a check amount or using a camera in an autonomous car. These small transformations negate the effect of the carefully crafted perturbations of adversarial examples, resulting in a correct classification by the deep neural network. Thus just acquiring the image decreases the potential impact of the proposed security threat. We also show that the already widely used process of averaging over multiple crops neutralizes most adversarial examples. Normal preprocessing, such as text binarization, almost completely neutralizes adversarial examples. This is the first paper to show that for text driven classification, adversarial examples are an academic curiosity, not a security threat.'\n",
      " 'Correlating Filter Diversity with Convolutional Neural Network Accuracy This paper describes three metrics used to asses the filter diversity learned by convolutional neural networks during supervised classification. As our testbed we use four different data sets, including two subsets of ImageNet and two planktonic data sets collected by scientific instruments. We investigate the correlation between our devised metrics and accuracy, using normalization and regularization to alter filter diversity. We propose that these metrics could be used to improve training CNNs. Three potential applications are determining the best preprocessing method for non-standard data sets, diagnosing training efficacy, and predicting performance in cases where validation data is expensive or impossible to collect.'\n",
      " 'A Hierarchical Meta-Classifier for Human Activity Recognition This paper proposes a multi-level meta-classifier for identifying human activities based on accelerometer data. The training data consists of 77 subjects performing a combination of 23 different activities and monitored using a single hip-worn triaxial accelerometer. Time and frequency based features were extracted from two-second windows of raw accelerometer data and a subset of the features, together with demographic information, was selected for classification. The activities were divided into five activity groups: non-ambulatory activities, walking, running, climbing upstairs, and climbing downstairs. Multiple classification techniques were tested for each classifier level and groups. Random forests were found to perform comparatively better at each level. Based upon those tests, a 3-level hierarchical classifier, consisting of 5 random forest classifiers, was built. At the first level, the non-ambulatory activities are separated from the rest. At the second, the ambulatory activities are divided into four activity groups. At the final level, the activities are classified individually. Accuracy on test sets was found to be approximately 87% overall for individual activities and 94% at the activity group level. These results compare favorably to contemporary results in classifying human activity.'\n",
      " 'Interaction Network Representations for Human Behavior Prediction Human behavior prediction is critical to studying how healthy behavior can spread through a social network. In this work we present a novel user representation based human behavior prediction model, the User Representation-based Socialized Gaussian Process model (UrSGP). First, we present the Deep Interaction Representation Learning (Deep Interaction) model for learning latent representations of interaction social networks in which each user is characterized by a set of attributes. In particular, we consider social interaction factors and user attribute factors to build a bimodal, fixed representation of each user in the network. Our model aims to capture the evolution of social interactions and user attributes and learn the hidden correlations between them. We then use our latent features for human behavior prediction via the UrSGP model. An empirical experiment conducted on a real health social network demonstrates that our model outperforms baseline approaches for human behavior prediction.'\n",
      " \"Predicting Future Agent Motions for Dynamic Environments Understanding activities of people in a monitored environment is a topic of active research, motivated by applications requiring context-awareness. Inferring future agent motion is useful not only for improving tracking accuracy, but also for planning in an interactive motion task. Despite rapid advances in the area of activity forecasting, many state-of-the-art methods are still cumbersome for use in realistic robots. This is due to the requirement of having good semantic scene and map labelling, as well as assumptions made regarding possible goals and types of motion. Many emerging applications require robots with modest sensory and computational ability to robustly perform such activity forecasting in high density and dynamic environments. We address this by combining a novel multi-camera tracking method, efficient multi-resolution representations of state and a standard Inverse Reinforcement Learning (IRL) technique, to demonstrate performance that is better than the state-of-the-art in the literature. In this framework, the IRL method uses agent trajectories from a distributed tracker and estimates a reward function within a Markov Decision Process (MDP) model. This reward function can then be used to estimate the agent's motion in future novel task instances. We present empirical experiments using data gathered in our own lab and external corpora (VIRAT), based on which we find that our algorithm is not only efficiently implementable on a resource constrained platform but is also competitive in terms of accuracy with state-of-the-art alternatives (e.g., up to 20% better than the results reported in [1]).\"\n",
      " 'Demographic Group Prediction Based on Smart Device User Recognition Gestures We propose a novel demographic group prediction mechanism for smart device users based upon the recognition of user gestures. The core idea of our proposed approach is to utilize data from a variety of the internal environmental sensors in the device to predict useful demographics information. In order to achieve this objective, an application with several intuitive user interfaces was implemented and used to capture user data. The results presented here are based upon the data from fifty users. These captured data are integrated or fused, pre-processed, analyzed, and used as training data for a supervised machine learning predictive approach. The data reduction methods are based upon principal component analysis (PCA) and linear discriminant analysis (LDA). PCA/LDA were implemented to reduce the data feature dimensions and to improve the k-nearest neighbors (KNN) supervised classification predictions. The results of our experiment indicate that high accuracy is achieved from this method. To the best of our knowledge, this is the first research that uses user recognition gestures to predict multiple demographic groups.'\n",
      " 'Cross-Document Knowledge Discovery Using Semantic Concept Topic Model Topic models employ the Bag-of-Words (BOW) representation, which break terms into constituent words and treat words as surface strings without assuming predefined knowledge about word meaning. In this paper, we propose the Semantic Concept Latent Dirichlet Allocation (SCLDA) and Semantic Concept Hierarchical Dirichlet Process (SCHDP) based approaches by representing text as meaningful concepts rather than words, using a new model known as Bag-of-Concepts (BOC). We propose new algorithms of applying SCLDA and SCHDP into the Concept Chain Queries (CCQ) problem. The algorithms are focused on discovering new semantic relationships between two concepts across documents where relationships found reveal semantic paths linking two concepts across multiple text units. The experiments demonstrate the search quality has been greatly improved, compared with using other LDA or HDP based approaches.'\n",
      " 'Domain Ontology Induction Using Word Embeddings Ontology, the shared formal conceptualization of domain information, has been shown to have multiple applications in modeling, processing and understanding natural language text. In this work, we use distributed word vectors out of various recent language models from Deep Learning for semi-automated domain ontology creation for closed domains. We cover all major aspects of Domain Ontology Induction or Learning like concept identification, attribute identification, taxonomical and non-taxonomical relationship identification using the distributed word vectors. Preliminary results show that simple clustering based methods using distributed word vectors from these language models outperforms methods using models like LSI in ontology learning for closed domains.'\n",
      " 'Latent Topic-Semantic Indexing Based Automatic Text Summarization Automatic summarization, a difficult but pressing problem in natural language processing, aims at shortening source documents while retaining main information. In recent years, more statistical machine learning methods have been applied to automatic summarization. In this paper, we propose a novel approach for summarization, based on hierarchical Bayesian model of topic-semantic indexing (TSI) and extraction strategy of average log-likelihood. The new method is tested on Brown corpus, and its performance is analyzed by a well-designed blind experiment of one-way ANOVA on human reviews. The experimental results show that TSI model is promising on topic-driven summarization.'\n",
      " 'An Investigation of Ensemble Techniques for Detection of Spam Reviews Whether purchasing a product or searching for a new doctor, consumers often turn to online reviews for recommendations. Determining whether reviews are truthful is imperative to the consumer, as to not get misled by false recommendations. Unfortunately, it is often difficult, or impossible, for humans to ascertain the validity of a review through reading the text, however, studies have shown machine learning methods perform well for detecting untruthful reviews. Previously, no studies have examined the effects of ensemble learners on the detection of untruthful reviews, despite these techniques being effective in related text classification domains. We seek to inform other researchers of the effects of ensemble techniques on the detection of spam reviews. To this aim, we evaluate four classifiers and three ensemble techniques using those four classifiers as base learners. We compare the results of Multinomial Naïve Bayes, C4.5, Logistic Regression, Support Vector Machine, Random Forest with 100, 250, and 500 trees, and Boosting and Bagging using the base learners. We found that none of the ensemble techniques tested were able to significantly improve review spam detection over standard Multinomial Naïve Bayes and thus, are not worth the computational expense they inflict.'\n",
      " 'A Re-estimation Brain Storm Optimization to Train Hidden Markov Model for Transcription Factor Binding Site Analysis Computational analysis of transcription factor binding site (TFBS) is one of the most challenging topics in bioinformatics. A set of TFBS sequences is a type of multiple sequence alignment (MSA). Thus, the hidden Markov model (HMM), as a powerful tool to model MSA, has been extensively applied in TFBS analysis. However, with the sizes of TFBS problems, training HMM in a deterministic way is computationally intractable. While the traditional heuristic Baum-Welch (BW) algorithm depends heavily on initial conditions, evolutionary optimizatioin approaches have been applied to train the model. These methods showed reasonable results but had much to improve. In this paper, we proposed a re-estimation brain storm optimization (RBSO) algorithm to train HMM for TFBS analysis. Our hybrid algorithm combines the global optimizing ability of brain storm optimization (BSO) and the advantage on convergence speed of the BW-based re-estimation operator. The algorithm has a considerable improvement compared to traditional BSO. In comparative experiments, RBSO performed significantly better than other approaches that have been used in this problem, judging from all critical criteria including log-odds score, convergence speed and robustness. The results indicate that our algorithm is very promising in extensive use in future TFBS sequencing study.'\n",
      " 'Inferring Gene Regulatory Networks by Combining Supervised and Unsupervised Methods Supervised methods for inferring gene regulatory networks (GRNs) perform well with good training data. However, when training data is absent, these methods are not applicable. Unsupervised methods do not need training data but their accuracy is low. In this paper, we combine supervised and unsupervised methods to infer GRNs using time-series gene expression data. Specifically, we use results obtained from unsupervised methods to train supervised methods. Since the results contain noise, we develop a data cleaning algorithm to remove noise, hence improving the quality of the training data. These refined training data are then used to guide classifiers including support vector machines and deep learning tools to infer GRNs through link prediction. Experimental results on several data sets demonstrate the good performance of the classifiers and the effectiveness of our data cleaning algorithm.'\n",
      " 'Bag of Bags: Nested Multi Instance Classification for Prostate Cancer Detection Computer-aided detection (CAD) algorithms have been proposed for auto-detection of different types of cancer. CAD algorithms rely on machine learning methods to classify regions of interest in images into cancerous and healthy regions. In cancer screening, the foremost problem to solve is whether a patient has cancer, regardless of the location of cancerous regions in the organ. This allows early detection of the disease leading to a right course of action in terms of treatment to be taken. In machine learning, this problem has been formulated as multi-instance learning (MIL) where bags of instances are classified rather than the individual instances. In this paper, we propose a bag of bags (BoB) nested MIL algorithm where high-level bags (or parent bags), each contains multiple smaller bags of instances. We applied the proposed BoB MIL algorithm to prostate cancer detection problem using magnetic resonance imaging data to first detect which patients have cancer and consequently, to detect which slices in the 3D volume imaging data of the detected patients contain cancerous regions. Experimental results obtained from the imaging data of 30 patients with ground-truth data based on biopsy results show that the proposed algorithm is not only capable of detecting prostate cancer at patient level, it is also able to detect the cancerous regions at slice level of imaging data with high accuracy.'\n",
      " 'Decoding Epileptogenesis in a Reduced State Space We describe here the recent results of a multidisciplinary effort to design a biomarker that can actively and continuously decode the progressive changes in neuronal organization leading to epilepsy, a process known as epileptogenesis. Using an animal model of acquired epilepsy, we chronically record hippocampal evoked potentials elicited by an auditory stimulus. Using a set of reduced coordinates, our algorithm can identify universal smooth low-dimensional configurations of the auditory evoked potentials that correspond to distinct stages of epileptogenesis. We use a hidden Markov model to learn the dynamics of the evoked potential, as it evolves along these smooth low-dimensional subsets. We provide experimental evidence that the biomarker is able to exploit subtle changes in the evoked potential to reliably decode the stage of epileptogenesis and predict whether an animal will eventually recover from the injury, or develop spontaneous seizures.'\n",
      " 'Machine Learning for Plant Disease Incidence and Severity Measurements from Leaf Images In many fields, superior gains have been obtained by leveraging the computational power of machine learning techniques to solve expert tasks. In this paper we present an application of machine learning to agriculture, solving a particular problem of diagnosis of crop disease based on plant images taken with a smartphone. Two pieces of information are important here, the disease incidence and disease severity. We present a classification system that trains a 5 class classification system to determine the state of disease of a plant. The 5 classes represent a health class and 4 disease classes. We further extend the classification system to classify different severity levels for any of the 4 diseases. Severity levels are assigned classes 1 - 5, 1 being a healthy plant, 5 being a severely diseased plant. We present ways of extracting different features from leaf images and show how different extraction methods result in different performance of the classifier. We finally present the smartphone-based system that uses the classification model learnt to do real-time prediction of the state of health of a farmers garden. This works by the farmer uploading an image of a plant in his garden and obtaining a disease score from a remote server.'\n",
      " 'Exposing Inpainting Forgery in JPEG Images under Recompression Attacks Inpainting, originally designed in computer vision to reconstruct lost or deteriorated parts of images and videos, has been used for image tampering, including region filling and object removal to alter the truth. While several types of tampering including copy-move and seam carving forgery can now be successfully exposed in image forensics, there has been very little study to tackle inpainting forgery in JPEG images, the detection of which is extremely challenging due to the post-recompression attacks performed to cover or compromise original inpainting traces. To date, there is no effective way to detect inpainting image forgery under combined recompression attacks. To fill such a gap in image forensics and reveal inpainting forgery from the post-recompression attacks in JPEG images, we propose in this paper an approach that begins with large feature mining in discrete transform domain, ensemble learning is then applied to deal with the high feature dimensionality and to prevent the overfitting that generally happens to some regular classifiers under high feature dimensions. Our study shows the proposed approach effectively exposes inpainting forgery under post recompression attacks; especially, it noticeably improves the detection accuracy while the recompression quality is lower than the original JPEG image quality, and thus bridges a gap in image forgery detection.'\n",
      " \"Recognition and Analysis of the Contours Drawn during the Poppelreuter's Test  This study aims to digitalize the Poppelreuter's overlapping figures test. The Poppelreuter's test used in psychology and neurology to assess visual perceptual function. Its recent modification performed with pencil and paper. Replacing the pencil and paper by the tablet computer equipped with the stylus, allows recording and analyzing fine motor motions observed during the test. On the one hand, this provides an opportunity to compute the measures describing condition of the participant. On the other hand, this possess two major problems to be tackled. The first one is to recognize the contours of the overlapping objects drawn by the participant. In the case of severe neurologic disorder, dissimilarity between the etalon shape and drawn contour may be very high. The second problem is to identify errors made during the drawing. The both problems are addressed within this study. Traditional machine learning techniques K-means, k-nearest neighbors and random forest used in this study to identify drawn contours and drawing mistakes. Finally, to demonstrate applicability of the proposed approach, kinematic parameters analyzed for the pilot groups of Parkinson Disease patients and healthy individuals.\"\n",
      " 'Automatic Species Recognition Based on Improved Birdsong Analysis This work seeks to improve upon the accuracy of birdsong analysis based species recognition. We intend to accomplish this by creating a more effective bird syllable segmentation algorithms (MIRS), Support Vector machine based classifiers are used to train the features of IRS and MIRS. The experimental results show the effectiveness of the proposed algorithm.'\n",
      " 'ECG Biometric Identification Using Wavelet Analysis Coupled with Probabilistic Random Forest A novel algorithm is proposed in this study for improving the accuracy and robustness of human biometric identification using electrocardiograms (ECG) from mobile devices. The algorithm combines the advantages of both fiducial and non-fiducial ECG features and implements a fully automated, two-stage cascaded classification system using wavelet analysis coupled with probabilistic random forest machine learning. The proposed algorithm achieves a high identification accuracy of 99.43% for the MIT-BIH Arrhythmia database, 99.98% for the MIT-BIH Normal Sinus Rhythm database, 100% for the ECG data acquired from an ECG sensor integrated into a mobile phone, and 98.79% for the PhysioNet Human-ID database acquired from multiple tests within a 6-month span. These results demonstrate the effectiveness and robustness of the proposed algorithm for biometric identification, hence supporting its practicality in applications such as remote healthcare and cloud data security.'\n",
      " 'A Multifaceted Approach to Bitcoin Fraud Detection: Global and Local Outliers In the Bitcoin network, lack of class labels tend to cause obscurities in anomalous financial behaviour interpretation. To understand fraud in the latest development of the financial sector, a multifaceted approach is proposed. In this paper, Bitcoin fraud is described from both global and local perspectives using trimmed k-means and kd-trees. The two spheres are investigated further through random forests, maximum likelihood-based and boosted binary regression models. Although both angles show good performance, global outlier perspective outperforms the local viewpoint with exception of random forest that exhibits nearby perfect results from both dimensions. This signifies that features extracted for this study describe the network fairly.'\n",
      " \"Toward an Online Anomaly Intrusion Detection System Based on Deep Learning In the past twenty years, progress in intrusion detection has been steady but slow. The biggest challenge is to detect new attacks in real time. In this work, a deep learning approach for anomaly detection using a Restricted Boltzmann Machine (RBM) and a deep belief network are implemented. Our method uses a one-hidden layer RBM to perform unsupervised feature reduction. The resultant weights from this RBM are passed to another RBM producing a deep belief network. The pre-trained weights are passed into a fine tuning layer consisting of a Logistic Regression (LR) classifier with multi-class soft-max. We have implemented the deep learning architecture in C++ in Microsoft Visual Studio 2013 and we use the DARPA KDDCUP'99 dataset to evaluate its performance. Our architecture outperforms previous deep learning methods implemented by Li and Salama in both detection speed and accuracy. We achieve a detection rate of 97.9% on the total 10% KDDCUP'99 test dataset. By improving the training process of the simulation, we are also able to produce a low false negative rate of 2.47%. Although the deficiencies in the KDDCUP'99 dataset are well understood, it still presents machine learning approaches for predicting attacks with a reasonable challenge. Our future work will include applying our machine learning strategy to larger and more challenging datasets, which include larger classes of attacks.\"\n",
      " \"Android Malware Detection: Building Useful Representations The problem of proactively detecting Android Malware has proven to be a challenging one. The challenges stem from a variety of issues, but recent literature has shown that this task is hard to solve with high accuracy when only a restricted set of features, like permissions or similar fixed sets of features, are used. The opposite approach of including all available features is also problematic, as it causes the features space to grow beyond reasonable size. In this paper we focus on finding an efficient way to select a representative feature space, preserving its discriminative power on unseen data. We go beyond traditional approaches like Principal Component Analysis, which is too heavy for large-scale problems with millions of features. In particular we show that many feature groups that can be extracted from Android application packages, like features extracted from the manifest file or strings extracted from the Dalvik Executable (DEX), should be filtered and used in classification separately. Our proposed dimensionality reduction scheme is applied to each group separately and consists of raw string preprocessing, feature selection via log-odds and finally applying random projections. With the size of the feature space growing exponentially as a function of the training set's size, our approach drastically decreases the size of the feature space of several orders of magnitude, this in turn allows accurate classification to become possible in a real world scenario. After reducing the dimensionality we use the feature groups in a light-weight ensemble of logistic classifiers. We evaluated the proposed classification scheme on real malware data provided by the antivirus vendor and achieved state-of-the-art 88.24% true positive and reasonably low 0.04% false positive rates with a significantly compressed feature space on a balanced test set of 10,000 samples.\"\n",
      " 'Investigating Transfer Learners for Robustness to Domain Class Imbalance A transfer learning environment is characterized by a machine learning algorithm being trained with data from one domain (the source domain) and being tested on data from a different domain (the target domain). In a transfer learning scenario, the class probability of the source domain may be different from the class probability of the target domain, which is referred to as \"domain class imbalance\". Domain class imbalance is different from \"class imbalance\". Class imbalance refers to the condition of a single domain having unequal class probabilities. In traditional machine learning, the training and testing data are drawn from a single domain. The effects of class imbalance in traditional machine learning are well studied, however, the issue of domain class imbalance in the field of transfer learning has received little research attention. This paper provides a comparative performance test of state-of-the-art transfer learning algorithms, using a wide-range of domain class imbalance combinations. A detailed discussion on the relative performances of the different algorithms, with statistical validation, is presented for the different domain class imbalance scenarios.'\n",
      " 'Learning Fairness under Constraints: A Decentralized Resource Allocation Game We study multi-type resource allocation in multi-agent system, where some constraints are enforced upon resource providers and users. These constraints are limitations of resource types and connection availabilities, which may make the collaboration between agents infeasible. We discuss the notion of distributed resource fairness under these constraints. Then we propose a game theory and reinforcement learning based solution for collaborative resource allocation, so that resources are assigned to users fairly and tasks are assigned to resource agents efficiently. We utilize data from Google data center as our input to simulations. Results show that our learning approach outperforms a greedy and random explorations in terms of resource utilization and fairness.'\n",
      " 'Bayesian Unification of Gradient and Bandit-Based Learning for Accelerated Global Optimisation Bandit based optimisation schemes have a remarkable advantage over gradient based approaches due to their global perspective, which eliminates the danger of getting stuck at local optima. However, for continuous optimisation problems or problems with a large number of actions, bandit based approaches can be hindered by slow learning. Gradient based approaches, on the other hand, navigate quickly in high-dimensional continuous spaces through local optimisation, following the gradient in fine grained steps. However, apart from being susceptible to local optima, these schemes are also less suited for online learning due to their reliance on extensive trial-and-error before the optimum can be identified. In contrast, bandit algorithms seek to identify the optimal action (global optima) in as few steps as possible. In this paper, we propose a Bayesian approach that unifies the above two distinct paradigms in one single framework, with the aim of combining their advantages. At the heart of our approach we find a stochastic linear approximation of the function to be optimised, where both the gradient and values of the function are explicitly captured. This model allows us to learn from both noisy function and gradient observations, as well as predicting these properties across the action space to support optimisation. We further propose an accompanying bandit driven exploration scheme that uses Bayesian credible bounds to trade off exploration against exploitation. Our empirical results demonstrate that by unifying bandit and gradient based learning, one obtains consistently improved performance across a wide spectrum of problem environments. Furthermore, even when gradient feedback is unavailable, the flexibility of our model, including gradient prediction, still allows us outperform competing approaches, although with a smaller margin.'\n",
      " 'Are Accuracy and Robustness Correlated Machine learning models are vulnerable to adversarial examples formed by applying small carefully chosen perturbations to inputs that cause unexpected classification errors. In this paper, we perform experiments on various adversarial example generation approaches with multiple deep convolutional neural networks including Residual Networks, the best performing models on ImageNet Large-Scale Visual Recognition Challenge 2015. We compare the adversarial example generation techniques with respect to the quality of the produced images, and measure the robustness of the tested machine learning models to adversarial examples. Finally, we conduct large-scale experiments on cross-model adversarial portability. We find that adversarial examples are mostly transferable across similar network topologies, and we demonstrate that better machine learning models are less vulnerable to adversarial examples.'\n",
      " 'Advanced Image Classification Using Wavelets and Convolutional Neural Networks Image classification is a vital technology many people in all arenas of human life utilize. It is pervasive in every facet of the social, economic, and corporate spheres of influence, worldwide. This need for more accurate, detail-oriented classification increases the need for modifications, adaptations, and innovations to Deep learning algorithms. This paper uses Convolutional Neural Networks (CNN) to classify handwritten digits in the MNIST database, and scenes in the CIFAR-10 database. Our proposed method preprocesses the data in the wavelet domain to attain greater accuracy and comparable efficiency to the spatial domain processing. By separating the image into different subbands, important feature learning occurs over varying low to high frequencies. The fusion of the learned low and high frequency features, and processing the combined feature mapping results in an increase in the detection accuracy. Comparing the proposed methods to spatial domain CNN and Stacked Denoising Autoencoder (SDA), experimental findings reveal a substantial increase in accuracy.'\n",
      " \"Consensus Clustering: A Resampling-Based Method for Building Radiation Hybrid Maps Building Radiation Hybrid (RH) maps is a challenging process. Traditional RH mapping techniques are very time consuming, and do not work well on noisy datasets. In this presented research, we propose a new approach that uses resampling technique with consensus clustering technique to filter out unreliable markers, and build robust RH maps in a short time. The main aims of using the proposed approach is: first to reduce the mapping computational complexity, thus speeding up the mapping process. And second, to filter out unreliable markers, and map the remaining reliable markers to build robust maps. The proposed approach maps RH datasets in four steps, as follows: (1) uses Jackknife resampling technique to resample the RH dataset, and groups all resampled datasets into clusters. (2) Builds consensus clusters and filters out unreliable markers. (3) Maps the consensus clusters. (4) Connects the consensus clusters' maps to form the final map. To demonstrate the performance of our proposed approach, we compare the accuracy of the constructed maps with the corresponding physical maps. Also, we compare the running time of our constructed maps with the Carthagene tool maps running time. The results show that the proposed approach can construct robust maps in a comparatively very short time.\"\n",
      " 'An LED Based Indoor Localization System Using k-Means Clustering This paper introduces a novel visible light positioning (VLP) system using an un-supervised machine learning approach. Two transmitters consist of light emitting diodes (LEDs) which are modulated with 1 kHz and 2.5 kHz sinusoidal signals respectively. At the receiver end, the received signal strength (RSS) is calculated and a sparse grid/cube is constructed by measuring light intensity at different locations. A bilinear interpolation is then applied to create a dense grid of readings which is used for the training of a hierarchical k-means clustering system. For a given query LEDs reading, the trained clusters are used for position estimation by minimizing the distances between the readings and cluster centroids. Experimental results show that an average accuracy of 0.31m can be achieved for a room with the dimensions of 4.3 × 4 × 4 m3. We further compared the performance of two other clustering methods: k-medoids and fuzzy c-means however no significant improvement over the kmeans clustering is found.'\n",
      " 'Distributed Conformal Anomaly Detection Conformal approach to anomaly detection was recently developed as a reliable framework of classifying examples into normal and abnormal groups based on a training data set containing only normal examples. Its validity property is that a normal example, generated by the same distribution as the examples from the training set, is classified as anomaly with probability bounded from above by a pre-selected significance level. Parallel processing of big data may require a split of the training set into several sources. We also assume that the collection of data for two or more sources might be done in parallel and the data distribution may differ for these sources. The contribution of this work to conformal anomaly detection is studying the ways of keeping conformal validity when the training set is obtained from heterogeneous (differently distributed) sources.'\n",
      " \"Phase Identification in Electric Power Distribution Systems by Clustering of Smart Meter Data Accurate network and phase connectivity models are crucial to distribution system analytics, operations and planning. Although network connectivity information is mostly reliable, phase connectivity data is typically missing or erroneous. In this paper, an innovative phase identification algorithm is developed by clustering of voltage time series gathered from smart meters. The feature-based clustering approach is adopted where principal component analysis is first carried out to extract feature vectors from the raw time series. A constrained k-means clustering algorithm is then executed to separate customers/smart meters into various phase connectivity groups. The algorithm is applied on a real distribution feeder in Southern California Edison's service territory. The accuracy of the proposed algorithm is over 90%.\"\n",
      " 'Density-Based Data Pruning Method for Deep Reinforcement Learning We present a density-based Data Pruning method for Deep Reinforcement Learning (DRL) to improve learning stability and long-term memory in rare situations. The method controls density distribution in the experience pool by discarding high correlation data and preserving rare and unique data. We apply our method to Deep Q-networks (DQN) and Deep Deterministic Policy Gradients (DDPG) for testing in discrete and continuous action space, respectively. We evaluate our method on path following tasks in a simulated physical environment. Compared to other conventional methods such as First-In-First-Out (FIFO), our method provides a significant improvement in performance and learning stability, the average cumulative reward is increased by up to 21% and the standard deviation of the cumulative reward over multiple trials is reduced by 80%. In addition, long-term memory improvement is shown as the agent can remember and perform a behavior corresponding to a past rare event.'\n",
      " 'Identifying Nontechnical Power Loss via Spatial and Temporal Deep Learning Fraud detection in electricity consumption is a major challenge for power distribution companies. While many pattern recognition techniques have been applied to identify electricity theft, they often require extensive handcrafted feature engineering. Instead, through deep layers of transformation, nonlinearity, and abstraction, Deep Learning (DL) automatically extracts key features from data. In this paper, we design spatial and temporal deep learning solutions to identify nontechnical power losses (NTL), including Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) and Stacked Autoencoder. These models are evaluated in a modified IEEE 123-bus test feeder. For the same tests, we also conduct comparison experiments using three conventional machine learning approaches: Random Forest, Decision Trees and shallow Neural Networks. Experimental results demonstrate that the spatiotemporal deep learning approaches outperform conventional machine learning approaches.'\n",
      " 'Bird Call Identification Using Dynamic Kernel Based Support Vector Machines and Deep Neural Networks In this paper, we apply speech and audio processing techniques to bird vocalizations and for the classification of birds found in the lower Himalayan regions. Mel frequency cepstral coefficients (MFCC) are extracted from each recording. As a result, the recordings are now represented as varying length sets of feature vectors. Dynamic kernel based support vector machines (SVMs) and deep neural networks (DNNs) are popularly used for the classification of such varying length patterns obtained from speech signals. In this work, we propose to use dynamic kernel based SVMs and DNNs for classification of bird calls represented as sets of feature vectors. Results of our studies show that both approaches give comparable performance.'\n",
      " 'A Next-Generation Secure Cloud-Based Deep Learning License Plate Recognition for Smart Cities License Plate Recognition System (LPRS) plays a vital role in smart city initiatives such as traffic control, smart parking, toll management and security. In this article, a cloud-based LPRS is addressed in the context of efficiency where accuracy and speed of processing plays a critical role towards its success. Signature-based features technique as a deep convolutional neural network in a cloud platform is proposed for plate localization, character detection and segmentation. Extracting significant features makes the LPRS to adequately recognize the license plate in a challenging situation such as i) congested traffic with multiple plates in the image ii) plate orientation towards brightness, iii) extra information on the plate, iv) distortion due to wear and tear and v) distortion about captured images in bad weather like as hazy images. Furthermore, the deep learning algorithm computed using bare-metal cloud servers with kernels optimized for NVIDIA GPUs, which speed up the training phase of the CNN LPDS algorithm. The experiments and results show the superiority of the performance in both recall and precision and accuracy in comparison with traditional LP detecting systems.'\n",
      " \"Energy Efficient EEG Monitoring System for Wireless Epileptic Seizure Detection Wireless EEG monitoring systems have been successfully used for seizure detection outside clinical settings. The wireless EEG sensor nodes consume a considerable amount of battery energy to acquire, encode and transmit the data to the server side. In this paper, we introduce energy-efficient monitoring systems to increase the sensors' battery lifetime. Specifically, we propose a feature extraction method that is robust to artifacts and can effectively select the most discriminant features relevant to seizures. Second, we show how to use the missing at random (MAR) method to reduce the energy required at the sensor node for data transmission without compromising the seizure detection accuracy at the server side. Finally, we show how the expectation maximization (EM) method is used at the server side to accurately substitute the missing values. The performance of the proposed scheme is compared to those of the state-of-the art methods, and is shown to achieve less power consumption without compromising the seizure detection accuracy.\"\n",
      " 'Using Domain Knowledge Features for Wind Turbine Diagnostics Maximising electricity production from wind requires improvement of wind turbine reliability. Component failures result in unscheduled or reactive maintenance on turbines which incurs significant downtime and, in turn, increases production cost, ultimately limiting the competitiveness of renewable energy. Thus, a critical task is the early detection of faults. To this end, we present a framework for fault detection using machine learning that uses Supervisory Control and Data Acquisition (SCADA) data from a large 3MW turbine, supplemented with features derived from this data that encapsulate expert knowledge about wind turbines. These new features are created using application domain knowledge that is general to large horizontal-axis wind turbines, including knowledge of the physical quantities measured by sensors, the approximate locations of the sensors, the time series behaviour of the system, and some statistics related to the interpretation of sensor measurements. We then use mRMR feature selection to select the most important of these features. The new feature set is used to train a support vector machine to detect faults. The classification performance using the new feature set is compared to performance using the original feature set. Use of the new feature set achieves an F1-score of 90%, an improvement of 27% compared to the original feature set.'\n",
      " 'Improving HSDPA Traffic Forecasting Using Ensemble of Neural Networks Accurate forecasting of data traffic demand is very crucial for the profitable operation of cellular data networks because it helps in facilitating the optimization and planning of the network resources. Many machine learning regression models including Support Vector Regression and Abductive Networks have been applied to this problem, but this paper studies the concept of ensemble method for improving the forecasting accuracy. Specifically, a cooperative ensemble training strategy using two optimization algorithms is proposed to train a Neural Network model. The trained model is characterized with good forecasting performance due to the exchange of experience and knowledge of the two optimization algorithm during the training process. A dataset consisting of 44160 recordings of hourly High-Speed Data Packet Access (HSDPA) data traffic, which was collected over a period of 30 days from sixty different sites of a UMTS-based cellular operator was used to evaluate the performance of the proposed method. Experimental results show the superiority of the Neural Network model trained with the proposed ensemble training strategy over other state-of-the-art methods.'\n",
      " 'Nonlinear Metric Learning for Semi-Supervised Learning via Coherent Point Drifting In this paper, we propose a nonlinear metric learning framework to boost the performance of semi-supervised learning (SSL) algorithms. Constructed on top of Laplacian SVM (LapSVM), the proposed method learns a smooth nonlinear feature space transformation that makes the input data points more linearly separable. Coherent point drifting (CPD) is utilized as the geometric model with the consideration of its remarkable expressive power in generating sophisticated yet smooth deformations. Our framework has broad applicability, and it can be integrated with many other SSL classifiers than LapSVM. Experiments performed on synthetic and real world datasets show the effectiveness of our CPD-LapSVM over the state-of-the-art metric learning solutions in SSL.'\n",
      " 'Adaptive Thresholding and Reweighting to Improve Domain Transfer Learning for Unbalanced Data with Applications to EEG Imbalance Domain adaptation methods can be highly sensitive to class balance, particularly the usually unknown balance of the unlabeled test set. In this work, we analyze the effect of imbalance on a well-known algorithm, ARTL (Adaptation Regularization Transfer Learning) and propose four approaches for mitigating the adverse effects of imbalance. These include (1) balancing the training set for pseudo-label calculation, (2) applying adaptive thresholding to pseudo-label calculation, (3) using class reweighting in the optimization objective, and (4) applying adaptive thresholding to the output objective. We tested these methods with the UCI newsgroup dataset and on three types of imbalanced EEG (electroencephalogram) classification problems. We observed significant improvements, particularly for cases of extreme imbalance, which are not well addressed by standard classification techniques.'\n",
      " 'L1-Norm Principal-Component Analysis via Bit Flipping The K L1-norm Principal Components (L1-PCs) of a data matrix X ? ? D × N can be found optimally with cost O(2 NK ), in the general case, and O(N rank(X)K - K + 1 ), when rankX is a constant with respect to N [1],[2]. Certainly, in real-world applications where N is large, even the latter polynomial cost is prohibitive. In this work, we present L1-BF: a novel, near-optimal algorithm that calculates the K L1-PCs of X with cost O (NDmin{N, D} + N 2 (K 4 + DK 2 ) + DNK 3 ), comparable to that of standard (L2-norm) Principal-Component Analysis. Our numerical studies illustrate that the proposed algorithm attains optimality with very high frequency while, at the same time, it outperforms on the L1-PCA metric any counterpart of comparable computational cost. The outlier-resistance of the L1-PCs calculated by L1-BF is documented with experiments on dimensionality reduction and genomic data classification for disease diagnosis.'\n",
      " 'Event Based Weight Update for Learning Infinite Spike Train Supervised Learning methods for Spiking Neural Network are either able to learn spike train for a single neuron or able to learn first spike in a multilayer feedforward connection setting. The first group of learning methods do not use the computational benefits of hidden layer neuron whereas the second group of learning methods do not exploit the information transfer potential of spike train. Although, there have been few efforts to learn spike train in multilayer feedforward setting for spiking neural networks, the computational cost of these methods increases when spike train is considered for long period. We present spike event based weight update strategy that is able to learn spike train pattern in multilayer feedforward spiking neural network and is efficient and scalable for learning spike train pattern for indefinite period of time. We will compare this method with relevant spiking neural network learning algorithms based on different benchmark datasets and show the efficacy of this event based weight update learning.'\n",
      " 'Comparing Gaussian Mixture Model and Hidden Markov Model to Classify Unique Physical Activities from Accelerometer Sensor Data With the recent interest in physical therapy through sufficient physical activity, considerable efforts have been made to monitor and classify daily human activities, especially for people who need physical rehabilitation. In our previous study, we designed a classifier to identify 25 unique physical activities performed by 92 healthy participants between the ages of 20 and 65. In this study, with the use of a GENEActiv accelerometer to monitor a wide range of daily activities, we present a learning approach to identify unique activities performed by a varied group of participants with various health conditions. The dataset is comprised of 99 senior participants and 23 participants who are significantly taller in height than the general population, performing 8 unique activities. We have extracted 130 different features in time and frequency domain and selected the most efficient features with the sequential forward selection algorithm. With two stages of classification, the first is utilized for combining similar classes, and the second determines the final decision. We have tested two classifiers for our learning approach, the Gaussian mixture models (GMMs) and the hidden Markov models (HMMs) and compared their performances. We have improved the GMM classifier from our previous study and it has shown more promising results for this dataset. We achieved an accuracy of 88.92% when classifying the 8 unique activities with GMM and 93.5% with HMM when classifying 7 activities.'\n",
      " \"A Probabilistic Programming Approach for Outlier Detection in Healthcare Claims Healthcare is an integral component in people's lives, especially for the rising elderly population. Medicare is one such healthcare program that provides for the needs of the elderly. It is imperative that these healthcare programs are affordable, but this is not always the case. Out of the many possible factors for the rising cost of healthcare, claims fraud is a major contributor, but its impact can be lessened through effective fraud detection. We propose a general outlier detection model, based on Bayesian inference, using probabilistic programming. Our model provides probability distributions rather than just point values, as with most common outlier detection methods. Credible intervals are also generated to further enhance confidence that the detected outliers should in fact be considered outliers. Two case studies are presented demonstrating our model's effectiveness in detecting outliers. The first case study uses temperature data in order to provide a clear comparison of several outlier detection techniques. The second case study uses a Medicare dataset to showcase our proposed outlier detection model. Our results show that the successful detection of outliers, which indicate possible fraudulent activities, can provide effective and meaningful results for further investigation within medical specialties or by using real-world, medical provider fraud investigation cases.\"\n",
      " 'Automatic Algorithm Selection in Computational Software Using Machine Learning Computational software programs, such as Maple and Mathematica, heavily rely on superfunctions and meta-algorithms to select the optimal algorithm for a given task. These meta-algorithms may require intensive mathematical proof to formulate, incur large computational overhead, or fail to consistently select the best algorithm. Machine learning demonstrates a promising alternative for automatic algorithm selection by easing the design process and overhead while also attaining high accuracy in selection. In a case study on the resultant superfunction, a trained neural network is able to select the best algorithm out of the four available 86% of the time in Maple and 78% of the time in Mathematica. When used as a replacement for pre-existing meta-algorithms, the neural network brings about a 68% runtime improvement in Maple and 49% improvement in Mathematica. Random forests, k-nearest neighbors, and both linear and RBF kernel SVMs are also compared to the neural network model, the latter of which offers the best performance out of the tested machine learning methods.'\n",
      " 'System-Level Test Case Prioritization Using Machine Learning Regression testing is the common task of retesting software that has been changed or extended (e.g., by new features) during software evolution. As retesting the whole program is not feasible with reasonable time and cost, usually only a subset of all test cases is executed for regression testing, e.g., by executing test cases according to test case prioritization. Although a vast amount of methods for test case prioritization exist, they mostly require access to source code (i.e., white-box). However, in industrial practice, system-level testing is an important task that usually grants no access to source code (i.e., black-box). Hence, for an effective regression testing process, other information has to be employed. In this paper, we introduce a novel technique for test case prioritization for manual system-level regression testing based on supervised machine learning. Our approach considers black-box meta-data, such as test case history, as well as natural language test case descriptions for prioritization. We use the machine learning algorithm SVM Rank to evaluate our approach by means of two subject systems and measure the prioritization quality. Our results imply that our technique improves the failure detection rate significantly compared to a random order. In addition, we are able to outperform a test case order given by a test expert. Moreover, using natural language descriptions improves the failure finding rate.'\n",
      " 'Detecting Smooth Cluster Changes in Evolving Graphs Clustering vertices in graphs or in sequences of graphs has important applications in network science, bioinformatics, and other areas. Most research to date has focused on static graphs or sequences where the number of vertices does not change. We propose a new algorithm that successfully partitions the vertices of a graph sequence into smooth clusters, even when the number of vertices is allowed to vary over time. Our approach uses spectral clustering and relies on applying the k partition problem to a graph constructed from the input graph sequence. Several experiments demonstrate the performance of our method and its advantages over existing methods.'\n",
      " 'A Privacy-Preserving Solution for the Bipartite Ranking Problem In this paper, we propose an efficient solution for the privacy-preserving of a bipartite ranking algorithm. The bipartite ranking problem can be considered as finding a function that ranks positive instances (in a dataset) higher than the negative ones. However, one common concern for all the existing schemes is the privacy of individuals in the dataset. That is, one (e.g., a researcher) needs to access the records of all individuals in the dataset in order to run the algorithm. This privacy concern puts limitations on the use of sensitive personal data for such analysis. The RIMARC (Ranking Instances by Maximizing Area under the ROC Curve) algorithm solves the bipartite ranking problem by learning a model to rank instances. As part of the model, it learns weights for each feature by analyzing the area under receiver operating characteristic (ROC) curve. RIMARC algorithm is shown to be more accurate and efficient than its counterparts. Thus, we use this algorithm as a building-block and provide a privacy-preserving version of the RIMARC algorithm using homomorphic encryption and secure multi-party computation. Our proposed algorithm lets a data owner outsource the storage and processing of its encrypted dataset to a semi-trusted cloud. Then, a researcher can get the results of his/her queries (to learn the ranking function) on the dataset by interacting with the cloud. During this process, neither the researcher nor the cloud learns any information about the raw dataset. We prove the security of the proposed algorithm and show its efficiency via experiments on real data.'\n",
      " 'Temporal Link Prediction Using Time Series of Quasi-Local Node Similarity Measures Evolving networks, which are composed of objects and relationships that change over time, are prevalent in many real-world domains and have become an significant research topic in recent years. Most of the previous link prediction studies neglect the evolution of the network over time and mainly focus on the predicting the future links based on a static features of nodes and links. However, real-world networks have complex dynamic structures and non-linear varying topological features, which means that both nodes and links of the networks may appear or disappear. These dynamicity of the networks make link prediction a more challenging task. To overcome these difficulties, link prediction in such networks must model nonlinear temporal evolution of the topological features and link occurrences information of the network structure simultaneously. In this article, we propose a novel link prediction method based on NARX Neural Network for evolving networks. Our model first calculates similarity scores based on quasi-local measures for each pair of nodes in different snapshots of the network and create time series for each pair. Then, NARX network is effectively applied to prediction of the future node similarity scores by using past node similarities and node connectivities. The proposed method is tested on DBLP coauthorship networks. It is shown that combining time information with node similarities and node connectivities improves the link prediction performance to a large extent.'\n",
      " 'DERIV: Distributed In-Memory Brand Perception Tracking Framework Social media captures voice of customers at a rapid pace. Consumer perception of a brand is crucial to its success. Current techniques for measuring brand perception using lengthy surveys of handpicked users in person, by mail, phone or online are time consuming and increasingly inadequate. A more effective technique to measure brand perception is to interpret customer voice directly from social media and other open data. In this work we present DERIV, a DistributEd, in-memoRy framework for trackIng consumer Voice based on a brand perception measure using storylines generated from open data. The framework measures perception of a brand in comparison to peer brands with in-memory distributed algorithms utilizing supervised machine learning techniques. Experiments performed with open data and models built with storylines of known peer brands show the technique as highly accurate and effective in capturing brand perception.'\n",
      " 'Recommendation Model Based on a Contextual Similarity Measure Recommendation technique is a personalized search used to assist a user access information/services that are related to his preferences and interests, or to the preferences and interests of similar users. The main challenge of personalized Information Retrieval is the modeling and the integration of user profiles. In this paper, we propose a generic model of user profiles based on the search history of users delimited by several search sessions. These profiles are based on weighted topical graphs and are integrated into a hybrid data recommendation process. To evaluate the proposed system a prototype is developed. The results are quite encouraging; they showed that our model is able to help users when searching for items.'\n",
      " \"Macro-Optimization of email Recommendation Response Rates Harnessing Individual Activity Levels and Group Affinity Trends Recommendation emails are among the best ways to re-engage with customers after they have left a website. While on-site recommendation systems focus on finding the most relevant items for a user at the moment (right item), email recommendations add two critical additional dimensions: who to send recommendations to (right person) and when to send them (right time). It is critical that a recommendation email system not send too many emails to too many users in too short of a time-window, as users may unsubscribe from future emails or become desensitized and ignore future emails if they receive too many. Also, email service providers may mark such emails as spam if too many of their users are contacted in a short time-window. Optimizing email recommendation systems such that they can yield a maximum response rate for a minimum number of email sends is thus critical for the long-term performance of such a system. In this paper, we present a novel recommendation email system that not only generates recommendations, but which also leverages a combination of individual user activity data, as well as the behavior of the group to which they belong, in order to determine each user's likelihood to respond to any given set of recommendations within a given time period. In doing this, we have effectively created a meta-recommendation system which recommends sets of recommendations in order to optimize the aggregate response rate of the entire system. The proposed technique has been applied successfully within CareerBuilder's job recommendation email system to generate a 50% increase in total conversions while also decreasing sent emails by 72%.\"\n",
      " \"Course Learning Outcome Performance Improvement: A Remedial Action Classification Based Approach Continuous Improvement is an essential element in any quality or accreditation process within academia or even industry. To address shortcomings in the attainment of Course Learning Outcomes (CLO's), it is often necessary to suggest Remedial Actions that vary depending on the domain of the CLO. In fact, taking a non-effective action can result in a waste of time for instructors and students missing an opportunity to overcome weaknesses related to the assessed learning outcome. In this paper, we adopt a supervised classification approach to model this problem by learning from previously applied remedial actions that showed positive results in the improvement of students' attainment of a given CLO. Firstly, a Remedial Actions dataset has been created from different sources and multiple semesters. Then several well-known classification techniques were applied to the dataset showing positive classification accuracy. One of the most accurate classifiers was used to support faculties in predicting the appropriate remedial action for new poorly attained CLOs.\"\n",
      " \"Extending Soft Sets towards the Optimality of Decision Based on Multiple Decisions over the Same Data Soft sets are integrated with fuzzy logic in this paper and this research work further extends the Cagman's work on soft sets.It makes parametric values associated with every individual object of Extended Soft Set in fuzzy form. This increases the decision capability of soft sets approach to distinguish one object from another based on their fuzzy parameter values. Further, we prove several fuzzy soft operations based on a new concept. Furthermore, we provide the concept of and-row operation which describes the product of soft sets with fuzzy parameter values. Then the sum operation on and-row product construct a decision making approach. This increases the capability for multiple decision makers on the same data to reach the final selection based on their individual conclusion.\"\n",
      " 'A Formal Design for the Lexical and Syntax Analyzer of a Pedagogically Effective Subset of C++ In this article, we have argued that a programming language can be improved for both teaching and learning by extracting its simpler subset, and by enforcing some useful constraints. We have further chosen a well known first programming language C++, and have defined its pedagogically effective subset, named Eazy, for teaching a first course in computer programming, generally known as CS1. In order to enforce the usage of the defined subset and to apply the constraints we need to modify the preprocessor of the language. To this end, we present a formal design for the lexical analyzer, and syntax analyzer for Eazy.'\n",
      " 'Analysis for Status of the Road Accident Occurance and Determination of the Risk of Accident by Machine Learning in Istanbul The traffic has been transformed into the difficult structure in points of designing and managing by the reason of increasing number of vehicle. This situation has discovered road accidents problem, influenced public health and country economy and done the studies on solution of the problem. Large calibrated data agglomerations have increased by the reasons of the technological improvements and data storage with low cost. Arising the need of accession to information from this large calibrated data obtained the corner stone of the data mining. In this study, assignment of the most compatible machine learning classification techniques for road accidents estimation by data mining has been intended.'\n",
      " 'Classifying Educational Lectures in Low-Resource Languages Classifying educational resources such as videos and articles can be challenging in low-resource languages due to lack of appropriate tools and sufficient labeled data. To overcome this problem, a crosslingual classification method that utilizes resources created in one high-resource language, such as English, to perform classification in many low-resource languages, is proposed. Data scarcity issue is prevented by transferring information from highresources languages to the low-resources ones. First, word embeddings are extracted using one of the frameworks proposed previously, then classifiers are trained using the highresource language documents. Two versions of the method that use different higher-level composition functions are implemented and compared.'\n",
      " 'k-Means Partition of Monthly Average Insolation Period Data for Turkey Solar power penetration has made the site-specific energy ratings an essential necessity for utilities, independent systems operators and regional transmission organizations. Since, it leads to the reliable and efficient energy production with the increased levels of solar power integration. This study concentrates on the partitional clustering analysis of monthly average insolation period data for the 75 provinces in Turkey. Together with the k-means clustering algorithm, we use Pearson Correlation, Cosine, Squared Euclidean and City-Block distance measures for the high-dimensional neighborhood measurement and utilize the silhouette width for validating the achieved clustering results. In consequence of comparing the star glyph plots with the k-means clustering results, the most productive and the most unfavorable places among all provinces are mined on the basis of monthly average insolation period.'\n",
      " 'Hourly Solar Irradiance Forecasting Based on Machine Learning Models In recent years, many research studies are conducted into the use of smart meters data for developping decision-making tools including both analytical, forecasting and display purposes. Forecasting energy generation or forecasting energy consumption demand are indeed central problems for urban stakeholders (electricity companies and urban planners). These issues are helpful to allow them ensuring an efficient planning and optimization of energy resources. This paper investigates the problem for forecasting the hourly solar irradiance within a Machine Learning (ML) framework using Similarity method (SIM), Support Vector Machine (SVM) and Neural Network (NN). These approaches rely on a methodology which takes into account the previous hours of the predicting day and also the days having the same number of sunshine hours in the history. The study is conducted on a real data set collected on the Paris suburb of Alfortville. A comparison with two time series approaches namely Naive method and Autoregressive Moving Average Model (ARMA) is performed. This study is the first step towards the development of the hourly solar irradiance forecasting hybrid models.'\n",
      " 'Applying the Meta-heuristic Prediction Algorithm for Modeling Power Density in Wind Power Plant In this paper, a robust artificial intelligence (AI) algorithm is applied to overcome challenges at power density prediction especially at the installation process of wind power plant. This algorithm also explores relationships between the meteorological parameters and power density. Importance degree of parameters on power density is converted numerical weighting values independently from each other. Thus, the effects of the wind speed, the wind direction, the temperature, the damp, the pressure on power density could be modelled. Besides, experimental study shows that the prediction accuracy and stability of the applied method superior than traditional AI-based techniques.'\n",
      " 'Faults Investigation of Transformer Windings Using the Frequency Response Analysis FRA This present paper focuses on the modeling of a real coil in order to diagnosis. This winding includes 05 discs of height (5 × 178) mm and containing 30 turns each on three layers. After validation of the adopted model, we performed parametric changes that reflect various defects in the winding to perform detection and investigation of fault location in the winding using the FRA method. Obtained results can be a tool in the field of machine learning.'\n",
      " 'A Study on Effects of Different Control Period of Neural Network Based Reference Modified PID Control for DC-DC Converters This paper studies about computational burden of a reference modified PID with a neural network prediction for dc-dc converters. Flexible control methods are required to realize a superior transient response since the converter has a nonlinear behavior. However, the computational burden becomes a problem to implement the control to computation devices. In this paper, the neural network is adopted to improve the transient response of output voltage of the dc-dc converter under the consideration of its computational burden. The neural network computation part has a longer computation period than the PID main control part. It can be possible since the neural network gives more than one predictions which are required for the reference modification for each main control period. Therefore, the reference modification can be adopted on every main control period. From results, it is confirmed that the proposed method can improve the transient response effectively with reducing computational burden of neural network control.'\n",
      " 'Enhanced Approach to Detection of SQL Injection Attack In recent years, many financial sectors are evolving with huge numbers of web applications, which plays a crucial role in organizations to make important decisions. Considering this, the data has to be secured in order to prevent it from any attacks which lead to a huge loss. One of the topmost attacks in the database is SQL injection attack, is injecting some malicious query into the database causing serious threats. This paper proposes an enhanced approach to dynamic query matching technique by imposing a sanitizer for quick and easy detection of attack.'\n",
      " 'Towards Web Spam Filtering Using a Classifier Based on the Minimum Description Length Principle The steady growth and popularization of the Web has led spammers to develop techniques to circumvent search engines aiming good visibility to their web pages in search results. They are responsible for serious problems such as dissatisfaction, irritation, exposure to unpleasant or malicious content, and financial loss. Despite different machine learning approaches have been used to detect web spam, many of them suffer with the curse of dimensionality or require a very high computational cost impeding their employment in real scenarios. In this way, there is still a big effort to develop more advanced methods that at the same time are able to prevent overfitting and fast to learn. To fill this gap, we present the MDLClass, a classifier technique based on the minimum description length principle, applied to the context of web spam filtering. The proposed method is very efficient, lightweight, multi-class, and fast. We also evaluated a new approach to detect web spam that combines the predictions obtained by the classifiers using content-based, link-based, and transformed link-based features. In our experiments, we employed two real, public and large datasets: the WEBSPAM-UK2006 and the WEBSPAM-UK2007. The results indicate that the proposed MDLClass and ensemble of predictions using different types of features are promising in the task of web spam filtering.'\n",
      " 'Early Identification of Vulnerable Software Components via Ensemble Learning Software components, which are vulnerable to being exploited, need to be identified and patched. Employing any prevention techniques designed for the purpose of detecting vulnerable software components in early stages can reduce the expenses associated with the software testing process significantly and thus help building a more reliable and robust software system. Although previous studies have demonstrated the effectiveness of adapting prediction techniques in vulnerability detection, the feasibility of those techniques is limited mainly because of insufficient training data sets. This paper proposes a prediction technique targeting at early identification of potentially vulnerable software components. In the proposed scheme, the potentially vulnerable components are viewed as mislabeled data that may contain true but not yet observed vulnerabilities. The proposed hybrid technique combines the supports vector machine algorithm and ensemble learning strategy to better identify potential vulnerable components. The proposed vulnerability detection scheme is evaluated using some Java Android applications. The results demonstrated that the proposed hybrid technique could identify potentially vulnerable classes with high precision and relatively acceptable accuracy and recall.'\n",
      " 'Building a Platform for Software-Defined Networking Cybersecurity Applications The emerging technology of Software-Defined Networking (SDN) affords a platform and architecture which is dynamic, manageable, cost-effective, and adaptable, making it ideal for many applications that are high-bandwidth and dynamic in nature. As this technology grows and matures, there is a need for cybersecurity applications to be designed, developed and evaluated. In this paper, we propose a development environment configuration to build security applications targeting the SDN-controller in an effort to explore the technology and the resources available to teach and research the platform from a security application development perspective.'\n",
      " \"Identifying Gender from SMS Text Messages Short message service (SMS) has become a very popular medium for communication due to its convenience and low cost. SMS text messaging makes it easy to provide a false name, age, gender, and location in order to hide one's true identity. Consequently it has become important to establish new cyber forensics methods, such as detecting SMS message authors, as a post-hoc analysis technique deemed useful in criminal persecution cases. In this paper, we propose a new combined method for authorship classification of gender of SMS text messages, which combines machine learning algorithms with text processing features to increase the prediction accuracy of the author gender classification. We were able to achieve 72.39 accuracy level with J48 classification algorithm supported by text processing.\"\n",
      " 'Security Perspective of Biometric Recognition and Machine Learning Techniques Biometric systems may be used to create a remote access model on devices, ensure personal data protection, personalize and facilitate the access security. Biometric systems are generally used to increase the security level in addition to the previous authentication methods and they seen as a good solution. Biometry occupies an important place between the areas of daily life of the machine learning. In this study;the techniques, methods, technologies used in biometric systems are researched, machine learning techniques used biometric applications are investigated for the security perspective, the advantages and disadvantages that these techniques provide are given. The studies in the literature between 2010-2016 years, used algorithms, technologies, metrics, usage areas, the machine learning techniques used for different biometric systems such as face, palm prints, iris, voice, fingerprint recognition are researched and the studies made are evaluated. The level of security provided by the use of biometric systems by developed using machine learning and disadvantages that arise in the use of these systems are stated in detail in the study. Also, impact on people of biometric methods in terms of ease of use, security and usages areas are examined.'\n",
      " 'A Web Based Pipeline Tool for the Combination of Logic Conditions for NGS Data Development of software tools to analyze next-generation sequencing (NGS) data is one of the urgent tasks in bioinformatics field. Currently, lots of next-generation sequencing data analysis software has been developed. However, most of them only support one type of analyses such as sequence alignments or function annotations by command lines. Therefore, a friendly user interface of NGS data with fewer configurations is necessary. In this paper, a web based automatic pipeline running on high performance computing environment was introduced. The raw data was generated from Illumine sequencing instrument. The GATK based parallel commutating scheme is used to control and generate the result. The pipeline starts from fastQ file uploaded by the graphical interface. Then the data will be analyzed automatically.'\n",
      " 'A Parallel K-Medoids Algorithm for Clustering based on MapReduce K-Medoids algorithm is a partition-based algorithm, which has the characteristics of simple implementation, strong robustness, and high accuracy. However, it has some disadvantages, such as strong dependence on the selection of initial center, the unknown number of classification K, high resource cost of frequent iteration of the algorithm, and poor clustering effect for mass data. In order to solve these problems, the original K-Medoids algorithm was improved by introducing the Canopy algorithm and the Max-Min distance algorithm, and K points were selected as the initial center of the cluster. In the era of big data, we use the MapReduce computing framework to parallelize the algorithm. The experimental results show that: the improved clustering algorithm not only has a good speedup, but also improves the clustering accuracy and convergence, and shows a large performance advantage in dealing with large-scale data.'\n",
      " 'A Big Data Analytics Framework for Supporting Multidimensional Mining over Big Healthcare Data Nowadays, a great deal of attention is being devoted to big data analytics in complex healthcare environments. Fetal growth curves, which are a classical case of big healthcare data, are used in prenatal medicine to early detect potential fetal growth problems, estimate the perinatal outcome and promptly treat possible complications. However, the currently adopted curves and the related diagnostic techniques have been criticized because of their poor precision. New techniques, based on the idea of customized growth curves, have been proposed in literature. In this perspective, the problem of building customized or personalized fetal growth curves by means of big data techniques is discussed in this paper. The proposed framework introduces the idea of summarizing the massive amounts of (input) big data via multidimensional views on top of which well-known Data Mining methods like clustering and classification are applied. This overall defines a multidimensional mining approach, targeted to complex healthcare environments. A preliminary analysis on the effectiveness of the framework is also proposed.'\n",
      " 'An Effective and Efficient Similarity-Matrix-Based Algorithm for Clustering Big Mobile Social Data Nowadays a great deal of attention is devoted to the issue of supporting big data analytics over big mobile social data. These data are generated by modern emerging social systems like Twitter, Facebook, Instagram, and so forth. Mining big mobile social data has been of great interest, as analyzing such data is critical for a wide spectrum of big data applications (e.g., smart cities). Among several proposals, clustering is a well-known solution for extracting interesting and actionable knowledge from massive amounts of big mobile (geo-located) social data. Inspired by this main thesis, this paper proposes an effective and efficient similarity-matrix-based algorithm for clustering big mobile social data, called TourMiner, which is specifically targeted to clustering trips extracted from tweets, in order to mine most popular tours. The main characteristic of TourMiner consists in applying clustering over a well-suited similarity matrix computed on top of trips. A comprehensive experimental assessment and analysis over Twitter data finally comfirms the benefits coming from our proposal.'\n",
      " \"Hedonic Housing Theory \\x97 A Machine Learning Investigation The hedonic pricing theory suggests that house is a differ-entiated commodity, whose value depends on its hetero-geneous characteristics. Application of the theory has been well implemented using OLS Regression. Our study investigates this econometric concept using machine learning algorithms. An improved pricing will benefit buyers, sellers, investors, banks and real estate professionals. Normality test for the experiment was done using Chi-Square Quantile-Quantile plot and Henze-Zirkler's Multivariate Normality Test. Statistical relationship was based on correlation matrix, Kaiser-Meyer-Olkin and Bartlett tests. Support Vector Regression (SVR), K-Nearest Neighbor (K-NN) and Principal Component Re-gression (PCR) were used as learning algorithms. Per-formance comparison of the learning algorithms was done using spearman's rho correlation coefficient. The performance of the model showed that PCR has a slight edge over SVR and K-NN. Also, the study validated the suitability and substitutability of PCR, SVR and K-NN in the implementation of the hedonic pricing theory.\"\n",
      " 'Feedforward Neural Networks for Predicting the Duration of Maintained Software Projects Once a software project has been developed and delivered, any modification to it corresponds to maintenance. Software maintenance (SM) involves modifications to keep a software project usable in a changed or a changing environment, reactive modifications to correct discovered faults, and modifications to improve performance or maintainability. Since the duration of SM should be predicted, in this study, after a statistical analysis of projects maintained on several platforms and programming languages generations, data sets were selected for training and testing multilayer feedforward neural networks (i.e., multilayer perceptron, MLP). These data sets were obtained from the International Software Benchmarking Standards Group. Results based on Wilcoxon statistical tests show that prediction accuracy with the MLP is statistically better than that with the statistical regression models when software projects were maintained on (1) Mid Range platform and coded in programming languages of third generation, and (2) Multi platform and coded in programming languages of fourth generation.'\n",
      " 'Equipment Condition Diagnosis and Fault Fingerprint Extraction in Semiconductor Manufacturing As the high-tech production system gets more complex, Equipment Condition Diagnosis (ECD) in semiconductor manufacturing for Fault Detection and Classification (FDC) is becoming more and more challenging than ever. This paper uses well-known machine learning techniques such as Support Vector Machine (SVM), K-Means clustering and Self-Organizing Map (SOM) to develop an efficient ECD model. The process normality is checked by SVM following by decomposing the process dynamics via K-Means. The abnormal observations are then projected into normal models built by Principal Component Analysis (PCA). Finally, by calculating the contribution values of out-of-control observations, different fault fingerprints with corresponding fault root are extracted again by K-Means. The impact of clustering techniques is investigated by comparing K-Means, SOM, and hierarchical clustering. An empirical study was conducted in collaboration with the leading semiconductor company in France to validate the methodology. The result shows that the proposed approach can effectively detect abnormal observations as well as automatically classify the fault fingerprints to give evident guidelines in explaining the detected faults.'\n",
      " 'A Hybrid Machine Learning Approach for Planning Safe Trajectories in Complex Traffic-Scenarios Planning of safe trajectories with interventions in both lateral and longitudinal dynamics of vehicles has huge potential for increasing the road traffic safety. Main challenges for the development of such algorithms are the consideration of vehicle nonholonomic constraints and the efficiency in terms of implementation, so that algorithms run in real time in a vehicle. The recently introduced Augmented CL-RRT algorithm is an approach that uses analytical models for trajectory planning based on the brute force evaluation of many longitudinal acceleration profiles to find collision-free trajectories. The algorithm considers nonholonomic constraints of the vehicle in complex road traffic scenarios with multiple static and dynamic objects, but it requires a lot of computation time. This work proposes a hybrid machine learning approach for predicting suitable acceleration profiles in critical traffic scenarios, so that only few acceleration profiles are used with the Augmented CL-RRT to find a safe trajectory while reducing the computation time. This is realized using a convolutional neural network variant, introduced as 3D-ConvNet, which learns spatiotemporal features from a sequence of predicted occupancy grids generated from predictions of other road traffic participants. These learned features together with hand-designed features of the EGO vehicle are used to predict acceleration profiles. Simulations are performed to compare the brute force approach with the proposed approach in terms of efficiency and safety. The results show vast improvement in terms of efficiency without harming safety. Additionally, an extension to the Augmented CL-RRT algorithm is introduced for finding a trajectory with low severity of injury, if a collision is already unavoidable.'\n",
      " 'Efficient Content Replacement in Wireless Content Delivery Network with Cooperative Caching Wireless content delivery networks (WCDNs) have received attention as a promising solution to reduce the network congestion caused by rapidly growing demands for mobile content. The amount of reduced congestion is intuitively proportional to the hit ratio in a WCDN. Cooperation among cache servers is strongly required to maximize the hit ratio in a WCDN where each cache server is equipped with a small-size cache storage space. In this paper, we address a content replacement problem that deals with how to manage contents in a limited cache storage space in a reactive manner to cope with a dynamic content demand over time. As a new challenge, we apply reinforcement learning, which is Q-learning, to the content replacement problem in a WCDN with coooperative caching. We model the content replacement problem as a Markov Decision Process (MDP) and finally propose an efficient content replacement strategy to maximize the hit ratio based on a multi-agent Q-learning scheme. Simulation results exhibit that the proposed strategy contributes to achieving better content delivery performance in delay due to a higher hit ratio, compared to typical existing schemes of least recently used (LRU) and least frequently used (LFU).'\n",
      " \"Spatial Dependency and Hedonic Housing Regression Model The location of a real estate property has a considerable impact on its appraised value. Accounting for geograph-ical information eliminates some reducible errors in the accuracy of a hedonic housing regression model. An im-proved performance will benefit home buyers, sellers, government and real estate professionals. This paper investigates the spatial dependency and substitutability of submarket and geospatial attributes in a hedonic housing regression model using mutual information (MI) and variance inflation factor (VIF). Best subset linear regression and regression tree predictive models were built as learning algorithms. Bayesian Information Criterion (BIC) and Residual Mean Deviance (RDM) measured the performance of the linear regression and regression trees respectively. The BIC of the linear regression model indicated a best fit at 14 and 11 variables for submarket and geospatial models respectively. Optimization of the submarket tree was attained with 9 parameters comprising of 15 terminal nodes, while 7 parameters comprising of 13 terminal nodes achieved optimization in the geospa-tial tree. While geospatial models have a slight edge over the submarket model, the experiment suggested the substi-tutability of the models. The dataset consisted of single family's homes in 8 counties between January and De-cember 2006 extracted from the Multiple Listing Service repository.\"\n",
      " 'Constructing a Deep Regression Model Utilizing Cascaded Sparse Autoencoders and Stochastic Gradient Descent This paper discusses utilizing sparse autoencoders for building regression models in order to predict real-valued timeseries data. The focus of this research is on exploiting and learning from the determining features of continuous data via stacked autoencoders, thus increasing the prediction accuracy of regression method. Archi-tecture comprising different layers of sparse autoencod-ers, where each level of autoencoders are trained based on the standard (typical) method are implemented and analyzed. In order to enhance the accuracy of the typical model of training autoencoders, cascaded model that benefits from the fusion of low-and high-level features is proposed. The objective is to improve vehicular traffic flow forecasting, since this area is a research field in pro-gress that impacts daily life. The SGD algorithm at the top level of deep architectures serves as the regression method. Evaluations are based on the precision accuracy of the algorithms applied to forecasting the traffic flow of a location down a key highway using the historical traffic data of several locations ahead in the Twin Cities Metro area of Minneapolis.'\n",
      " 'A Novel Algorithm for Dynamic Clustering: Properties and Performance In this paper, we present a dynamic clustering algorithm that efficiently deals with data streams and achieves several important properties which are not generally found together in the same algorithm. The dynamic clustering algorithm operates online in two different time-scale stages, a fast distance-based stage that generates micro-clusters and a density-based stage that groups the micro-clusters according to their density and generates the final clusters. The algorithm achieves novelty detection and concept drift thanks to a forgetting function that allows micro-clusters and final clusters to appear, drift, merge, split or disappear. This algorithm has been designed to be able to detect complex patterns even in multi-density distributions and making no assumption of cluster convexity. The performance of the dynamic clustering algorithm is assessed theoretically through complexity analysis and empirically through a set of experiments.'\n",
      " 'User Movement Prediction: The Contribution of Machine Learning Techniques Ambient Assisted Living (AAL) aims to increase the time older people or disabled people can live in their home environment by assisting them in performing activities of daily living by the use of intelligent products. Localization and tracking of users in indoor environment are the main components of AAL. Wireless sensor networks is an effective technology to accomplish these services by using Received Signal Strength (RSS) information. This work seeks to investigate the effect of machine learning techniques on the accuracy of user movement prediction. Five base classifiers and two ensemble learning approaches are employed and the results are evaluated in terms of precision recall, and F-measure. A real-life benchmark dataset in the area of AAL is used for evaluation. The results show that J48 is the best performing model compared to the other base-level classifiers. It also shows that Bagged J48 achieves the best performance.'\n",
      " 'Validation of a Quantifier-Based Fuzzy Classification System for Breast Cancer Patients on External Independent Cohorts Recent studies in breast cancer domains have identified seven distinct clinical phenotypes (groups) using immunohistochemical analysis and a variety of unsupervised learning techniques. Consensus among the clustering algorithms has been used to categorise patients into these specific groups, but often at the expenses of not classifying all patients. It is known that fuzzy methodologies can provide linguistic based classification rules to ease those from consensus clustering. The objective of this study is to present the validation of a recently developed extension of a fuzzy quantification subsethood-based algorithm on three sets of newly available breast cancer data. Results show that our algorithm is able to reproduce the seven biological classes previously identified, preserving their characterisation in terms of marker distributions and therefore their clinical meaning. Moreover, because our algorithm constitutes the fundamental basis of the newly developed Nottingham Prognostic Index Plus (NPI+), our findings demonstrate that this new medical decision making tool can help moving towards a more tailored care in breast cancer.'\n",
      " 'Review on Machine Learning Based Lesion Segmentation Methods from Brain MR Images Brain lesions are life threatening diseases. Traditional diagnosis of brain lesions is performed visually by neuro-radiologists. Nowadays, advanced technologies and the progress in magnetic resonance imaging provide computer aided diagnosis using automated methods that can detect and segment abnormal regions from different medical images. Among several techniques, machine learning based methods are flexible and efficient. Therefore, in this paper, we present a review on techniques applied for detection and segmentation of brain lesions from magnetic resonance images with supervised and unsupervised machine learning techniques.'\n",
      " 'Machine Learning for Optimum CT-Prediction for qPCR Introduction of fluorescence-based Real-Time PCR (RT-PCR) is increasingly used to detect multiple pathogens simultaneously and rapidly by gene expression analysis of PCR amplification data. PCR data is analyzed often by setting an arbitrary threshold that intersect the signal curve in its exponential phase if it exists. The point at which the curve crosses the threshold is called Threshold Cycle (CT) for positive samples. On the other, when such cross of threshold does not occur, the sample is identified as negative. This simple and arbitrary however not an elagant definition of CT value sometimes leads to conclusions that are either false positive or negative. Therefore, the purpose of this paper is to present a stable and consistent alternative approach that is based on machine learning for the definition and determination of CT values.'\n",
      " 'Iteratively Learning a Liver Segmentation Using Probabilistic Atlases: Preliminary Results This works deals with the concept of liver segmentation by using a priori information based on probabilistic atlases and segmentation learning based of previous steps. A probabilistic atlas is here understood as a probability or membership map that tells how likely is that a point belongs to a shape drawn from the shape distribution at hand. We devise a procedure to segment Perfusion Magnetic Resonance liver images that combines both: a probabilistic atlas of the liver and a segmentation algorithm based on global information of previous simpler segmentation steps, local information from close segmented slices and finally a mathematical morphology procedure, namely viscous reconstruction, to fill the shape. Preliminary results of the algorithm are provided.'\n",
      " 'Probabilistic Expert Systems for Reasoning in Clinical Depressive Disorders Like other real-world problems, reasoning in clinical depression presents cognitive challenges for clinicians. This is due to the presence of co-occuring diseases, incomplete data, uncertain knowledge, and the vast amount of data to be analysed. Current approaches rely heavily on the experience, knowledge, and subjective opinions of clinicians, creating scalability issues. Automating this process requires a good knowledge representation technique to capture the knowledge of the domain experts, and multidimensional inferential reasoning approaches that can utilise a few bits and pieces of information for efficient reasoning. This study presents knowledge-based system with variants of Bayesian network models for efficient inferential reasoning, translating from available fragmented depression data to the desired information in a visually interpretable and transparent manner. Mutual information, a Conditional independence test-based method was used to learn the classifiers.'\n",
      " \"Feature Fusion for Denoising and Sparse Autoencoders: Application to Neuroimaging Data Although there is no cure to date, Alzheimer's disease detection in early stages has a significant impact on the patient's life in terms of cost, the progress, and helping to plan in advance for an appropriate healthcare in the life ahead as well as providing clinical etiologies for further research. This paper discusses implementing a feature fusion method utilizing sparse and denoising autoencoders to reveal the stage of Alzheimer's disease. Four cohorts consisted of individuals with Alzheimer's disease, late mild cognitive impairment, early mild cognitive impairment, and normal control groups are classified using multinomial logistic regression fueled by the fusion of high-level and low-level features. The high-level features are extracted from the stacked autoencoders. The results show that feature fusion enhance the performance of typical autoencoders. However, the performance of feature fusion using denoising autoencoders is superior to that of the sparse training of autoencoders in terms of overall accuracy, precision, and recall.\"\n",
      " 'Differentiation and Integration of Machine Learning Feature Vectors This paper presents a new approach to the production of feature maps for the improvement of classification in machine learning. The idea is based on a calculus of differentiation and integration of feature vectors, which can be viewed as functions on a metric space or network. Based on this we propose a novel network-based binary machine learning classifier. We illustrate our method using molecular networks alone to distinguish phenotypes, including cancer types and subtypes. We include feature sets derived from disease-specific gene co-expression networks in different cancer data sets using The Cancer Genome Atlas (TCGA) along with other previously published studies. We also illustrate our network-based predictor on another data type, based on infrared spectroscopy of lung cancer tissue.'\n",
      " \"HMM-Based Intrusion Detection System for Software Defined Networking Software Defined Networking (SDN) is a networking model that allows for greater dynamic control of a networking environment. With today's increasingly complex networking environment, SDN networks allow for a greater degree of control and flexibility of a network. This is accomplished through the separation of the control and data planes, as well as the implementation of a global programmable controller. A Network Intrusion Detection Systems (NIDS) can work very well with SDN networks as it can help monitor the overall security of a network by analyzing the network as a whole and making choices to defend the network based on data from the entire network. Using a Hidden Markov Model (HMM), a NIDS could monitor a network and learn from the evolving network activity of the present and react accordingly. This machine-learning NIDS could improve the efficiency of security applications and increases the range of activities that they are able to accomplish. In this paper we plan to demonstrate the possibility of using Hidden Markov models to develop an adaptive NIDS for use in the new emerging technology of SDN.\"\n",
      " 'Epilepsy, a Cyberattack on Brains\\x92 Networked Control System Understanding pathways of neurological disorders requires extensive research on both structural and functional characteristics of the brain. Graph theoretical analysis of functional connectivity networks highlight the dynamics of communication among brain neurons. Resembling brain to a Networked Control System, describes seizure, epileptic episodes, as a response to a set of triggers. This unknown set attempts to destabilize the system and so referred as cyberattacks in network terminology. The study investigates the dynamics of brain networks under the attack of epileptic seizures focusing on the network parameters variation for pre- inter- and post-attack durations. Statistical analysis of the Scalp EEG-based connectivity networks found significantly (p <; 0.05) higher global efficiency and lower clustering coefficient during the attack compared to those of before attack onset and system reinstatement. Study did not support the existence of statistically significant difference in small world index for inter-attack duration, however network tends to scatter from small word model.'\n",
      " \"Toward Parametric Security Analysis of Machine Learning Based Cyber Forensic Biometric Systems Machine learning algorithms are widely used in cyber forensic biometric systems to analyze a subject's truthfulness in an interrogation. An analytical method (rather than experimental) to evaluate the security strength of these systems under potential cyber attacks is essential. In this paper, we formalize a theoretical method for analyzing the immunity of a machine learning based cyber forensic system against evidence tampering attack. We apply our theory on brain signal based forensic systems that use neural networks to classify responses from a subject. Attack simulation is run to validate our theoretical analysis results.\"\n",
      " \"Automating ECU Identification for Vehicle Security The field of vehicular cybersecurity has received considerable media and research attention in the past few years. Given the increasingly connected aspect of consumer automobiles, along with the inherent danger of these machines, there has been a call for experienced security researchers to contribute towards the vehicle security domain. The proprietary nature of Controller Area Network (CAN) bus messages, however, creates a barrier of entry for those unfamiliar, due to the need to identify what the messages on a given vehicle's bus are broadcasting. This work aims to automate the process of correlating CAN bus messages with specific Electronic Control Unit (ECU) functions in a new vehicle, by creating a machine learning classifier that has been trained on a dataset of multiple vehicles from different manufacturers. The results show that accurate classification is possible, and that some ECUs that broadcast similar vehicle dynamics broadcast similar CAN messages.\"\n",
      " 'A Machine Learning Approach for Fault Detection in Vehicular Cyber-Physical Systems A network of vehicular cyber-physical systems (VCPSs) can use wireless communications to interact with each other and the surrounding environment to improve transportation safety, mobility, and sustainability. However, cloud-oriented architectures are vulnerable to cyber attacks, which may endanger passenger and pedestrian safety and privacy, and cause severe property damage. For instance, a hacker can use message falsification attack to affect functionality of a particular application in a platoon of VCPSs. In this paper, a neural network-based fault detection technique is applied to detect and track fault data injection attacks on the cooperative adaptive cruise control layer of a platoon of connected vehicles in real time. A decision support system was developed to reduce the probability and severity of any consequent accident. A case study with its design specifications is demonstrated in detail. The simulation results show that the proposed method can improve system reliability, robustness, and safety.'\n",
      " 'An Oblivious Routing-Based Power Flow Calculation Method for Loss Minimization of Smart Power Networks: A Theoretical Perspective Power loss minimization plays an important role in the appropriate operation of power networks. Line power loss occurs when the power is transmitted through the lines of a network due to the permittivity of lines medium. Transmission loss may increase the dispatch cost of all of the obtained power flows based on market contracts. Hence, the independent system operators should use loss minimization methods to facilitate the implementation of the contracted power transactions. Loss minimization also will improve the security and stability of power network. In this paper, we present a novel loss minimization scheme based on oblivious network design, referred to as oblivious routing-based power flow method. The method is built on the bottom-up oblivious network routing scheme which offers multiple paths from several sources (generation units) to the specific destinations (electric load demands). Although there is limited information regarding other line flows and the current status of network, the routing scheme mathematically guarantees that the power flow solution is an approximation of the optimal solution with a specific competitiveness ratio. In fact, the Our main focus is on the power flow calculation while optimizing power losses. Compared with the recently developed power flow methods, our approach does not depend on the network topology and its performance for both radial and non-radial networks is accurate. Hence, it is suitable to use the propose approach for large-scale loss minimization while determining the power flows. This paper mainly focuses on the theoretical aspect of the proposed method. As our method is based on a novel concept from computer science discipline, we provide sufficient explanation about the preliminaries of oblivious routing scheme.'\n",
      " \"Multiview Centroid Based Fuzzy Classification of Large Data Modern data is increasingly complex. High dimensionality, heterogeneity and independent multiple representations are the basic properties of today's data. With increasing sources of data collection, a single object can have multiple representations, which we call views. In this paper we propose a multiview classification technique, which uses fuzzy mapping to obtain maximum similarity between an object and nearest multiview centroids. Our fuzzy mapping based approach obtains a unit L1 hyperplane as a common space for each view. To establish the efficacy of our proposed method we present experimental comparisons with number of baselines on two synthetic and two real-world data sets.\"\n",
      " 'Local and Global Data Spread Based Index for Determining Number of Clusters in a Dataset Most of the clustering algorithms are sensitive to the input parameters and produce different clustering results for different input parameters for same datasets. A number of methods and indices have been proposed for validating results of a clustering process. The most commonly used approaches for cluster validation are based on internal indices. In this paper, we propose a new cluster validity index (ARSpread index) for the purpose of cluster validation and determining number of clusters present in a dataset. Local and global data spread based approach is proposed to measure the compactness of a cluster. A distinctness measure that is based on a penalty function is incorporated in the proposed index. We conduct a thorough comparison of five commonly known indices with the proposed index and provide a summary of experimental performance of different indices. Experimental results show that the proposed new index performs better than the commonly known indices.'\n",
      " 'Sequential Pattern Based Temporal Contour Representations for Content-Based Multimedia Timeline Analysis Temporal contour shapes are closely linked to the narrative structure of multimedia content and provide important reference points in content-based multimedia timeline analysis. In this paper, multimedia timeline is extracted from content as time varying video and audio signal features. A temporal contour representation is implemented based on sequential pattern discovery algorithm for modeling the variation contours of multimedia features. The proposed contour representation extracts repetitive temporal patterns from a hierarchy of time resolutions or from synchronized video/audio feature dimensions. The statistically significant contour components, depicting the dominant timeline shapes, are utilized as a structural or analytical representation of the timeline. The modeling performance of this proposed temporal modeling framework is demonstrated through empirical validation and subjective evaluations.'\n",
      " 'Predicting Movie Box Office Profitability: A Neural Network Approach In this research, we have developed a model for predicting the profitability class of a movie namely \"Profit\" and \"Loss\" based on the data about movies released between the years 2010 and 2015. Our methodology considers both historical data as well as data extracted from the social media. This data is normalized and then given a weight using standard normalization techniques. The cleaned and normalized dataset is then used to train a back-propagation cross entropy validated neural network. Results show that our strategy of identifying the class of success is highly effective and accurate when compared to the results from using a support machine vector on the data.'\n",
      " 'Deep Learning of Cell Classification using Microscope Images of Intracellular Microtubule Networks Microtubule networks (MTs) are a component of a cell that may indicate the presence of various chemical compounds and can be used to recognize properties such as treatment resistance. Therefore, the classification of MT images is of great relevance for cell diagnostics. Human experts find it particularly difficult to recognize the levels of chemical compound exposure of a cell. Improving the accuracy with automated techniques would have a significant impact on cell therapy. In this paper we present the application of Deep Learning to MT image classification and evaluate it on a large MT image dataset of animal cells with three degrees of exposure to a chemical agent. The results demonstrate that the learned deep network performs on par or better at the corresponding cell classification task than human experts. Specifically, we show that the task of recognizing different levels of chemical agent exposure can be handled significantly better by the neural network than by human experts.'\n",
      " 'DeepPositioning:  Intelligent Fusion of Pervasive Magnetic Field and WiFi Fingerprinting for Smartphone Indoor Localization via Deep Learning  Since WiFi has been pervasively available indoor, most smartphone indoor localization systems are based on WiFi fingerprinting although they only give coarse-grained location estimation. In this paper, we propose a novel deep learning-based indoor fingerprinting system (called DeepPositioning), combining Received Signal Strength Indicator (RSSI) of WiFi and pervasive magnetic field to obtain richer fingerprinting. DeepPositioning includes an offline learning phase and an online serving phase. In the offline learning phase, deep learning is utilized to automatically extract rich intrinsic features from a large number of multi-class fingerprints collected using mobile phones. Experimental results demonstrate that deep learning models with the intelligent fusion of pervasive WiFi and magnetic field data can effectively improve smartphone indoor localization compared to existing approaches based on WiFi only.'\n",
      " 'Learning to Coordinate with Deep Reinforcement Learning in Doubles Pong Game This paper discusses the emergence of cooperative and coordinated behaviors between joint and concurrent learning agents using deep Q-learning. Multi-agent systems (MAS) arise in a variety of domains. The collective effort is one of the main building blocks of many fundamental systems that exist in the world, and thus, sequential decision making under uncertainty for collaborative work is one of the important and challenging issues for intelligent cooperative multiple agents. However, the decisions for cooperation are highly sophisticated and complicated because agents may have a certain shared goal or individual goals to achieve and their behavior is inevitably influenced by each other. Therefore, we attempt to explore whether agents using deep Q-networks (DQN) can learn cooperative behavior. We use doubles pong game as an example and we investigate how they learn to divide their works through iterated game executions. In our approach, agents jointly learn to divide their area of responsibility and each agent uses its own DQN to modify its behavior. We also investigate how learned behavior changes according to environmental characteristics including reward schemes and learning techniques. Our experiments indicate that effective cooperative behaviors with balanced division of workload emerge. These results help us to better understand how agents behave and interact with each other in complex environments and how they coherently choose their individual actions such that the resulting joint actions are optimal.'\n",
      " 'Deep Learning for Microalgae Classification Microalgae are unicellular organisms that presents limited physical characteristics such as size, shape or even the present structures. Classifying them manually may require great effort from experts since thousands of microalgae can be found in a small sample of water. Furthermore, the manual classification is a non-trivial operation. We proposed a deep learning technique to solve the problem. We also created a classified dataset that allow us to adopt this technique. To the best of our knowledge, the present work is the first one to apply this kind of technique on the microalgae classification task. The obtained results show the capabilities of the method to properly classify the data by using as input the low resolution images acquired by a particle analyzer instead of pre-processed features. We also show the improvement provided by the use of data augmentation technique.'\n",
      " 'Anomaly Prediction Based on k-means Clustering for Memory-constrained Embedded Devices This paper proposes an anomaly prediction method based on k-means clustering that assumes embedded devices with memory constraints to predict control system anomalies. With this method, by checking control system behavior, it is possible to predict anomalies. However, continuing clustering is difficult because data accumulate in memory similar to existing k-means clustering method, which is problematic for embedded devices with low memory capacity. Therefore, we also propose k-means clustering to continue clustering for infinite stream data. The proposed k-means clustering method is based on online k-means clustering of sequential processing. The proposed k-means clustering method only stores data required for anomaly prediction and releases other data from memory. Experimental results show that anomalies can be predicted by k-means clustering, and the proposed method can predict anomalies similar to standard k-means clustering while reducing memory consumption. Moreover, the proposed k-means clustering demonstrates better results of anomaly prediction than existing online k-means clustering.'\n",
      " 'Clustering Distributed Short Time Series with Dense Patterns The clustering of genes with similar temporal profiles is an important task in gene expression data analysis. Current approaches to the clustering of sparse gene expression data with temporal information suffer from their at least quadratic complexity in the number of clusters, the number of genes, or both, and are not distributed. In this paper, we present the first distributed and density-based approach to short time series clustering, called DTSCluster, which is suitable for gene expression data. DTSCluster identifies dense patterns in the distributed datasets and uses them to generate the time series clusters. The comparative experimental results revealed that DTSCluster is scalable in the dataset size with linear complexity in time and space, and outperforms other representative approaches in terms of cluster validation with the silhouette index as well. The distributed scenario also opens up the opportunity for collaborative data mining between different gene expression data holders.'\n",
      " 'Modeling Over-Dispersion for Network Data Clustering Over-dispersed network data mining has emerged as a central theme in data science, evident by a sharp increase in the volume of real-world network data with imbalanced clusters. While most of existing clustering methods are designed for discovering the number of clusters and class specific connectivity patterns, few methods are available to uncover the imbalanced clusters, commonly existing in network communities and image segments, from network data with over-dispersed cluster size distribution. The latter is considered as an intrinsic structural property of the network data. In this paper, we propose a generalized probabilistic modeling framework, SizeConnectivity, to estimate over-dispersed cluster size distribution together with class specific connectivity patterns from network data. A wide range of cluster size distributions revealed by real-world network data can be accurately captured by our method. We performed extensive synthetic and real-world experiments on clustering social network data and image data for detecting network communities and image segments. Our results demonstrate a superior performance of our SizeConnectivity clustering method in recovering the hidden structure of network data via modeling over-dispersion.'\n",
      " 'Deep Learning Based Car Damage Classification Image based vehicle insurance processing is an important area with large scope for automation. In this paper we consider the problem of car damage classification, where some of the categories can be fine-granular. We explore deep learning based techniques for this purpose. Initially, we try directly training a CNN. However, due to small set of labeled data, it does not work well. Then, we explore the effect of domain-specific pre-training followed by fine-tuning. Finally, we experiment with transfer learning and ensemble learning. Experimental results show that transfer learning works better than domain specific fine-tuning. We achieve accuracy of 89.5% with combination of transfer and ensemble learning.'\n",
      " 'Attribute Assisted Interpretation Confidence Classification Using Machine Learning An attribute assisted classification deriving estimates of interpretation confidence was performed. Instantaneous and coherency attributes were used in a supervised followed by an unsupervised classification resulting in an error envelope of the interpretation. In an initial approximation, confidence weights for a signal and background response are estimated using support vector machine learning. Subsequently, a weighted discrimination based on several coherency attributes using self-organizing maps is obtained. The resulting quantization is used as additional input and constraint in a final probability assessment of signal confidence using instantaneous attributes in support vector machine learning. The additional input in the form of quantization vectors and possible reduction in dimensionality of the input attribute vector space, allows to combine highly non-linear correlations in a multivariate discrimination. The trained classification is used to assign signal confidence probabilities to an interpreted seismic horizon. The proposed methodology is applied to an onshore data set from Wyoming, USA, revealing how single- and multi-trace attributes can be used to quantitatively assess the uncertainty of an interpretation often lost during project maturation.'\n",
      " 'A Hybrid Scheme for Fault Diagnosis with Partially Labeled Sets of Observations Machine learning techniques are widely used for diagnosing faults to guarantee the safe and reliable operation of the systems. Among various techniques, semi-supervised learning can help in diagnosing faulty states and decision making in partially labeled data, where only a few number of labeled observations along with a large number of unlabeled observations are collected from the process. Thus, it is crucial to conduct a critical study on the use of semi-supervised techniques for both dimensionality reduction and fault classification. In this work, three state-of-the- art semi-supervised dimensionality reduction techniques are used to produce informative features for semi-supervised fault classifiers. This study aims to achieve the best pair of the semisupervised dimensionality reduction and classification techniques that can be integrated into the diagnostic scheme for decision making under partially labeled sets of observations.'\n",
      " \"Predictive Modelling Strategies to Understand Heterogeneous Manifestations of Asthma in Early Life Wheezing is common among children and ~50% of those under 6 years of age are thought to experience at least one episode of wheeze. However, due to the heterogeneity of symptoms there are difficulties in treating and diagnosing these children. `Phenotype specific therapy' is one possible avenue of treatment, whereby we use significant pathology and physiology to identify and treat pre-schoolers with wheeze. By performing feature selection algorithms and predictive modelling techniques, this study will attempt to determine if it is possible to robustly distinguish patient diagnostic categories among pre-school children. Univariate feature analysis identified more objective variables and recursive feature elimination a larger number of subjective variables as important in distinguishing between patient categories. Predicative modelling saw a drop in performance when subjective variables were removed from analysis, indicating that these variables are important in distinguishing wheeze classes. We achieved 90%+ performance in AUC, sensitivity, specificity, and accuracy, and 80%+ in kappa statistic, in distinguishing ill from healthy patients. Developed in a synergistic statistical - machine learning approach, our methodologies propose also a novel ROC Cross Evaluation method for model post-processing and evaluation. Our predictive modelling's stability was assessed in computationally intensive Monte Carlo simulations.\"\n",
      " 'Home Appliance Energy Disaggregation Using Low Frequency Data and Machine Learning Classifiers Home appliance monitoring provides useful information about appliance usage, which can be used to better inform users about their consumption habits and promote energy conservation. However, metering all loads is cost prohibitive. Instead, many have tried to disaggregate loads from aggregate power measurements. Existing approaches that require submetering high resolution power signals of individual appliances during training and testing, are impractical and economically infeasible. In this paper, we introduce a low-cost approach for home appliance monitoring based on observations made on a single circuit. Our approach consists of three steps. First, we apply a neural network classifier to segment the input power signals. Then, we apply another classifier to label each segment as an individual appliance or multiple appliances. Finally, we iteratively disaggregate the multi-appliance segments with the classifier in the previous step. Our proposed approach is evaluated in two experiments. The first experiment uses a fully labeled public dataset consisting of 1,211 segments from 25 student bedrooms on a university campus. The second experiment uses 1,563 segments from the REDD public dataset. The evaluation shows that our approach can accurately detect those appliances that dominate energy consumption (overall accuracy of 86.6% and 91.2%, respectively). We also present an in-depth analysis of the failures and conjecture why they are harder to detect.'\n",
      " 'On the Impacts of Noise from Group-Based Label Collection for Visual Classification State of the art visual classification continues to improve, particularly with the use of deep learning and millions of labeled images. However, the effort required to label training sets of this size has led to semi-supervised approaches that collect partially noisy labeled data with less effort. Label noise has been shown to degrade supervised learning, but these analyses focus on noise from erroneous label assignment of data instances. Group-based labeling reduces workload by assigning a single label to a group of images simultaneously, which introduces label noise with structure dependent on all training instances. This work investigates the impact of group-based label noise on classifier learning, and discusses how and why this differs from instance-based label noise. We also discuss label noise modeling designed to provide more robust classification given noisy training instances, and evaluate the generalization of these techniques to group-based noise.'\n",
      " 'Learning Robust Video Synchronization without Annotations Aligning video sequences is a fundamental yet still unsolved component for a broad range of applications in computer graphics and vision. Most classical image processing methods cannot be directly applied to related video problems due to the high amount of underlying data and their limit to small changes in appearance. We present a scalable and robust method for computing a non-linear temporal video alignment. The approach autonomously manages its training data for learning a meaningful representation in an iterative procedure each time increasing its own knowledge. It leverages on the nature of the videos themselves to remove the need for manually created labels. While previous alignment methods similarly consider weather conditions, season and illumination, our approach is able to align videos from data recorded months apart.'\n",
      " 'Google\\'s Cloud Vision API Is Not Robust To Noise Google has recently introduced the Cloud Vision API for image analysis. According to the demonstration website, the API \"quickly classifies images into thousands of categories, detects individual objects and faces within images, and finds and reads printed words contained within images.\" It can be also used to \"detect different types of inappropriate content from adult to violent content.\" In this paper, we evaluate the robustness of Google Cloud Vision API to input perturbation. In particular, we show that by adding sufficient noise to the image, the API generates completely different outputs for the noisy image, while a human observer would perceive its original content. We show that the attack is consistently successful, by performing extensive experiments on different image types, including natural images, images containing faces and images with texts. For instance, using images from ImageNet dataset, we found that adding an average of 14.25% impulse noise is enough to deceive the API. Our findings indicate the vulnerability of the API in adversarial environments. For example, an adversary can bypass an image filtering system by adding noise to inappropriate images. We then show that when a noise filter is applied on input images, the API generates mostly the same outputs for restored images as for original images. This observation suggests that cloud vision API can readily benefit from noise filtering, without the need for updating image analysis algorithms.'\n",
      " \"Machine Learning in Appearance-based Robot Self-localization An appearance-based robot self-localization problem is considered in the machine learning framework. The appearance space is composed of all possible images, which can be captured by a robot's visual system under all robot localizations. Using recent manifold learning and deep learning techniques, we propose a new geometrically motivated solution based on training data consisting of a finite set of images captured in known locations of the robot. The solution includes estimation of the robot localization mapping from the appearance space to the robot localization space, as well as estimation of the inverse mapping for modeling visual image features. The latter allows solving the robot localization problem as the Kalman filtering problem.\"\n",
      " 'Learning Antecedent Structures for Event Coreference Resolution The vast majority of existing work on learning-based event coreference resolution has employed the so-called mentionpair model, which is a binary classifier that determines whether two event mentions are coreferent. Though conceptually simple, this model is known to suffer from several major weaknesses. Rather than making pairwise local decisions, we view event coreference as a structured prediction task, where we propose a probabilistic model that selects an antecedent for each event mention in a given document in a collective manner. Our model achieves the best results reported to date on the new KBP 2016 English and Chinese event coreference resolution datasets.'\n",
      " 'Automatic Generation and Recommendation for API Mashups Until today, finding the most suitable APIs to use in an application was burdensome, requiring manual and time-consuming searches across a diverse set of websites, in particular regarding how multiple APIs could be combined and worked together (i.e. API mashups). In this paper, we propose a new method to automatically generate API mashups through real-world data collection, text mining and natural language processing (NLP ) techniques. The generated API mashups are further ranked and recommended to developers based on a quantitative indicator of whether the given API mashup is plausible. To evaluate the overall accuracy of the proposed method, we use the generated API mashups to train several machine learning and deep learning models, and then use an independent mashup dataset collected from Github projects for testing. The experimental results show that our proposed method is feasible and accurate for automatic API mashup generation and recommendation.'\n",
      " 'Classification-Based Adaptive Web Scraper  Web scraping is an important problem in computer science. The problem with the commonly-used position or structure-based web scraping tools is that they need to be manually reconfigured as soon as the structure of the web page changes. In this paper, we try to solve this problem of information extraction for web pages consisting of repetitive blocks. We extract these blocks and their constituent attributes, using a novel classification-based approach. Our approach gives high accuracy when used to extract product-offers from an offer-aggregator website. It is also highly adaptive to the changing structure of a website.'\n",
      " \"Stochastic Primal-Dual Method on Riemannian Manifolds of Bounded Sectional Curvature We study a stochastic primal-dual method for optimizing functions on elliptic (sub)manifolds- Riemannian (sub)manifolds with a positive bounded sectional curvature. In particular, we establish a convergence rate for geodesically convex functions that is related to the lower bound on the sectional curvature. The convergence analysis we present is based on Toponogov's comparison theorem, where geodesic triangles on the elliptic manifolds and a sphere are compared. We numerically demonstrate the performance of the proposed stochastic primal-dual algorithm on the sphere for non-negative principle component analysis (PCA), and on the Lie group SO(3) for the anchored localization from partial noisy measurements of relative rotations. In both applications, the proposed algorithm scales gracefully to high dimensions.\"\n",
      " 'Anytime Exploitation of Stragglers in Synchronous Stochastic Gradient Descent In this paper we propose an approach to parallelizing synchronous stochastic gradient descent (SGD) that we term \\x93Anytime-Gradients\\x94. The Anytime-Gradients is designed to exploit the work completed by slow compute nodes or \\x93stragglers\\x94. In many approaches work completed by these nodes, while only partial, is discarded completely. To maintain synchronization in our approach, each computational epoch is of fixed duration, and at the end of each epoch, workers send updated parameter vectors to a master mode for combination. The master weights each update by the amount of work done. The Anytime-Gradients scheme is robust to both persistent and non-persistent stragglers and requires no prior knowledge about processor abilities. We show that the scheme effectively exploits stragglers and outperforms existing methods.'\n",
      " 'An Evolutionary Learning Approach to Self-Configuring Image Pipelines in the Context of Carbon Fiber Fault Detection Carbon fiber reinforced plastics (CFRP) play a key role for the production of leightweight structures. Simultaneously, online quality inspection of CFRP becomes more important, especially for environments with high safety standards. In this context, vision systems aim to find defects of different shape, size, contour and orientation. Little effort, however, has been made in detecting defect areas in images taken from the surface of carbon fibers. A common approach for segmenting filament defects are edge detection and thresholding. With every change of material and process adjustments, the filter parameters have to be adapted. In this paper, we propose a cartesian genetic programming (CGP) approach to semi-automatically select the best parameters. This strategy saves time for parameter identification while at the same time increases precision. A test run on randomly selected samples shows how the approach can substantially improve detection reliability.'\n",
      " 'Online Structure-Search for Sum-Product Networks A variety of algorithms exist for learning both the structure and parameters of sum-product networks (SPNs), a class of probabilistic model in which exact inference can be done quickly. The vast majority of them are batch learners, including a recently proposed algorithm, SEARCHSPN. However, SEARCHSPN has properties that make it particularly suited for adaptation to the online setting. In this paper we introduce the ONLINESEARCHSPN algorithm which does just that. We compare it to two general methods that build online learners from batch learners; one learns poor models quickly and the other learns good models slowly. Our experiments show that ONLINESEARCHSPN achieves the best of both methods. The test likelihood values of the models it learns are as good as the slow learner, while the training times needed to learn the models are much closer to the fast learner.'\n",
      " \"A Machine Learning Approach to Detecting Sensor Data Modification Intrusions in WBANs Wireless Body Area Networks (WBANs) are widely used for collecting and monitoring patients' vital healthcare parameters, such as breathing, heart function and muscle activity. A serious flaw of WBANs is their vulnerability to various security issues, one of which is the physical tampering of the sensors. Transmission of invalid data by a damaged or compromised sensor may lead to incorrect diagnosis, improper treatment and undesirable results. In this paper, we analyze blood glucose-level sensors and propose a machine learning algorithm that detects intentional and inadvertent data modification intrusions for this type of sensors. The proposed algorithm uses Otsu's Thresholding Method and other statistical measures to create features that estimate boundaries, averages, deviations and patterns of sensor data. Feature vectors are then classified by a Support Vector Machine (SVM) model with a linear kernel and varying misclassification parameter. Experiments on a large real-patient dataset show that the proposed algorithm achieves 100% precision and 99.22% recall.\"\n",
      " 'Automatic Algorithm Recognition of Source-Code using Machine Learning As codebases for software projects get larger, reaching ranges of millions of lines of code, the need for computer-aided program comprehension grows. We define one of the tasks of program comprehension to be algorithm recognition: given a piece of source-code from a file, identify the algorithm this code is implementing, such as brute-force or dynamic programming. Most research in this area is making use of pattern matching, which involves much human effort and is of questionable accuracy when the structure and semantics of programs change. Thus, this paper proposes to let go of defined patterns, and make use of simpler features, such as counts of variables and counts of different constructs to recognize algorithms. We then feed these features to a classification algorithm to predict the class or type of algorithm used in this source code. We show through experimental results that our proposed method achieves a good improvement over baseline.'\n",
      " 'Realistic Traffic Generation for Web Robots Critical to evaluating the capacity, scalability, and availability of web systems are realistic web traffic generators. Web traffic generation is a classic research problem, no generator accounts for the characteristics of web robots or crawlers that are now the dominant source of traffic to a web server. Administrators are thus unable to test, stress, and evaluate how their systems perform in the face of ever increasing levels of web robot traffic. To resolve this problem, this paper introduces a novel approach to generate synthetic web robot traffic with high fidelity. It generates traffic that accounts for both the temporal and behavioral qualities of robot traffic by statistical and Bayesian models that are fitted to the properties of robot traffic seen in web logs from North America and Europe. We evaluate our traffic generator by comparing the characteristics of generated traffic to those of the original data. We look at session arrival rates, inter-arrival times and session lengths, comparing and contrasting them between generated and real traffic. Finally, we show that our generated traffic affects cache performance similarly to actual traffic, using the common LRU and LFU eviction policies.'\n",
      " 'Incomplete Dot Products for Dynamic Computation Scaling in Neural Network Inference We propose the use of incomplete dot products (IDP) to dynamically adjust the number of input channels used in each layer of a convolutional neural network during feedforward inference. IDP adds monotonically non-increasing coefficients, referred to as a \\x93profile\\x94, to the channels during training. The profile orders the contribution of each channel in non-increasing order. At inference time, the number of channels used can be dynamically adjusted to trade off accuracy for lowered power consumption and reduced latency by selecting only a beginning subset of channels. This approach allows for a single network to dynamically scale over a computation range, as opposed to training and deploying multiple networks to support different levels of computation scaling. Additionally, we extend the notion to multiple profiles, each optimized for some specific range of computation scaling. We present experiments on the computation and accuracy trade-offs of IDP for popular image classification models and datasets. We demonstrate that, for MNIST and CIFAR-10, IDP reduces computation significantly, e.g., by 75%, without significantly compromising accuracy. We argue that IDP provides a convenient and effective means for devices to lower computation costs dynamically to reflect the current computation budget of the system. For example, VGG-16 with 50% IDP (using only the first 50% of channels) achieves 70% in accuracy on the CIFAR-10 dataset compared to the standard network which achieves only 35% accuracy when using the reduced channel set.'\n",
      " 'Time-Sensitive Adaptation of Regularization Strength of Recurrent Neural Networks for Accurate Learning Regularization is an important issue for neural networks because of strong expression power causing overfitting to data. A regularization method is to penalize cost functions by activation-based penalty. In its applications to recurrent neural networks, the method usually assigns penalty uniformly distributed over time steps. However, required strength for recurrent networks differs by time steps. In this paper we propose a new activation-based penalty function varying its strength over time steps in recurrent neural networks. To verify its impact, we conducted practical experiments to predict the power consumption of home appliances. In the results, the proposed method reduced training errors and maintained validation and test errors, which implies the improvement of forecasting ability. In sensitivity analysis, the method restricted sudden decrease of impact of early time steps to the cost.'\n",
      " \"Recognition of Acoustic Events Using Masked Conditional Neural Networks Automatic feature extraction using neural networks has accomplished remarkable success for images, but for sound recognition, these models are usually modified to fit the nature of the multi-dimensional temporal representation of the audio signal in spectrograms. This may not efficiently harness the time-frequency representation of the signal. The ConditionaL Neural Network (CLNN) takes into consideration the interrelation between the temporal frames, and the Masked ConditionaL Neural Network (MCLNN) extends upon the CLNN by forcing a systematic sparseness over the network's weights using a binary mask. The masking allows the network to learn about frequency bands rather than bins, mimicking a filterbank used in signal transformations such as MFCC. Additionally, the Mask is designed to consider various combinations of features, which automates the feature hand-crafting process. We applied the MCLNN for the Environmental Sound Recognition problem using the Urbansound8k, YorNoise, ESC-10 and ESC-50 datasets. The MCLNN have achieved competitive performance compared to state-of-the-art Convolutional Neural Networks and hand-crafted attempts.\"\n",
      " 'Parametric Exponential Linear Unit for Deep Convolutional Neural Networks Object recognition is an important task for improving the ability of visual systems to perform complex scene understanding. Recently, the Exponential Linear Unit (ELU) has been proposed as a key component for managing bias shift in Convolutional Neural Networks (CNNs), but defines a parameter that must be set by hand. In this paper, we propose learning a parameterization of ELU in order to learn the proper activation shape at each layer in the CNNs. Our results on the MNIST, CIFAR-10/100 and ImageNet datasets using the NiN, Overfeat, All-CNN and ResNet networks indicate that our proposed Parametric ELU (PELU) has better performances than the non-parametric ELU. We have observed as much as a 7.28% relative error improvement on ImageNet with the NiN network, with only 0.0003% parameter increase. Our visual examination of the non-linear behaviors adopted by Vgg using PELU shows that the network took advantage of the added flexibility by learning different activations at different layers.'\n",
      " 'Understading Image Restoration Convolutional Neural Networks with Network Inversion In recent years, Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in many image restoration applications. The knowledge of how these models work, however, is still limited. While there have been many attempts at better understanding the inner working of CNNs, they have mostly been applied to classification networks. Because of this, most existing CNN visualization techniques may be inadequate to the study of image restoration architectures. In the paper, we present network inversion, a new method developed specifically to help in the understanding of image restoration Convolutional Neural Networks. We apply our method to underwater image restoration and dehazing CNNs, showing how it can help in the understanding and improvement of these models.'\n",
      " 'Lecture Vdeo Indexing Using Boosted Margin Maximizing Neural Networks This paper presents a novel approach for lecture video indexing using a boosted deep convolutional neural network system. The indexing is performed by matching high quality slide images, for which text is either known or extracted, to lower resolution video frames with possible noise, perspective distortion, and occlusions. We propose a deep neural network integrated with a boosting framework composed of two sub-networks targeting feature extraction and similarity determination to perform the matching. The trained network is given as input a pair of slide image and a candidate video frame image and produces the similarity between them. A boosting framework is integrated into our proposed network during the training process. Experimental results show that the proposed approach is much more capable of handling occlusion, spatial transformations, and other types of noises when compared with known approaches.'\n",
      " \"Direct Multiclass Boosting Using Base Classifiers' Posterior Probabilities Estimates We present a new multiclass boosting algorithm called Adaboost.BG. Like the original Freund and Shapire's Adaboost algorithm, it aggregates trees but instead of using their misclassification error it takes into account the margins of the observations, which may be seen as confidence measures of their prediction, rather then their correctness. We prove the efficiency of our algorithm by simulation and compare it to similar approaches known to minimize the global margins of the final classifier.\"\n",
      " 'Classification of Pollen Grain Images Based on an Ensemble of Classifiers The recognition of pollen grains is a challenging task since they are three-dimensional structures with complex morphological characteristics. Palynologists are responsible for studying pollen, spores and similar microscopic plant structures. In this work, we develop and analyze an automatic method for classification of pollen grain images based on a set of features and classifiers. Predictions of different classifiers are fused into an ensemble rule of majority voting. Experiments conducted on two datasets containing different types of pollen grains are used to demonstrate the effectiveness of the proposed approach.'\n",
      " 'UoI-NMF Cluster: A Robust Nonnegative Matrix Factorization Algorithm for Improved Parts-Based Decomposition and Reconstruction of Noisy Data With the ever growing collection of large volumes of scientific data, development of interpretable machine learning tools to analyze such data is becoming more important. However, robust, interpretable machine learning tools are lacking, threatening extraction of scientific insight and discovery. Nonnegative Matrix Factorization (NMF) algorithms decompose an m × n nonnegative data matrix A into a k × n basis matrix H and an m × k weight matrix W, such that A ? WH, where k is the desired rank. In this paper, we present a novel two stage algorithm, UoI-NMF cluster for NMF, which is based on three innovations: (i) completely separate bases learning from weight estimation, (ii) learn bases by clustering NMF results across bootstrap resamples of the data, and (iii) use the recently introduced Union of Intersections (UoI) framework to estimate ultra-sparse weights that maximize data reconstruction accuracy. We deploy our algorithm on various synthetic and scientific data to illustrate its performance, with a focus on neuroscience data. Compared to other NMF algorithms, UoI-NMF cluster yields: a) more accurate parts-based decompositions of noisy data, b) a sparse and accurate weight matrix, and c) high accuracy reconstructions of the de-noised data. Together, these improvements enhance the performance and interpretability of NMF application to noisy data, and suggest similar approaches may benefit other matrix decomposition algorithms.'\n",
      " 'Deep Transductive Nonnegative Matrix Factorization for Speech Separation Non-negative matrix factorization (NMF) has attracted great attentions in speech separation as it can preserve the non-negativity property of the magnitude spectrogram of speech signal. However, NMF sometimes performs poorly because it cannot extract the non-linear features in speech. In this paper, we propose a deep transductive NMF model (DTNMF) which incorporates a multi-layer structure into NMF and learns a shared dictionary on source signal of each speaker and the mixture signal to be separated. Since the multi-layer structure enables DTNMF to learn more precise presentation of source signal with the non-linear features extracted, DTNMF significantly enhances the performance of speech separation. Experimental results on Non-negative matrix factorization (NMF) has attracted great attentions in speech separation as it can preserve the non-negativity property of the magnitude spectrogram of speech signal. However, NMF sometimes performs poorly because it cannot extract the non-linear features in speech. In this paper, we propose a deep transductive NMF model (DTNMF) which incorporates a multi-layer structure into NMF and learns a shared dictionary on source signal of each speaker and the mixture signal to be separated. Since the multi-layer structure enables DTNMF to learn more precise presentation of source signal with the non-linear features extracted, DTNMF significantly enhances the performance of speech separation. Experimental results on the popular LibriSpeech dataset show that DTNMF outperforms the representative NMF models for separating the mixture of single-channel speech signals.'\n",
      " 'An Empirical Study of Cross-Lingual Transfer Learning Techniques for Small-Footprint Keyword Spotting This paper presents our work on building a small-footprint keyword spotting system for a resource-limited language, which requires low CPU, memory and latency. Our keyword spotting system consists of deep neural network (DNN) and hidden Markov model (HMM), which is a hybrid DNN-HMM decoder. We investigate different transfer learning techniques to leverage knowledge and data from a resource-abundant source language to improve the keyword DNN training for a target language which has limited in-domain data. The approaches employed in this paper include training a DNN using source language data to initialize the target language DNN training, mixing data from source and target languages together in a multi-task DNN training setup, using logits computed from a DNN trained on the source language data to regularize the keyword DNN training in the target language, as well as combinations of these techniques. Given different amounts of target language training data, our experimental results show that these transfer learning techniques successfully improve keyword spotting performance for the target language, measured by the area under the curve (AUC) of DNN-HMM decoding detection error tradeoff (DET) curves using a large in-house far-field test set.'\n",
      " \"Wearable Motion Sensor Based Analysis of Swing Sports Recent trends show that wearable devices with embedded motion sensors are being utilized for enriching user experience in health and fitness by tracking an individual's physical activities such as walking, running, cycling etc. Sports is another essential domain where these sensors can be used to provide valuable information. Particularly for swing sports like Tennis, Badminton and Golf, sensors on wrist-worn wearables can easily be used to give insights into players' games for improvement and preventing injuries that ensue from incorrect techniques. In this paper we propose the design of a sports analytics system with underlying methodologies that efficiently distinguish intricacies of players' hand movements for a given sport. Under this system, we discuss generalized approaches for detecting shots. We also propose and compare two novel techniques for shot classification, one using correlation based feature selection with mRMR, and another based on CNN and BLSTM neural networks. Our commercialized applications TennisTraq and ShuttleTraq, available on Samsung Galaxy Appstore, are based on the proposed system.\"\n",
      " 'Multiple Kernel Representation Learning for WiFi-Based Human Activity Recognition Human activity recognition is becoming the vital underpinning for a myriad of emerging applications in the field of human-computer interaction, mobile computing, and smart grid. Besides the utilization of up-to-date sensing techniques, modern activity recognition systems also require a machine learning (ML) algorithm that leverages the sensory data for identification purposes. In view of the unique characteristics of the measurement data and the ML challenges thereof, we propose a non-intrusive human activity recognition system that only uses existing commodity WiFi routers. The core of our system is a novel multiple kernel representation learning (MKRL) framework that automatically extracts and combines informative patterns from the Channel State Information (CSI) measurements. The MKRL firstly learns a kernel string representation from time, frequency, wavelet, and shape domains with an efficient greedy algorithm. Then it performs information fusion from diverse perspectives based on multi-view kernel learning. Moreover, different stages of MKRL can be seamlessly integrated into a multiple kernel learning framework to build up a robust and comprehensive activity classifier. Extensive experiments are conducted in typical indoor environments and the experimental results demonstrate that the proposed system outperforms existing methods and achieves a 98\\\\% activity recognition accuracy.'\n",
      " 'Multilabel Classification with Weighted Labels Using Learning Classifier Systems In this work the Michigan style strength-based learning classifier system, which is a rule-based supervised learning algorithm, is extended to handle multi-label classification tasks. Moreover, it is assumed that the class membership for training data is partially known and the uncertainty is represented by confidence values that reflects the probability of each label being true. Necessary parameters are introduced, and learning classifiers are modified to learn simultaneously the confidence level and multi-label in the training data. Additionally, to quantify the classifier performance, a novel loss measure is introduced that generalizes the well-known Hamming loss criteria to takes into account the classification error and confidence estimation error simultaneously. The algorithm is tested on one real-world data and two synthetic data sets. Results show the ability of the model in learning multi-class and multi-label data with low confidence estimation error.'\n",
      " 'Integrated Framework for Improving Large-Scale Hierarchical Classification Hierarchical classification (HC) approaches leverage the hierarchical structure during training and testing of models which helps in the improvement of classification performance and prediction efficiency. However, their performance improvement in comparison to flat approaches may be poor if the hierarchy used for training contains: (i) Inconsistent hierarchical relationships such as parent-child or siblings and (ii) Less cohesive or overlapping classes. Moreover, dynamic changes in the data characteristics over time requires new classes (orphan nodes) to be identified to improve the generalization performance of learned models. In addition, we also need to deal with imbalance data in large-scale problem where large number of classes have a few examples for training, posing statistical challenges. In this paper, we propose an integrated framework to address the aforementioned issues for improving large-scale HC. Our experimental evaluations on various image and text datasets shows improved performance with our proposed framework.'\n",
      " 'Stacking Methods for Hierarchical Classification Hierarchical Classification (HC) consists of classification problems whose classes are structured in a hierarchical fashion. Many problems are addressed by HC, in special a decent amount of works dealt with bioinformatics related problems such as Protein Function Prediction (PFP) and Transposable Elements (TEs) classification. Both of them are still a challenging task for HC due to the noisy and imbalanced nature of the datasets. As a countermeasure, Stacking is an ensemble method capable of generalizing knowledge from many classifiers. In this work, we propose three Stacking methods for HC and evaluate its performance on PFP and TEs datasets. Our results show that, when compared to regular Stacking and state-of-art methods from the literature, our methods are able to obtain superior or competitive performances.'\n",
      " 'NMF-Based Label Space Factorization for Multi-label Classification Multi-label classification is a learning task in which each data sample can belong to more than one class. Until now, some methods that are based on reducing the dimensionality of the label space have been proposed. However, these methods have not used specific properties of the label space for this purpose. In this paper, we intend to find a hidden space in which both the input feature vectors and the label vectors are embedded. We propose a modified Non-Negative Matrix Factorization (NMF) method that is suitable for decomposing the label matrix and finding a proper hidden space by a feature-aware approach. We consider that the label matrix is binary and also in this matrix some deserving labels for an instance may not be on (called missing labels). We conduct several experiments and show the superiority of our proposed methods to the state-of-the-art multi- label classification methods.'\n",
      " 'Automatic Scoring of a Nonword Repetition Test  In this study, we explore the feasibility of speech-based techniques to automatically evaluate a nonword repetition (NWR) test. NWR tests, a useful marker for detecting language impairment, require repetition of pronounceable nonwords, such as \"D OY F\", presented aurally by an examiner or via a recording. Our proposed method leverages ASR techniques to first transcribe verbal responses. Second, it applies machine learning techniques to ASR output for predicting gold standard scores provided by speech and language pathologists. Our experimental results for a sample of 101 children (42 with autism spectrum disorders, or ASD; 18 with specific language impairment, or SLI; and 41 typically developed, or TD) show that the proposed approach is successful in predicting scores on this test, with averaged product-moment correlations of 0.74 and mean absolute error of 0.06 (on a observed score range from 0.34 to 0.97) between observed and predicted ratings.'\n",
      " \"Geometrical Analysis of Machine Learning Security in Biometric Authentication Systems Feature extraction and Machine Learning (ML) techniques are required to reduce high variability of biometric data in Biometric Authentication Systems (BAS) toward improving system utilization (acceptance of legitimate subjects). However, reduction in data variability, also decreases the adversary's effort in manufacturing legitimate biometric data to break the system (security strength). Typically for BAS design, security strength is evaluated through variability analysis on data, regardless of feature extraction and ML, which are essential for accurate evaluation. In this research, we provide a geometrical method to measure the security strength in BAS, which analyzes the effects of feature extraction and ML on the biometric data. Using the proposed method, we evaluate the security strength of five state-of-the-art electroencephalogram-based authentication systems, on data from 106 subjects, and the maximum achievable security strength is 83 bits.\"\n",
      " 'Thyme: Improving Smartphone Prompt Timing Through Activity Awareness Smartphone prompts and notifications are popular because they provide users with timely and important information. However, they can also be an annoyance if they pop up at inopportune times and interrupt important tasks. In this paper, we introduce Thyme, an intelligent notification front end that uses activity recognition and machine learning to identify the best times to prompt smartphone users. We evaluate the performance of an activity-aware prompting approach based on 47 participants with fixed time and Thyme-based prompts. Our results show that responsiveness improves from 12.8% to 93.2% using this intelligent approach to the timing of smartphone-based prompts.'\n",
      " \"EyeQual: Accurate, Explainable, Retinal Image Quality Assessment Given a retinal image, can we automatically determine whether it is of high quality (suitable for medical diagnosis)? Can we also explain our decision, pinpointing the region or regions that led to our decision? Images from human retinas are vital for the diagnosis of multiple health issues, like hypertension, diabetes, and Alzheimer's; low quality images may force the patient to come back again for a second scanning, wasting time and possibly delaying treatment. However, existing retinal image quality assessment methods are either black boxes without explanations of the results or depend heavily on feature engineering or on complex and error-prone anatomical structures' segmentation. Therefore, we propose EyeQual, that solves exactly this problem. EyeQual is novel, fast for inference, accurate and explainable, pinpointing low-quality regions on the image. We evaluated EyeQual on two real datasets where it achieved 100% accuracy taking just 36 milliseconds for each image.\"\n",
      " \"The Effect of Communication on Noncooperative Multiplayer Multi-armed Bandit Problems We consider decentralized stochastic multi-armed bandit problem with multiple players in the case of different communication probabilities between players. Each player makes a decision of pulling an arm without cooperation while aiming to maximize his or her reward but informs his or her neighbors in the end of every turn about the arm he or she pulled and the reward he or she got. Neighbors of players are determined according to an Erdos-Rényi graph with connectivity ? which is reproduced in the beginning of every turn. We consider i.i.d. rewards generated by a Bernoulli distribution and assume that players are unaware about the arms' probability distributions and their mean values. In case of a collision, we assume that only one of the players who is randomly chosen gets the reward where the others get zero reward. We study the effects of ?, the degree of communication between players, on the cumulative regret using well-known algorithms UCB1, ?Greedy and Thompson Sampling.\"\n",
      " 'Comparing Transfer Learning and Traditional Learning Under Domain Class Imbalance Transfer learning is a subclass of machine learning, which uses training data (source) drawn from a different domain than that of the testing data (target). A transfer learning environment is characterized by the unavailability of labeled data from the target domain, due to data being rare or too expensive to obtain. However, there exists abundant labeled data from a different, but similar domain. These two domains are likely to have different distribution characteristics. Transfer learning algorithms attempt to align the distribution characteristics of the source and target domains to create high-performance classifiers. This paper provides comparative performance analysis between stateof- the-art transfer learning algorithms and traditional machine learning algorithms under the domain class imbalance condition. The domain class imbalance condition is characterized by the source and target domains having different class probabilities, which can create marginal distribution differences between the source and target data. Statistical analysis is provided to show the significance of the results.'\n",
      " 'RobustSPAM for Inference from Noisy Longitudinal Data and Preservation of Privacy The availability of complex temporal datasets in social, health and consumer contexts has driven the development of pattern mining techniques that enable the use of classical machine learning tools for model building. In this work we introduce a robust temporal pattern mining framework for finding predictive patterns in complex timestamped multivariate and noisy data. We design an algorithm RobustSPAM that enables mining of temporal patterns from data with noisy timestamps. We apply our algorithm to social care data from a local government body and investigate how the efficiency and accuracy of the method depends on the level of noise. We further explore the trade-off between the loss of predictivity due to perturbation of timestamps and the risk of person re-identification.'\n",
      " 'On the Limitation of Convolutional Neural Networks in Recognizing Negative Images Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance on a variety of computer vision tasks, particularly visual classification problems, where new algorithms reported to achieve or even surpass the human performance. In this paper, we examine whether CNNs are capable of learning the semantics of training data. To this end, we evaluate CNNs on negative images, since they share the same structure and semantics as regular images and humans can classify them correctly. Our experimental results indicate that when training on regular images and testing on negative images, the model accuracy is significantly lower than when it is tested on regular images. This leads us to the conjecture that current training methods do not effectively train models to generalize the concepts. We then introduce the notion of semantic adversarial examples - transformed inputs that semantically represent the same objects, but the model does not classify them correctly - and present negative images as one class of such inputs.'\n",
      " 'A New Framework for Fine Tuning of Deep Networks Very often training of deep neural networks involves two learning phases: unsupervised pretraining and supervised fine tuning. Unsupervised pretraining is used to learn the parameters of deep neural networks, while as supervised fine tuning improves upon what has been learnt in the pretraining stage. The predominant algorithm that is used for supervised fine tuning of deep neural networks is standard backpropagation algorithm. However, in the field of shallow neural networks, a number of modifications to backpropagation algorithm have been proposed that have improved the performance of trained model. In this paper we propose a hybrid approach that integrates gain parameter based backpropagation algorithm and the dropout technique and evaluate its effectiveness in the fine tuning of deep neural networks on three benchmark datasets. The results indicate that the proposed hybrid approach performs better fine tuning than backpropagation algorithm alone.'\n",
      " 'HDLTex: Hierarchical Deep Learning for Text Classification Increasingly large document collections require improved information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of traditional supervised classifiers has degraded as the number of documents has increased. This is because along with growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.'\n",
      " 'A Noise Prediction and Time-Domain Subtraction Approach to Deep Neural Network Based Speech Enhancement Deep neural networks (DNNs) have recently been successfully applied to the speech enhancement task; however, the low signal-to-noise ratio (SNR) performance of DNN-based speech enhancement systems remains less than desirable. In this paper, we study an approach to DNN-based speech enhancement based on noise prediction. Three speech enhancement models based on noise prediction are proposed, and their performance is compared to that of conventional spectral-mapping models in seen and unseen noise tests. Objective test results show that the proposed noise prediction models perform well in enhancing speech quality in seen noise conditions and in enhancing high SNR speech signals. They also perform well in enhancing speech intelligibility in both seen and unseen noise conditions, but do not outperform the conventional models on quality metrics in unseen noise conditions. Further analysis of the enhanced speech signals is undertaken to explain the observed results.'\n",
      " 'Granular Computing with Compatibility Based Intuitionistic Fuzzy Rough Sets  In this paper, we are concerned with a problem related to granular computing with game theoretic intuitionistic fuzzy rough sets(GTIFRS). The game theoretic intuitionistic fuzzy rough sets is defined over compatibility based intuitionistic fuzzy relation. The imprecise information obtained, is considered to be composed of intuitionistic fuzzy granules. The basis of granulation is splitting intervals into several sub-intervals. A competitive situation arises due to movement of granules which is controlled by threshold parameters.'\n",
      " 'Subject-Dependent SSVEP Identification Using GMM Training and Adaptation The use of Brain Computer Interface (BCI) systems in the Intensive Care Unit (ICU) can facilitate communication on demand. BCI systems enable ICU patients to communicate using the electrical activity of their brains. For this purpose, we designed and developed a BCI system comprised of an Android tablet that allows patients to look at the screen to ask for what they need using their Electroencephalogram (EEG) recorded using a wireless wearable BCI. However, there are two main challenges associated with the BCI application. Due to the insufficient screen refresh rate of the mobile device, the flickering stimuli is imprecise. Hence, we introduce a partition-based feature extraction and fusion method using Canonical Correlation Analysis (CCA) and Power Spectral Density Analysis (PSDA) to overcome this limitation. Also, BCI devices require a calibration stage in order to capture subject-specific information, which might be particularly troublesome for ICU patients. WE hypothesize that inducing subject related information in the model training and adaptation improves the overall SSVEP identification performance with minimal calibration requirements. As such, We propose a three stage Gaussian Mixture Model (GMM)-based model training and subject adaptation: 1) we generate a subject independent universal GMM model, 2) we generate subject-dependent identification models using only a few collected SSVEP segments from each patient, and 3) we form a vector out of the subject-dependent GMMs and pass it to Support Vector Machine (SVM) for SSVEP target frequency identification. Our experimental results on 10 subjects demonstrated that the proposed framework yielded very efficient SSVEP identification performances achieving 98.7% accuracy using our most accurate model.'\n",
      " 'Supervised Machine Learning Based Surface Inspection by Synthetizing Artificial Defects The preparation of labeled training data for supervised machine learning methods involves a lot of effort. Regarding surface inspection tasks, this endeavor is often not economically reasonable. In this paper, an artificial defect synthetization algorithm based on a multistep stochastic process is proposed. It adds defects to fault-free surface images, which can be used for supervised machine learning. By this means a deep convolutional neural network has been trained, achieving a detection rate of 94% of occurring real defects on the presented test surface.'\n",
      " 'Adventure Game with a Neural Network Controlled Non-playing Character This paper presents a way to evolve a non-playing character by controlling it through a neural network, then using a genetic algorithm to alter the weights. Previous neural network data provides a population from which to select individuals, and the simulated results allow relative rankings that we use as a fitness function. Treating the selected sets of neural network weights as a binary sequence, the program uses cross-over and mutation to create a new set of weights, which are subsequently evaluated. Through this process, we find that the program creates better sets of neural network weights, and that the relative rankings allow the computer-controlled character to have a range of difficulty levels. We implement this experiment as part of a game.'\n",
      " 'A New Approach to Segment Hemorrhagic Stroke in Computed Tomography via Optimum Path Snakes This work presents a new approach to segment hemorrhagic stroke based on an active contour method called Optimum Path Snakes (OPS). The Analysis of Human Tissue Densities (AHTD) was introduced as the evolution of the Pulmonary Density Analysis feature extractor. The results of this approach were compared with the Region Growing, Watershed and Level Set based on the coherent propagation methods to segment the stroke region. Accuracy, Matthews Correlation Coefficient, Dice Coefficient, Hausdorff Distance and Harmonic Means metrics were used to verify the efficacy of OPS over the other methods. The OPS method along with the AHTD extractor presented the best results, which demonstrated the potential for this approach to be used in medical diagnosis systems.'\n",
      " 'Automated Patent Classification Using Word Embedding Patent classification is the task of assign a special code to a patent, where the assigned code is used to group patents with similar subject into a same category. This paper presents a patent categorization method based on word embedding and long short term memory network to classify patents down to the subgroup IPC level. The experimental results indicate that our classification method achieve 63\\\\% accuracy at the subgroup level.'\n",
      " 'Anomaly Detection in Multivariate Non-stationary Time Series for Automatic DBMS Diagnosis Anomaly detection in database management systems (DBMSs) is difficult because of increasing number of statistics (stat) and event metrics in big data system. In this paper, I propose an automatic DBMS diagnosis system that detects anomaly periods with abnormal DB stat metrics and finds causal events in the periods. Reconstruction error from deep autoencoder and statistical process control approach are applied to detect time period with anomalies. Related events are found using time series similarity measures between events and abnormal stat metrics. After training deep autoencoder with DBMS metric data, efficacy of anomaly detection is investigated from other DBMSs containing anomalies. Experiment results show effectiveness of proposed model, especially, batch temporal normalization layer. Proposed model is used for publishing automatic DBMS diagnosis reports in order to determine DBMS configuration and SQL tuning.'\n",
      " 'RBF-FIRMLP Architecture for Digit Recognition The finite impulse response multilayer perceptron (FIRMLP) is a multilayer perceptron where the static weights have been replaced by finite impulse response filters. Hereby, it represents a model for spatio-temporal processing. In this paper we present a temporal processing neural network which is based on the FIRMLP, but some layers have been replaced by temporal radial basis function (RBF) units. As training algorithm we used the temporal backpropagation not just for adapting the weights but also for finding the centers and widths of the RBF layers as well. The performance comparison have been done for the task of handwritten digit ecognition by using the MNIST and MNIST-Variations databases.'\n",
      " 'Incremental Dynamic Search Solver This paper introduces Incremental Dynamic Search (IDS) Solver, a local search based solver, we propose, for solving general finite constraint satisfaction and combinatorial optimization problems. The goal of the IDS Solver is to offer a pluggable approach to Constraint-based models as well as a platform for composing a framework for parallel local search extension, whose functionality is determined by the modelled problem. The aim of the solver is to improve the efficiency, the robustness, and the usability of local-based search algorithms. The proposed solver along with its parallel extension are presented in this paper.'\n",
      " 'DDoS Attack Modeling and Detection Using SMO Over the last decade, Distributed Denial of Service (DDoS) attacks have been employed to cause huge financial and prestige loss to different kinds of e-business. Attackers also target governmental websites using DDoS attacks as a new weapon in the world of cyber war. The importance of the issue has inspired many researchers from academia and the industry to provide solutions to this type of challenging attack. In this study, we simulated DDoS attacks in a virtual lab and then collected firewall logs from the Security Information and Event Management (SIEM) platform of a company in the field of security management solutions. We extracted 14 research features from firewall logs and applied a SMO algorithm to train our data using 10 fold cross-validation. The SMO with PolyKernel was able to create a prediction model without any false alarm. We also tested our model with two different datasets. This research is an ongoing multistep study. Future research will concentrate on online DDoS detection.'\n",
      " \"Cybersecurity Automated Information Extraction Techniques: Drawbacks of Current Methods, and Enhanced Extractors We address a crucial element of applied information extraction-accurate identification of basic security entities in text--by evaluating previous methods and presenting new labelers. Our survey reveals that the previous efforts have not been tested on documents similar to the targeted sources (news articles, blogs, tweets, etc.) and that no sufficiently large publicly available annotated corpus of these documents exists. By assembling a representative test corpus, we perform a quantitative evaluation of previous methods in a realistic setting, revealing an overall lack of recall, and giving insight to the models' beneficial and inhibiting elements. In particular, our results show that many previous efforts overfit to the non-representative test corpora in this domain. Informed by this evaluation, we present three novel cyber entity extractors, which seek to leverage the available labeled data but remain worthwhile on the more diverse documents encountered in the wild. Each new model increases the state of the art in recall, with maximal or near maximal F1 score. Our results establish that the state of the art in cyber entity tagging is characterized by F1 = 0.61.\"\n",
      " 'Privacy Preserving Record Linkage Using MetaSoundex Algorithm Integration of records referring to same entity aids to the resolution of conflicting data values, improves the quality of data, and facilitates sophisticated analysis in data mining. Frequently, record linkage includes integration of sensitive data, which invades personal privacy of an individual. As a result, privacy preserving record linkage (PPRL) has become the prime importance in matching and integrating records in Data Assurance/Security field. Encoding using phonetic codes for preserving privacy is one of the prominent approaches in record linkage techniques. In this paper, we proposed a hybrid protocol, known as MetaSoundex, for achieving privacy preserving record linkage using phonetic encoding. The experiments proved that the proposed technique has higher accuracy in record linkage than the widely-known phonetic matching technique, Soundex.'\n",
      " 'Machine Learning Methods Used in Evaluations of Secure Biometric System Components This paper provides a comprehensive overview of theories, methodologies, techniques, standards and frameworks of biometric systems. The studies conducted between 2007-2017 are examined in order to ensure the security of the equipment used in a biometric system, to secure the characteristic feature extraction, to provide secure data storage in the biometric database, to maintain transmission channels used in biometric applications from vulnerabilities, and to ensure the correctness of the results obtained from intelligent decision mechanism. Machine learning techniques used to detect and protect existing attacks are analyzed, obtained results are shared and recommendations are made in the last part of the study.'\n",
      " \"Automated Behavioral Analysis of Malware: A Case Study of WannaCry Ransomware Ransomware, a class of self-propagating malware that uses encryption to hold the victims' data ransom, has emerged in recent years as one of the most dangerous cyber threats, with widespread damage; e.g., zero-day ransomware WannaCry has caused world-wide catastrophe, from knocking U.K. National Health Service hospitals offline to shutting down a Honda Motor Company in Japan [1]. Our close collaboration with security operations of large enterprises reveals that defense against ransomware relies on tedious analysis from high-volume systems logs of the first few infections. Sandbox analysis of freshly captured malware is also commonplace in operation. We introduce a method to identify and rank the most discriminating ransomware features from a set of ambient (non-attack) system logs and at least one log stream containing both ambient and ransomware behavior. These ranked features reveal a set of malware actions that are produced automatically from system logs, and can help automate tedious manual analysis. We test our approach using WannaCry and two polymorphic samples by producing logs with Cuckoo Sandbox during both ambient, and ambient plus ransomware executions. Our goal is to extract the features of the malware from the logs with only knowledge that malware was present. We compare outputs with a detailed analysis of WannaCry allowing validation of the algorithm's feature extraction and provide analysis of the method's robustness to variations of input data-changing quality/quantity of ambient data and testing polymorphic ransomware. Most notably, our patterns are accurate and unwavering when generated from polymorphic WannaCry copies, on which 63 (of 63 tested) antivirus (AV) products fail.\"\n",
      " \"Automatic Bitcoin Address Clustering Bitcoin is digital assets infrastructure powering the first worldwide decentralized cryptocurrency of the same name. All history of Bitcoins owning and transferring (addresses and transactions) is available as a public ledger called blockchain. But real-world owners of addresses are not known in general. That's why Bitcoin is called pseudo-anonymous. However, some addresses can be grouped by their ownership using behavior patterns and publicly available information from off-chain sources. Blockchain-based common behavior pattern analysis (common spending and one-time change heuristics) is widely used for Bitcoin clustering as votes for addresses association, while offchain information (tags) is mostly used to verify results. In this paper, we propose to use off-chain information as votes for address separation and to consider it together with blockchain information during the clustering model construction step. Both blockchain and off-chain information are not reliable, and our approach aims to filter out errors in input data. The results of the study show the feasibility of a proposed approached for Bitcoin address clustering. It can be useful for the users to avoid insecure Bitcoin usage patterns and for the investigators to conduct a more advanced de-anonymizing analysis.\"\n",
      " 'Forecasting Domestic Hot Water Demand in Residential House Using Artificial Neural Networks The prediction of domestic hot water energy consumption is a key purpose in order to decrease energy consumed on residential houses. The advantage to use the artificial neural networks method is its capacity to adapt to a particular consumer without consumption profile. A lot of paper develop artificial neural network models to predict energy consumption, but they use high quantities of parameters.In this study, we develop models with only available information on classical installations. We separate our experimental data in three kinds of instants: near-zero consumption,low consumption and high consumption moments, and we compare the results of three models based on neural networks method on each of these kinds of consumption. We measure the reaction time between the prediction and the real consumption moment. The results show that our models give good accuracy to predict the moments of consumption and the values of high consumption moment.'\n",
      " 'A Learning Framework for Control-Oriented Modeling of Buildings Buildings consume almost 40\\\\% of energy in the US. In order to optimize the operation of buildings, models that describe the relationship between energy consumption and control knobs such as set-points with high predictive capability are required. Data driven modeling techniques have been investigated to a somewhat limited extent for optimizing the operation and control of buildings. In this context, deep learning techniques such as Recurrent Neural Networks (RNNs) hold promise, empowered by advanced computational capabilities and big data opportunities. This paper investigates the use of deep learning for modeling the power consumption of building heating, ventilation and air-conditioning (HVAC) systems. A preliminary analysis of the performance of the methodology for different architectures is conducted. Results show that the proposed methodology outperforms other data driven modeling techniques significantly.'\n",
      " 'Multistep-ahead Streamflow and Reservoir Level Prediction Using ANNs for Production Planning in Hydroelectric Stations In this work, a methodology to estimate the reservoir level in a hydroelectric dam, based on the predicted streamflow and desired active power, is presented. The streamflow is predicted using two multistep-ahead prediction methods: Close-Loop Prediction (CLP) and Open-Loop Prediction (OLP). Streamflow predictors and dam model are based on Artificial Neural Networks (ANNs). Further analysis of historical streamflow data demonstrated the presence of three climatic seasons and allowed to set the better configuration of ANNs topology and horizons. The prediction system was tested in a hydroelectric power plant in Ecuador. In particular, a comparison between the results obtained from the different combinations of streamflow predictors and dam model was performed concerning success percentage of prediction. Finally, dam model revealed a good accuracy for reservoir level predictions when combined with the most promising streamflow predictors implemented with CLP method for the summer season.'\n",
      " 'Modelling of Fuzzy Logic Controller of a Maximum Power Point Tracker Based on Artificial Neural Network The Grid Connected Photovoltaic System (GCPV) has become more used system in renewable energy. Several researches have been carried out to improve the efficiency and the decrease of energy losses. One of the important components used to increase the efficiency is the DC/DC boost converter. In this paper, a new hybrid model is proposed to control the DC/DC converter, this new controller is built on the fuzzy logic controller (FLC) and artificial neural network (ANN). The pathway taken to build the model is divided into three steps, the first step is to generate a data based on the FLC, the next step is to choose an ANN structure for modeling the FLC and the last step is the test and the validation of the obtained model. The phase of building an ANN is achieved by supervised learning based on back-propagation algorithm. This algorithm is used to train the ANN model by searching of the optimal weights and thresholds that has been a minimal root mean square error between the FLC output and the ANN model. The validation test was performed with various irradiation values between the both intelligent controllers and classical P&O algorithm simultaneously.'\n",
      " 'Efficient Prediction of Dynamic Tariff in Smart Grid Using CGP Evolved Artificial Neural Networks The phenomenal growth of smart grids is resulting in their ever increasing adaptation which has resulted in opening doors to extensive research for applications incorporated within the grid environment. A smart electricity price forecasting mechanism is proposed which when incorporated in the smart grid can be quite beneficial in informing the user of the electricity price during the next hour. Two models have been evolved using the Neuro Evolutionary Cartesian Genetic Programming Evolved Artificial Neural Network(CGPANN) algorithm to estimate the electricity prices for the next hour. Both the models incorporate Feedforward CGPANN algorithm. One of these models takes in as input electricity prices of the previous 12 hours to predict the price value of the next hour, while the other takes in as input the price value of the previous 24 hours to predict the electricity unit cost during the next hour. Comparison of the techniques with previous methods show exceptional strength of prediction. An error as low as 2.82% has clearly established the proposed FCGPANN based forecasting method as an efficient method for futuristic electricity price forecasting. Moreover such prediction can be quite beneficial in demand side management in smart grid environment as informing the user of the rate of electric unit during the next hour may help the user in reducing extra power utilization resulting in a cost effective solution.'\n",
      " 'Solar Radiation Prediction Improvement Using Weather Forecasts Prediction models were developed to generate forecasts of solar radiation, and, by proxy, expected solar plant power output, for one hour and 24 hours in the future. Data was sourced from the Georgia Automated Environmental Monitoring Network (GAEMN) and the National Oceanic and Atmospheric Administration (NOAA) for five cities in Georgia. Early predictive models only made use of historical recorded solar radiation and other weather phenomena as inputs, while later models incorporated weather forecasts for the target area and surrounding areas. Including weather forecast data in the prediction models resulted in a 7.6% reduction in mean absolute error (MAE) for one-hour predictions when compared to using historical observations alone, and a 40.2% reduction in MAE for 24-hour predictions. Results from several machine learning techniques were compared, with Random Forests achieving the lowest error rate. The results indicate that weather forecasts are an important component of accurate solar radiation prediction even over short- and medium-term prediction timeframes, and the inclusion of the surrounding geographical area in addition to the target city is an important component of these predictions.'\n",
      " 'Prediction of Power Grid Failure Using Neural Network Learning  Power Grid failures have the potential to drastically affect the population be it a localized outage or a large-scale blackout. Pre-event planning currently consists of preparation for all scenarios and some enthusiastic prognoses, leading to most resources spreading thin. Focus on a specific area of concern typically follows large scale power grid failures as post event analysis and does not include an overall analysis. In this study, a neural network is used to conduct \\x93pre-event\\x94 analysis of a power grid to determine if it is susceptible to failure. This research study demonstrates that overall \\x93pre-event\\x94 analysis can be beneficial with the use of a machine learning agent. The agent can also be used to determine areas that need the most attention. Future work with larger number of constraints and additional machine learning algorithms will be explored to further improve power grid analysis and performance.'\n",
      " 'A Review of Deep Learning Methods Applied on Load Forecasting The utility industry has invested widely in smart grid (SG) over the past decade. They considered it the future electrical grid while the information and electricity are delivered in two-way flow. SG has many Artificial Intelligence (AI) applications such as Artificial Neural Network (ANN), Machine Learning (ML) and Deep Learning (DL). Recently, DL has been a hot topic for AI applications in many fields such as time series load forecasting. This paper introduces the common algorithms of DL in the literature applied to load forecasting problems in the SG and power systems. The intention of this survey is to explore the different applications of DL that are used in the power systems and smart grid load forecasting. In addition, it compares the accuracy results RMSE and MAE for the reviewed applications and shows the use of convolutional neural network CNN with k-means algorithm had a great percentage of reduction in terms of RMSE.'\n",
      " 'Mitigating IoT-based Cyberattacks on the Smart Grid The impact of cybersecurity attacks on the Smart Grid may cause cyber as well as physical damages, as clearly shown in the recent attacks on the power grid in Ukraine where consumers were left without power. A set of recent successful Distributed Denial-of-Service (DDoS) attacks on the Internet, facilitated by the proliferation of the Internet-of-Things powered botnets, shows that it is just a matter of time before the Smart Grid, as one of the most attractive critical infrastructure systems, becomes the target and likely victim of similar attacks, potentially leaving catastrophic disruption of power service to millions of people. It is in this context that we propose a scalable mitigation approach, referred to as Minimally Invasive Attack Mitigation via Detection Isolation and Localization (MIAMI-DIL), under a hierarchical data collection infrastructure. We provide a proofof- concept by means of simulations which show the efficacy and scalability of the proposed approach.'\n",
      " 'A Novel Application of Naive Bayes Classifier in Photovoltaic Energy Prediction Solar energy is one of the most affordable and clean renewable energy source in the world. Hence, the solar energy prediction is an inevitable requirement in order to get the maximum solar energy during the day time and to increase the efficiency of solar energy systems. For this purpose, this paper predicts the daily total energy generation of an installed photovoltaic system using the Naïve Bayes classifier. In the prediction process, one-year historical dataset including daily average temperature, daily total sunshine duration, daily total global solar radiation and daily total photovoltaic energy generation parameters are used as the categorical-valued attributes. By means of the Naïve Bayes application, the sensitivity and the accuracy measures are improved for the photovoltaic energy prediction and the effects of other solar attributes on the photovoltaic energy generation are evaluated.'\n",
      " 'Application of Decision Trees for Detection of Student Dropout Profiles The results of the research project that aims to identify patterns of student dropout from socioeconomic, academic, disciplinary and institutional data of students from undergraduate programs at the University of Nariño from Pasto city (Colombia), using data mining techniques are presented. Built a data repository with the records of students who were admitted in the period from the first half of 2004 and the second semester of 2006. Three complete cohorts were analyzed with an observation period of six years until 2011. Socioeconomic and academic student dropout profiles were discovered using classification technique based on decision trees. The knowledge generated will support effective decision-making of university staff focused to develop policies and strategies related to student retention programs that are currently set.'\n",
      " \"Student Retention Pattern Prediction Employing Linguistic Features Extracted from Admission Application Essays This paper investigates the use of linguistic features extracted from the application essays of students enrolled in a university academic program for their retention pattern prediction. Three sets of linguistic features are generated from text analysis: (1) latent Dirichlet allocation (LDA) based topic modeling with a variety of topic numbers, (2) Linguistic Inquiry and Word Count (LIWC), and (3) part-of-speech (POS) distribution. Various classification experiments are implemented to evaluate the prediction performance of student retention patterns from these three feature sets and their combinations. The results show that the POS distribution features yield the best prediction performance among these three, while neither the LDA features nor ensemble methods improves predictive performance, which is contrary to admission experts' manual analysis methods in the conventional admission processes.\"\n",
      " 'Component Based Architecture for the Control of Crossing Regions in Railway Networks The research work in this paper discusses an improved Petri net model of railway crossing regions which are important and critical components of a railway networks. A control algorithm has been developed showing the interaction of the controller to other component of the system. A formal approach viz. Petri net (PN) is applied to model the safety requirement of trains along the crossing regions in railway networks. For the modeling, the component based modeling and the state-oriented modeling approaches have been integrated. First the track components and the control component are identified. The interaction of identified components, satisfying the safety requirements, is also defined in the high level architecture. Finally, state-oriented modeling approach has been adopted to design the detailed model of crossing region. Further, this paper uses the coverability tree to verify the specifications of crossing regions. By taking the crossing point as center, a circular region is introduced for safety purpose. Further, safety properties have been defined in term of place-invariants which have been verified by the state-space analysis.'\n",
      " 'Classification of ECG Arrhythmia with Machine Learning Techniques The ECG uses some methods to diagnose these cardiac arrhythmias and tries to correct the diagnosis. ECG signals are characterized by a collection of waves such as P, Q, R, S, T. These five waves are preformed, wave transformed, and classified. In the current literature, the P, Q, R, S, T waves in ECG signals are classified using some machine learning techniques. In the work to be done, MLP (Multi Layer Perceptron) and SVM (Support Vector Machine) classification techniques which are not compared with each other using these signals will be compared. Is study, BP (Back Propagation) algorithm with MLP classifier and K-A (Kernel-Adatron) algorithm with SVM classifier were used. In addition, the use of these methods is new in the field of ECG classification. It will try to find a more effective method with new uses in the study and the literature will contribute to this area. In addition, wave transformation techniques such as DWT, DCT, and CWT will be used to increase the success of the classification used in the study. This will lead to the most effective classification method in the existing data set. In the work to be done, it is aimed to bring improvements to the classification methods used in existing studies. It is aimed to develop a method to improve the calculation time and standard classification performance of MLP and SVM, and it is aimed to contribute to the informed consciousness of this work.'\n",
      " 'Human Motion Trajectory Analysis Based Video Summarization Multimedia technology is growing day by day and contributing towards enormous amount of video data especially in the area of security surveillance. The browsing through such a large collection of videos is a challenging and time-consuming task. Despite the advancement in technology automatic browsing, retrieval, manipulation and analysis of large videos are still far behind. In this paper a fully automatic human-centric system for video summarization is proposed. In most of the surveillance applications, human motion is of great interest. In proposed system the moving parts in the video are detected using background subtraction, and blobs are extracted from the binary image. Human detection is done through Histogram of Oriented Gradient (HOG) using Support Vector Machine (SVM) classifier. Then, motion of humans is tracked through consecutive frames using Kalman filter, and trajectory of each person is extracted. The analysis of trajectory leads to a meaningful summary which covers only important parts of video. One can also mark region of interest to be included in the summary. Experimental results show the proposed system reduces long video into meaningful summary and saves a lot of time and cost in terms of storage, indexing and browsing effort.'\n",
      " 'A Simple Neuro-Heuristic Computational Intelligence Algorithm for Thin Film Flow Equation Arising in Physical Models In this study, computational method are used for finding the approximation in the solution of thin film flow problem using stochastic solver like genetic algorithm (GA) and pattern search (PS). The mathematical model is formulated by defining a fitness function and the process is working in artificial neural networks (ANNs). Proposed numerical results are optimized several times for various values of stoke numbers and material parameters. Different parameters are chosen and several independent number of runs are carried out to find the reliability and accuracy of results. A statistical analysis is presented for the reliability of designed scheme.'\n",
      " 'Support Vector Regression for Predicting the Enhancement Duration of Software Projects Software engineering (SE) has been defined as the application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software. Enhancement is a type of software maintenance. SE involves software planning (SP), and SP includes prediction. In this study, we propose the application of two types of support vector regression (SVR) termed ?-SVR and ?-SVR to predict the duration of the software enhancement. A SVR is a type of support vector machine, which is a machine learning technique. Two data sets of software projects were used for training and testing the ?-SVR and ?-SVR. The prediction accuracy of the SVRs was compared to that of a statistical regression. Based on statistical tests, results showed that a ?-SVR with linear kernel was statistically better than that of a statistical regression model when software projects were enhanced on Mid Range platform and coded in programming languages of third generation.'\n",
      " 'Audio Signal Reconstruction Using Cartesian Genetic Programming Evolved Artificial Neural Network (CGPANN) We propose a novel audio signal reconstruction model that makes use of a non-linear estimation algorithm called Cartesian Genetic Programming evolved Artificial Neural Network (CGPANN). CGPANN estimates the non-linear graphs of audio signals with much better accuracy than its counterparts: the interpolation and extrapolation. We have compared them in terms of SNR improvement and ability to deal with disputed data. Unlike other conventional reconstruction algorithms, the proposed algorithm can restore the signal which is damaged up to 50% by noise. A state-of-the-art approach for reconstructing an audio signal utilizing machine learning is presented in this paper. The performance of algorithm is evaluated by measuring its Signal-to-Noise (SNR) improvement and difference between original and reconstructed signal in terms of Mean Absolute Percentage Error (MAPE). SNR improvement of up to 20 dB is recorded for single point estimation with 25% missing samples, 19 dB for multi-point (up to 5) estimation in which half of the data is missing and 16 dB for a signal with random variable noise.'\n",
      " 'Forward Looking Sonar Scene Matching Using Deep Learning Optical images display drastically reduced visibility due to underwater turbidity conditions. Sonar imaging presents an alternative form of environment perception for underwater vehicles navigation, mapping and localization. In this work we present a novel method for Acoustic Scene Matching. Therefore, we developed and trained a new Deep Learning architecture designed to compare two acoustic images and decide if they correspond to the same underwater scene. The network is named Sonar Matching Network (SMNet). The acoustic images used in this paper were obtained by a Forward Looking Sonar during a Remotely Operated Vehicle (ROV) mission. A Geographic Positioning System provided the ROV position for the ground truth score which is used in the learning process of our network. The proposed method uses 36.000 samples of real data for validation. From a binary classification perspective, our method achieved 98% of accuracy when two given scenes have more than ten percent of intersection.'\n",
      " \"Brace Treatment Monitoring Solution for Idiopathic Scoliosis Patients Scoliosis is a medical condition which occurs in adolescents, where an individual's spine develops curvature. A Thoracolumbosacral orthosis (TLSO) is a type of brace used to control the lateral curvature of the spine in scoliosis. It is a nonsurgical treatment with the goal of preventing curve progression in patients with idiopathic scoliosis. To successfully monitor compliance with brace treatment, we designed and developed a wearable multi-modal sensor solution is embedded into the patient's brace. The custom designed hardware consists of a sensor board, a force sensor, an accelerometer and a gyroscope. The force sensor collects the force being exerted on the patient's back, while the accelerometer and gyroscope generate cues to determine the patient's activities and lifestyle. In this paper, we propose a novel data-mining method to identify patient activities and evaluate the effectiveness of the brace treatment pervasively based on fusion of continuous force and inertial motion recordings. Our aim is to design a context-aware remote monitoring system for ubiquitous evaluation and enhancement of brace treatment compliance of adolescent idiopathic scoliosis patients. We investigated experimental scenario in which, the patient performs a series of pre-defined activities at home during day long segments of brace wear, during pervasive sensor data recordings. The experimental results demonstrated that we achieved an overall accuracy of a 100% for semi-supervised activity detection. The level of tightness of brace-fit reduced gradually over a period of 4 weeks by 33%.\"\n",
      " 'Exploring the Impact of Clone Refactoring on Test Code Size in Object-Oriented Software This paper aims at exploring the impact of clone refactoring on the test code size, in terms of number of operations, in object-oriented software. We investigated three research questions: (1) the impact of clone refactoring on three important source code attributes (coupling, complexity and size) that are related to unit testability of classes, (2) the impact of clone refactoring on the test code size, and (3) the variations after clone refactoring in the source code attributes that have the most important impact on the test code size. We used linear regression and three popular machine learning techniques (i.e., k-Nearest Neighbors, Naïve Bayes and Random Forest) to develop predictive and explanatory models. We used data collected from an open source Java software system (ANT) that has been refactored using clone-refactoring techniques. The analyses indicate that there is a strong and positive relationship between clone refactoring and the reduction of the test code size. Results show that: (1) the source code attributes of refactored classes have been significantly improved, (2) the test code size of refactored classes has been significantly reduced, and (3) the variations of the test code size are more influenced by the variations of the complexity and size of refactored classes compared to coupling.'\n",
      " 'Evaluating Non-personalized Single-Heuristic Active Learning Strategies for Collaborative Filtering Recommender Systems In collaborative filtering recommender systems, the users rate items, and this process helps in understanding their preferences. The systems can suffer from the cold-start problem, which refers to the absence or insufficiency of ratings for new users. This can be solved by using active learning strategies, which can be non-personalized or personalized, and which were evaluated and tested previously using different datasets and metrics. In this paper, we present a clearer study by implementing the main non-personalized single-heuristic strategies (random, popularity, co-coverage, variance, entropy, entropy0) on the same dataset, and by evaluating them using the same metrics, in order to have a better comparison. We use the public MovieLens dataset in the experimentations and the results show that the random strategy performs the worst, whereas the entropy0 leads to the best results. All strategies except the random strategy lead to very close results at a certain point, where ratings for almost the same items will have been elicited.'\n",
      " 'Railway Incident Ranking with Machine Learning Modern railway networks include thousands of failure registration devices, and prompt response to detected failures is critical to normal network operation. However, a large share of produced alerts may be formed by false alarms associated with maintenance or faulty diagnostics, thus hindering the processing of actual failures. It is therefore very desirable to perform fast automated intelligent ranking of incidents before they are analyzed by human operators. In this paper we describe a machine-learning-based incident ranking model that we have developed and deployed at the Moscow Railway network (a large network with 500+ stations). The model estimates the probability of failure using multiple features of the incident at hand. The model was constructed using the XGBoost library and a database of 5 million historical incidents. The model shows high accuracy (AUC 0.901) in the deployment environment.'\n",
      " 'A Spatio - Temporal Hedonic House Regression Model This work focuses on an algorithmic investigation of the housing market spanning 11 years using the hedonic pricing theory. An improved pricing model will benefit home buyers and sellers, real estate agents and appraisers, government and mortgage lenders. Hedonic pricing theory is an econometric concept that explains the market value of a differentiated commodity using implicit pricing. Exploiting the spatial dependent nature of the housing market, we created new submarkets. A model was built with the new submarket, while another one was built using the existing submarket. Random forest and LASSO were trained with the two models. We argue that our approach has a considerable impact on the dimension of a spatio-temporal hedonic house pricing model without a significant reduction in its performance.'\n",
      " 'Foreclosure Sale and House Value: Correlation or Causation?  Despite the financial crisis that erupted in the last decade precipitated by the unprecedented number of foreclosure sales in various parts of the world, there seem to be a paucity of machine learning literatures on this important subject. Using dataset of single family houses from the Multiple Listing Services (MLS) repository, we developed a machine learning investigation of the bubbled and busted real estate market spanning 11 years. Our anatomy of the real estate market crisis was based on the impact of foreclosure sales on the value of real estate properties. A detailed analysis will benefit homeowners, government and real estate investors. Stationarity test for the experiment was based on Augmented Dickey-Fuller, Durbin-Watson, Kwiatkowski, Philips, Schmidt & Shin (KPSS) and Portmanteau tests. Akaike Information Criterion (AIC), Final Prediction Error Criterion (FPE), Hannan-Quinn Criterion (HQ) and Schwarz-Bayes Criterion (SBC) were used for optimization criteria for Granger regression model. Using Autocorrelation Function (ACF), Partial Autocorrelation Function (PACF), time series regression, and Granger Causality, we argue that there exists strong evidence that foreclosure sales have a statistical relationship with changes in standard sales, however, no evidence was found for a causal effect.'\n",
      " 'Predictive Models of Hard Drive Failures Based on Operational Data Hard drives are an essential component of modern data storage. In order to reduce the risk of data loss, hard drive failure prediction methods using the Self-Monitoring, Analysis and Reporting Technology attributes have been proposed. However, these methods were developed from datasets not necessarily representative of operational systems. In this paper, we consider the Backblaze public dataset, a recent operational dataset from over 47,000 drives, exhibiting hard drive heterogeneity with 81 models from 5 manufacturers, an extremely unbalanced ratio of 5000:1 between healthy and failure samples and a realworld loosely controlled environment. We observe that existing predictive models no longer perform sufficiently well on this dataset. We therefore selected machine learning classification methods able to deal with a very unbalanced training set, namely SVM, RF and GBT, and adapted them to the specific constraints of hard drive failure prediction. Our results reach over 95% precision and 67% recall on a one year real-world public dataset of over 12 million records with only 2586 failures.'\n",
      " 'Bayesian Networks for Inverse Inference in Manufacturing Bayesian Networks Physics based simulations of manufacturing processes are used for prediction of material properties and defects in a number of industrial applications. However, a practising engineer often requires the solution to an \"inverse problem\" - prediction of inputs for the desired outcome. The inverse problem is usually solved by constrained optimisation. Extensive simulation during optimisation is avoided through response surfaces constructed from simulations. But the design space is often so large that even with response surfaces, optimisation might not be possible. Moreover, these problems are typically ill-posed, so discriminative models such as artificial neural networks do not work well. In this paper, we investigate the application of conditional linear Gaussian Bayesian networks to address the inverse problem with multi-pass wire drawing process as a case study. We propose an approach to systematically find all solutions and rank them according to their likelihood.'\n",
      " 'Novel Trends in Scaling Up Machine Learning Algorithms Big Data has been a catalyst force for the Machine Learning (ML) area, forcing us to rethink existing strategies in order to create innovative solutions that will push forward the field. This paper presents an overview of the strategies for using machine learning in Big Data with emphasis on the high-performance parallel implementations on many-core hardware. The rationale is to increase the practical applicability of ML implementations to large-scale data problems. The common underlying thread has been the recent progress in usability, cost effectiveness and diversity of parallel computing platforms, specifically, the Graphics Processing Units (GPUs), tailored for a broad set of data analysis and Machine Learning tasks. In this context, we provide the main outcomes of a GPU Machine Learning Library (GPUMLib) framework, which empowers researchers with the capacity to tackle larger and more complex problems, by using high-performance implementations of wellknown ML algorithms. Moreover, we attempt to give insights on the future trends of Big Data Analytics and the challenges lying ahead.'\n",
      " 'MapReduce Based Classification for Fault Detection in Big Data Applications Recently emerging software applications are large, complex, distributed and data-intensive, i.e., big data applications. That makes the monitoring of such applications a challenging task due to lack of standards and techniques for modeling and analysis of execution data (i.e., logs) produced by such applications. Another challenge imposed by big data applications is that the execution data produced by such applications also has high volume, velocity, variety, and require high veracity, value. In this paper, we present our monitoring solution that performs real-time fault detection in big data applications. Our solution is two-fold. First, we prescribe a standard model for structuring execution logs. Second, we prescribe a Bayesian classification based analysis solution that is MapReduce compliant, distributed, parallel, single pass and incremental. That makes it possible for our proposed solution to be deployed and executed on cloud computing platforms to process logs produced by big data applications. We have carried out complexity, scalability, and usability analysis of our proposed solution that how efficiently and effectively it can perform fault detection in big data applications.'\n",
      " 'Learning Effective Query Management Strategies from Big Data The availability of big data collections, together with powerful hardware and software mechanisms to process them, gives nowadays the possibility to learn useful insights from data, which can be exploited for multiple purposes, including marketing, fault prevention, and so forth. However, it is also possible to learn important metadata that can suggest how data should be manipulated in several advanced operations. In this paper, we show the potentiality of learning from data by focusing on the problem of relaxing the results of database queries, that is, trying to return some approximated answer to a query when a result for it is unavailable in the database, and the system will return an empty answer set, or even worse, erroneous mismatch results. In particular, we introduce a novel approach to rewrite queries that are in disjunctive normal form and contain a mixture of discrete and continuous attributes. The approach preprocesses data collections to discover the implicit relationships that exist among the various domain attributes, and then uses this knowledge to rewrite the constraints from the failing query. In a first step, the approach tries to learn a set of functional dependencies from the data, which are ranked according to special mechanisms that will successively allow to predict the order in which the extracted dependencies have to be used to properly rewrite the failing query. An experimental evaluation of the approach on three real data sets shows its effectiveness in terms of robustness and coverage.'\n",
      " 'A Machine Learning Tool for Supporting Advanced Knowledge Discovery from Chess Game Data In the current era of big data, high volumes of a wide variety of data of different veracity can be easily collected or generated at a high velocity. Embedded in these big data is valuable information or knowledge. This calls for machine learning techniques for supporting advanced knowledge discovery from these big data. A rich source of big heterogeneous data is game data--including sports games, online video games, and board games such as chess games. The deep interaction and simplicity of representation afforded by the game of chess have worked together to produce one of the most studied games in the world. It is a great intellectual challenge, and not only for humans. Chess engines can sometimes play chess better than grandmasters, and they can be used to assist the study of games and individual positions. However, this does not help a chess student choose which games to study. In this paper, we present a machine learning system--specifically, an unsupervised learning tool--to analyze big chess datasets. Evaluation results show that not only can machine learning help find interesting games, but also that chess can be a great testing ground for machine learning and data mining techniques for big data analytics.'\n",
      " 'Advanced ECHMM-Based Machine Learning Tools for Complex Big Data Applications We present a novel approach for accurate characterization of workloads, which is relevant in the context of complex big data applications.Workloads are generally described with statistical models and are based on the analysis of resource requests measurements of a running program. In this paper we propose to consider the sequence of virtual memory references generated from a program during its execution as a temporal series, and to use spectral analysis principles to process the sequence. However, the sequence is time-varying, so we employed processing approaches based on Ergodic Continuous Hidden Markov Models (ECHMMs) which extend conventional stationary spectral analysis approaches to the analysis of time-varying sequences. In this work, we describe two applications of the proposed approach: the on-line classification of a running process and the generation of synthetic traces of a given workload. The first step was to show that ECHMMs accurately describe virtual memory sequences; to this goal a different ECHMM was trained for each sequence and the related run-time average process classification accuracy, evaluated using trace driven simulations over a wide range of traces of SPEC2000, was about 82%. Then, a single ECHMM was trained using all the sequences obtained from a given running application; again, the classification accuracy has been evaluated using the same traces and it resulted about 76%. As regards the synthetic trace generation, a single ECHMM characterizing a given application has been used as a stochastic generator to produce benchmarks for spanning a large application space.'\n",
      " 'A Cluster Analysis of Challenging Behaviors in Autism Spectrum Disorder We apply cluster analysis to a sample of 2,116 children with Autism Spectrum Disorder in order to identify patterns of challenging behaviors observed in home and centerbased clinical settings. The largest study of this type to date, and the first to employ machine learning, our results indicate that while the presence of multiple challenging behaviors is common, in most cases a dominant behavior emerges. Furthermore, the trend is also observed when we train our cluster models on the male and female samples separately. This work provides a basis for future studies to understand the relationship of challenging behavior profiles to learning outcomes, with the ultimate goal of providing personalized therapeutic interventions with maximum efficacy and minimum time and cost.'\n",
      " \"Predicting Psychosis Using the Experience Sampling Method with Mobile Apps Smart phones have become ubiquitous in the recent years, which opened up a new opportunity for rediscovering the Experience Sampling Method (ESM) in a new efficient form using mobile apps, and provides great prospects to become a low cost and high impact mHealth tool for psychiatry practice. The method is used to collect longitudinal data of participants' daily life experiences, and is ideal to capture fluctuations in emotions (momentary mental states) as an early indicator for later mental health disorder. In this study ESM data of patients with psychosis and controls were used to examine emotion changes and identify patterns. This paper attempts to determine whether aggregated ESM data, in which statistical measures represent the distribution and dynamics of the original data, are able to distinguish patients from controls. Variable importance, recursive feature elimination and ReliefF methods were used for feature selection. Model training and tuning, and testing were performed in nested cross-validation, and were based on algorithms such as Random Forests, Support Vector Machines, Gaussian Processes, Logistic Regression and Neural Networks. ROC analysis was used to post-process these models. Stability of model performances was studied using Monte Carlo simulations. The results provide evidence that pattern in mood changes can be captured with the combination of techniques used. The best results were achieved by SVM with radial kernel, where the best model performed with 82% accuracy and 82% sensitivity.\"\n",
      " 'Bayesian Nonparametric Clustering of Patients with Advanced Cancer on Anxiety and Depression Bayesian nonparametric (BNP) statistical techniques are thriving in Machine Learning, yet they are not widely used in psychiatric research, in part because of a lack of accessible tutorials and statistical computing solutions for researchers who are often non-technicians. We wrote a program to carry out BNP cluster analysis. We applied it to psychological data collected in a randomized controlled trial comparing Individual Meaning Centered Psychotherapy (IMCP, n =109), Supportive Psychotherapy (SP, n =108) and Enhanced Usual Care (EUC, n =104) in reducing psychological distress and improving meaning making in patients with advanced and terminal cancer. A BNP cluster analysis identified 5 subgroups of patients with unique profiles of anxiety and depression scores before psychotherapy. Our findings show that cancer patients who report mild symptoms in both anxiety and depression are most likely to respond to IMCP as compared to EUC. Somewhat unexpectedly, patients with anxiety and depression both at an elevated level do not show the highest response. We aim to introduce BNP statistical techniques to behavioral researchers in psychiatry, using BNP cluster analysis in IMPC psychotherapy as an illustrative example, and discuss with other researchers how they may use it in their own work.']' \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# output = [extract_keywords_yake(text) for text in data_df[\"text\"].values]\n",
    "# output = [extract_keywords_yake(text) for text in data_df[\"text\"].values]\n",
    "data_df[\"extracted_keywords\"] = extract_keywords_yake(data_df[\"text\"].values)\n",
    "# data_df[\"extracted_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of defects, Ensemble Clustering Technique, defect prediction software, Software Metrics Number, data mining techniques'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"extracted_keywords\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'software defect prediction, particle swarm optimization, cluster data, ensemble clustering'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"keywords\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"yake_keywords.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b692d53c618c7279fd8f739b29cb9b56968a589a1952adc40c54d9e83ebc1323"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
